Locating cross-library API calls. XLA looks for cross-library calls by walking through the call graph generated by FlowDroid . Specifically, each node in the graph represents a function and carries the information about the function’s class and package (according to Java’s reverse domain name notational convention ); each edge (with direction) describes a call from the caller node to the callee node. On the graph, XLA identifies cross-library calls by comparing the package names of the caller and callee class: if their top and second level domains (1) do not match with each other, and (2) do not match the host app’s package name, the call is considered cross-library – an approach also used by MAPS.

Also, a cross-library call can leverage Java’s reflection to implicitly trigger a function (see the example in Figure 4a). Hence, XLA inspects all reflection calls on the call graph, and checks whether the caller and callee classes belong to different libraries. To this end, XLA first locates reflection calls from a set of call patterns (see Table 6). As shown by a recent study , these patterns cover the most common reflection use cases in Android apps. Further, our approach recovers the callee’s class name and method name from the arguments passed to the reflection functions. For example, the argument of Class.forName(target_class_name) indicates the callee class name, e.g., com.facebook.AccessToken in Figure 4a. A problem here is, the argument could be a variable. To find its value, XLA utilizes DroidRA , an inter-procedural, context-sensitive and flow-sensitive analyzer dedicated to resolve reflection calls, to track the string content propagated to the variable.

Identifying cross-library leaks. With the discovered cross-library calls, XLA then identifies the restricted data items returned to the caller library, and performs taint tracking to detect potential data exfiltration (to the Internet) by the caller library. In particular, XLA leverages Meta-DB to recognize restricted data items being returned, as meta-DB recorded which are the sensitive SDK APIs and the restricted data they return (see Section 3).

Further, we need to track down the data flow of the restricted data. Instead of directly using the techniques of FlowDroid (e.g., with deep object sensitivity), which is considered heavy-weight for an analysis of 1M apps , we need a relatively light-weight tool. Hence, we opt for existing taint track techniques that are capable of inter-procedural analysis, field-sensitive but not object-sensitive. We take the return value of the cross-library calls as the taint source, and networking APIs as the sink. For example, the return value of the reflection call on com.facebook.AccessToken.getToken() is a taint source including Facebook user’s session token (Figure 4a); once the data reaches a sink in the caller library, e.g., OutputStream.write(String.getBytes()) API to send the data to the Internet, XLA reports a potential data exfiltration.

Checking policy non-compliance. Given a potential exfiltration of the restricted data from a victim SDK, we check whether it violates the ToS policy of the target SDK (obtained by DPA in Section 3). Depending on the conditions with which the ToSes restrict the access to individual data items, our approach for a compliance check is as follows.

- No third-party access; no access by any party. If the ToS (e.g., those of Facebook, Twitter and Pinterest) prohibits an access to the data by a third-party (e.g., a third-party library or its vendor) or by any party (e.g., Facebook user ID and password are not even allowed to be exfiltrated/stored by the host app vendor), we consider the exfiltration of the data a violation of the ToS – an XLDH activity is identified.

- Requiring user consents; complying with regulations. Some ToSes ask that the access to certain data items should require a user consent or comply with privacy regulations (i.e., GDPR, CCPA, COPPA). In XLDH, data sharing and collection occur between caller library and victim SDK without being processed by the host app. Hence, we consider the caller library to be a data controller , which has obligations to comply with regulations and disclose the data practice in its privacy policy . In our study, we check the privacy policy of the caller library to determine whether it discloses the data collection and sharing behaviors in its privacy policy. To automatically analyze the privacy policy, we use PolicyLint  to extract privacy policy tuples (actor, action, data object, entity) associated with that restricted data. Here the tuple (actor, action, data object, entity) illustrates who [actor] collects/shares [action] what [data object] with whom [entity], e.g., “We [actor] share [action] personal information [data object] with advertisers [entity]". In our study, we care about the tuples with caller library as actor, share/collect as action and the restricted data as entity. Note that for non-English privacy policies which PolicyLint  can not handle, we translate them into English for further processing.

Discussion. Recent studies such as  on privacy compliance considered the data as leaked out once an API returning the data is invoked by an unauthorized party. We found this is imprecise in detecting XLDH, due to the pervasiveness of service syndication (e.g., Twitter4j, Firebase Authentication) in which a benign library wraps other SDKs (Facebook login, Twitter login) to support their easy integration into apps.

USENIX Association 30th USENIX Security Symposium 4141
Sequence patternClass.forName() → getMethod() → invoke()getDeclaredMethod() → setAccessible → invoke()
syndication libraries also acquire restricted data from these third-party SDKs but rarely send them out to their servers. Therefore, a policy violation can only be confirmed once the collected data are delivered to the unauthorized recipient.

# 3 Meta-DB Construction
Our Meta-DB records the API specifications and metadata of top 40 third-party libraries, which cover 91% of Google Play apps (see below). For each API, Meta-DB records the data it returns (e.g., session token, page likes, user ID, profiles, groups followed) and whether or not the return data is restricted by the SDK’s ToS.

Identifying popular third-party SDKs. To find the most popular SDKs which are appealing XLDH-attack targets, we ranked the third-party SDKs based on the number of apps using them. Specifically, we randomly sampled 200,000 apps in Dg and identified the third-party SDKs using by those apps. Just like MAPS , we considered a SDK as third-party if the top and second level domains in its package name do not match the app’s package name. After ranking those SDKs, we selected the top 200 excluding those with obfuscated package names, and further manually reviewed and removed utility SDKs which are not associated with restricted data, e.g., Google gson SDK . The remaining 40 SDKs were then used in our research to construct Meta-DB (Figure 3).

Note that in our study, the 40 SDKs (from top 200) recorded in Meta-DB are integrated in 91% of apps. This indicates a high chance for them to co-locate with a malicious library in an app. In contrast, the remaining 6,273 SDKs we found were less popular: the 201st popular SDK was integrated in just 0% of Google Play apps.

Identifying privacy-sensitive APIs. We gathered 26,707 API specifications provided by the aforementioned 40 SDK vendors. Such documentations, especially those provided by popular vendors, tend to be highly structured, with well specified API names, argument lists, and return data. This allowed us to build a parser to extract the API names and the return values. Particularly, for each API, we use regex (e.g., "returns(\W*\w*)*|retrieves(\W*\w*)*|get(\W*\w*)*") to match the return values. Note that API specifications are often well-structured and the regex based method is efficient to identify the return values. In particular, we evaluate the regex-based method on 200 labelled data and achieve a precision of 100% and a recall of 98%. Altogether, we extracted 10,336 APIs and their associated return values from 26,707 API specifications.

Our study marked an API as privacy-sensitive if its return values were protected by data sharing policies. This is done by checking each API’s return values against the restricted data reported by DPA. However, this can not be achieved by simply using a string matching method, because the API specification and ToS usually describe protected information differently. For example, ToS tends to describe a data object in a more generic way (e.g., user profile), while the API documentation usually use more specific terms (e.g., username). Hence, we align the data objects in API specification with that in the ToS based upon their semantics (represented by the vectors computed using an embedding technique). Specifically, we train a domain-specific word embedding model to get the data object vectors, and then measure the similarity by calculating the cosine distance between the vectors. In our implementation, we gather 1G domain-specific corpora (e.g., privacy policies, ToSes, API documentations) and 2G open-domain corpora (e.g., Google News, Wikipedia) to train a skip-gram based word2vec model. Here, we leverage data augmentation technique , which generate a new sentence by randomly replacing synonym, inserting word, swapping positions of words and deleting words, to enlarge our domain-specific corpora.