Encrypted channels with packers. Android apps can use packers to protect apps from being copied or altered (e.g., by encrypting class DEX files). We used APKiD6 to identify the prevalence of packers in apps. We found that 121/12,598 (0%) apps use packers for Java implementations. These apps can contain some API methods not detectable by common static analysis tools (e.g., Apktool and Androguard). ThirdEye uncovered 51/121 (42%) apps that use cryptographic APIs, and 34/51 (66%) apps that use custom-encrypted channels leveraging packers. In addition, by analyzing 20 randomly selected apps that use appsflyer tracking SDK, we found all of those apps included packed appsflyer SDK, but APKiD failed to identify the packed SDK. This SDK was used in 1386/2887 (48%) apps that used custom-encrypted channels to send tracking information (see under “Recipients of encrypted traffic”).

# 5 Insecure key management and weak ciphers
We found 2421/2887 (83%) apps sent data with custom encryption using fixed keys (on the same device in two different installations); 2112/2421 (87%) apps used symmetric and 502/2421 (20%) apps used public-key ciphers. On the other hand, 1780/2421 (73%) apps used fixed keys across devices; 1593/1780 (89%) and 341/1780 (19%) of them used symmetric and public-key ciphers, respectively. Moreover, we identified 561/2421 (23%) apps with hard-coded keys. We also identified 154/2421 (6%) apps used both symmetric and public-key ciphers with fixed keys. We also observed that 27 apps used custom encryption to store their content in the device shared storage; 26 apps used symmetric keys, and one used a public key; 9 apps stored ciphertext (generated using symmetric fixed keys) in shared storage, exposing various content types (e.g., device information, inputs, network data) to other apps; see Sec. 5.

In terms of the use of broken/weak cryptographic algorithms, and short-length keys, we observed that even Android 12’s cryptographic API does not restrict such usage. We identified 262/2887 (9%) apps used insecure algorithms, e.g., DES (106), RC4 (3), 3DES (34), RSA-384 (1), and RSA-512 (60). The use of fixed keys and weak ciphers can lead to serious privacy/security issues, depending on the app; see Sec. 7 under “New security vulnerabilities”. Note that if an app uses a fixed/hard-coded key to encrypt data sent over HTTPS, then this will not lead to data exposure to a network attacker.

# 6APKiD
(https://githubhelp.com/l9sk/APKiD) provides information on how an APK is formulated, e.g., compilers, packers, obfuscators.

# 5 Apps sending geolocation information
GPS and router SSID. We observed that 2727/12,598 (21%) apps sent GPS coordinates [ 62 ] and router’s SSID to remote servers; 129 (4%) of them used additional encryption to send this information; see Table 1. Interestingly, 197 apps sent GPS coordinates to third-party services, but not to their own servers. For example, the official app of Russian Post (com.octopod.russianpost.client.android) sent GPS coordinates (via regular HTTPS) to tracker-api.my.com, a subsidiary of the Russian social media company VK (vk.vom). On the other hand, com.cashingltd.cashing, com.tdcm.android.trueyou sent GPS coordinates to appsflyer.com only under custom encryption.

Neighbor’s router scanning. Apps with location permission can collect BSSID, ESSID from the app user’s router, as well as all nearby wireless routers. Such router IDs have been used to determine physical location since 2011 (e.g., [ 27]), and currently public databases of such ID-location mapping exist for hundreds of millions of routers (see e.g., wigle.net, mylnikov.org); this has also been exacerbated by the increasing adoption of IPv6 [ 49]. A user’s location-capable app thus can reveal not only her location, but also the location of her neighbors (irrespective of the apps/devices used by them). We found 102 apps that sent neighboring router IDs to their servers (notable apps: PayPal, PayPal Business, Yandex, Mail.ru, VK, Kaspersky Security and VPN). More importantly, 22 (21%) apps sent such IDs only via custom encrypted channels; a notable example: Baidu Search (com.baidu.searchbox). Even after a user moves to a new location with her old router, her location change can still be exposed, if she has a neighbor with a location-capable app. The 102 apps that we identified, have been mostly downloaded by users from Russia (66,480,721 users), Brazil (41,163,244), Indonesia (9566,304), USA (8802,562), and India (6749,443); estimated download numbers are from similarweb  (Q2, 2021, for Google Play apps). Some of these non-Google-Play apps are also very popular; e.g., com.baidu.searchbox and com.sina.weibo, ranked 9th and 12th, respectively, in AppinChina.co app store.

# 5 Exposures via files
Leftover files in external storage. Among our analyzed apps that created files in external storage, 128 apps stored device information, 12 stored GPS coordinates, and 10 stored network information. 27/150 (18%) of these apps used custom encryption to store content in external storage; 9/27 (33%) apps stored device info and one of those apps stored authentication tokens; e.g., ru.mediafort.povarenok stored the DES-encrypted value of the device email (i.e., device account) in mediafort/data.txt; tw.comico stored user authentication tokens with a fixed key.

Covert channels. We found 44 apps stored device information into common folder paths in shared storage. There were 104 apps that checked the existence of these paths. These files can be used as inter-process communication (IPC)/covert channels — 4 apps from different vendors wrote the device WiFi MAC address to .cc/.adfwe.dat file path; 8 apps from different vendors check the existence of this path; 20 apps saved the MD5 hashed value of WiFi interface MAC address; 67 apps check the existence of the path. Moreover, we detect that app.buzz.share app and its lite version with over 110 million downloads stored identifiers, such as device ID, in a file (bytedance/device_parameters_i18n.dat), encrypted with
# CCS ’22, November 7–11, 2022, Los Angeles, CA, USA
# Sajjad Pourali, Nayanamana Samarasinghe, & Mohammad Mannan
# 6 EFFECTIVENESS AND LIMITATIONS
# Overall effectiveness
We verified our initial results through manual inspection, refined the tool before conducting the large-scale study. Note that we do not have any ground-truth on the targeted leakage, and we also cannot rely on any existing tools for accuracy; e.g., AGRIGENTO  could have been used in some limited cases (e.g., for the data types considered by the tool), but it is now outdated (designed for Android 4). ThirdEye’s effectiveness is apparent from the numerous new privacy exposures of various types that we uncovered. However, for some apps, our analysis may fail to fully identify the security and privacy issues due to the use of non-standard and custom encryption channels—see below under limitations. We first summarize the strengths of ThirdEye components, which, in combination, contribute to our overall effectiveness.

Our UI interactor (partially) supports custom registration/login and Google sign-in, detects already explored widgets/objects to prevent duplicate interaction/exploration, and avoids non-targeted activities (e.g., ads). In contrast, Android Monkey lacks these features, and hence can take longer for the same code coverage and miss anything beyond the login page. We report the results of a preliminary experimental comparison with Monkey below. Our operations logger performs network/cryptographic/file API instrumentations. It is resistant to obfuscation/packing for identifying Android SDK cryptographic APIs, supports HTTP/S and non-HTTP protocols, supports (unobfuscated) 3rd-party encryption/decryption API, supports defragmentation of multi-part cryptographic functions and network packets. These features help us to understand a lot of custom-encrypted and non-HTTP traffic, and identify more privacy exposures compared to existing work. Our data flow inspector detects privacy issues in the collected network traffic/files, by matching actual plaintext (collected by the app operations logger) and ciphertext from the network (after handling any IP defragmentation)—i.e., our reported exposures indeed happen during app runtime. This helps us to avoid false positives. We reliably detect the use of weak cryptographic keys and algorithms; support various privacy-sensitive items (can be easily extended); support various encoding schemes, and nested encoding and encryption; support file detection within encrypted traffic; and distinguish between app and OS traffic. These features make the data flow inspector to accurately detect privacy and (potential) security problems.

# UI interactor vs. Android Monkey
To compare the effectiveness of our UI interactor against Android Monkey (commonly used in past studies ), we randomly chose 150 apps that exceeded the 5-minute threshold from our results. We set up two new experiments with a 10-minute threshold (following ): in one experiment we used our UI interactor, and in another, we used the Monkey as the UI exerciser. We also configured Monkey to generate a large number of UI events, by setting a short interval of 0 seconds between events. Note that our interactor generates far fewer events—on average, 10 seconds per event, as we keep states to avoid duplicate events, perform text analysis, and use the online Google Translate service. We used the latest versions of the 150 randomly chosen apps, and 115 of them completed the analysis without any unexpected termination (in both Monkey and UI-interactor; we did not consider any partial results in this test).