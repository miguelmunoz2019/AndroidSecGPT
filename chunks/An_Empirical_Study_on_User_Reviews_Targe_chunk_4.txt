As the categorization of the apps based on reviews gives us categorical data, for correlation calculation we have categorical vs categorical data and categorical vs numerical data. As mentioned in Section 3, for the categorical vs categorical data we have used the symmetry approach of “Cramer’s V” (hereafter shown by CV) and asymmetry approach of “Theil’s U” (hereafter shown by TU1 and TU21). For numerical vs categorical data also “Correlation Ratio” approach has been used (hereafter shown by CR).

The Table 4 shows the result. The third row shows the correlation between apps’ categories based on related reviews and categories of apps in different perspectives. Considering the Figure 3, we noticed that the negative reviews form the majority of the related reviews. From this, we can assume that people do not usually praise apps for security and privacy concerns; therefore the apps with tag of “Not discussed” are actually “Good”. Hence we replaced the tag of “Not discussed” to “Good” (in Table 2). This provided us a new correlations whose results are listed in the last row.

We have also used non-parametric statistical significance tests to assess the relation between categories of the apps in terms of reviews and in terms of their actual behavior. The Table 5 provides the p-values for both the MWU and KWH tests (row 3). Following the same assumption as above, in the last row we have the p-values for these tests, where all the apps with tag of “Not discussed” have been replaced with the tag of “Good”.

1TU1 shows the correlation between first set and second one and TU2 shows the vice versa.

# 6 Discussion
After running the classifier, we found around 0% of the all reviews are related to security and privacy concerns. We looked into the related reviews from different viewpoints. In terms of categories of the apps, although Game, Entertainment, Tools, Shopping, and Social are the categories with the highest reviews in our dataset, when it comes to the ratio of security/privacy related reviews, we see different categories on top of the list. It is not surprising to see categories such as Communication, Photography, Travel and Local, and Social are on top of the lists, as the users may be worried about the security of their personal information in communication and social mobile apps and also they may be concerned about the access of apps to some of their private information such as photos and location (cf. Figure 2).

Considering the rating of the reviews in Figure 3, it seems most of the time people complain about their concerns, as the number of related reviews with 1 star is the highest. In terms of the role of developer, we expected to see that the developers with higher number of apps in our dataset, have higher number of reviews and consequently the same ratio of negative related reviews. Initially we noticed that the top 20 developers with most apps in our dataset have the most reviews as well (with the same ordering). Then after plotting the percentage of negative related reviews, we noticed for some developers like “Facebook” and “Samsung”, ratio of negative related reviews to all reviews are higher than expected (Figure 4). This shows us that the developer of an app can potentially influence the users’ perception.

After the process of dynamic analysis, we were able to match the actual behavior of the apps with users’ judgment. The third row of the Table 4 shows the correlation between apps’ categories based on related reviews and categories of apps from the different perspectives. In the first look, we noticed that excluding the perspective of the last column (which relates to the number of permissions asked from users), in all the others, almost there is no correlation. Furthermore based on the results we obtained from the first research question, we assumed that people do not usually praise apps for security and privacy concerns and we changed the apps with tag of “Not discussed” to “Good” for better understanding. This resulted in new correlations shown in the last row. Again, excluding the last column, there is almost no correlation between different perspectives and apps’ categories based on users’ reviews. Considering that the only correlation happens based on the number of permissions asked from user, we can say the main criterion of the users for judging the functionality of the apps in terms of privacy and security is the number of permissions asked. In another viewpoint, users do not have any other promising criterion to help them decide how to feel about an app.

For the significance tests (cf. Table 5), we assumed the significance level (the probability of rejecting the null hypothesis when it is true, denoted by α) to be 0. We can see that the “p” value is very small for PE (row 4); so we can reject the null hypothesis and can confirm that the number of permissions asked is related to the categorization of the apps. Again for column LOC, the p value is smaller than α in row 3; hence, we can interpret that LOC also affects the app categorizations. This definitely makes sense because if an app sends out location details, it needs to ask for permission from the user in most of the cases. Therefore, the results under LOC are affected in the same way as PE. So, in these aspects, we can say that the users’ reviews can be a signal of the app’s behavior. On the other side, if we consider the p-values under CH, it is greater than α for the majority of the cases; hence we failed to reject the null hypothesis. We have the same results for BA, BAH and MPH perspectives. So in these cases, we can say that the users’ review are not a good indicator for the behavior of the apps.

The main limit of our study was the restriction of Google API for accessing to reviews of an app. For some of the famous apps, we only had access to the latest reviews for last few months. The reviews in short time intervals can be biased and may not provide a fair representation of users’ perception.

We found that the number of permissions can considerably influence users’ thoughts. Therefore, a main step for future can be evaluating if the higher number of permissions necessarily results in worse functionality in terms of security and privacy. Along with this, investigating the most efficient practices for addressing privacy/security concerns while getting high number of permissions, is always an interesting topic. All these ideas can be equipped by approaches for making users to feel safe and comfortable while granting permissions. On the other hand, developing tools and guidelines to increase the number of users’ criterion for judging their privacy violations can be a good step in the future.

# 7 Conclusion
In our study, we initially scraped details and reviews of 539 top free mobile applications of the Google Play Android app market. We made our dataset with the total number of 2,186,093 of reviews. After pre-processing phase, we ran our classifier, SVM, which provided us the best performance according to 10-fold cross validation. In our experiment, 0% of reviews are classified as related to security and privacy concerns. Our analysis showed that users are more concerned for the apps from categories such as communication, photography, travel, and social. They also mostly provide their security/privacy related reviews along with low ratings (1 and 2 stars). We also noticed that users may get influenced by the developer of an app. It means, they may trust or distrust a developer.

In order to assess the judgment of users, we performed dynamic analysis to see the actual behavior of the apps. We found a correlation between the judgment of users for an app and the number of permissions asked from user by it. We also noticed some correlation between the categories of apps based on user reviews to those apps that send out location information. In all other perspectives such as “number of domains contacted” and “bridging AAID”, no significant correlation was observed. This can be originated from the fact that permissions are the main criterion for judging the amount of access of the apps to personal data..