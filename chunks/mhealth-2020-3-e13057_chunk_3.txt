In this study, we identified 36 criteria that are important to the design, development, and analysis of mHealth-related apps,
https://mhealth.jmir.org/2020/3/e13057
JMIR Mhealth Uhealth 2020 | vol. 8 | iss. 3 | e13057 | p. 6
(page number not for citation purposes)
# JMIR MHEALTH AND UHEALTH
# Llorens-Vernet & Miró
which were grouped and subsumed into eight categories according to their similarity: (1) usability (ie, the app must be adapted to the targeted population), (2) privacy (ie, compliance with the law and treatment of users’ data), (3) security (ie, data protection, authorization mechanisms, and detection of vulnerability), (4) appropriateness and suitability (ie, the benefits and advantages for the end users are explained), (5) transparency and content (ie, scientific evidence and sources information), (6) safety (ie, the potentiality of risk to end users), (7) technical support and updates (ie, there is a policy about the maintenance of the app after it has been launched), and (8) technology (ie, the app works smoothly and does not fail abruptly).

In addition, this set of criteria underwent a test, and the preliminary data have shown that the criteria are understood by potential users. Furthermore, they have been reported to be of high importance by the group of stakeholders. Of particular importance (ie, a criterion that was valued as 9 or higher by all stakeholders groups on a 0-10 numerical rating scale) were the following: (1) It is easy to use (ie, navigation is intuitive); (2) It guarantees the privacy of the information recorded. It requires users to give their express consent. It warns of the risks of using the app; (3) Confidential user data is protected and anonymized, and there is a privacy mechanism so that users can control their data; and (4) It uses scientific evidence to guarantee the quality of the contents. It is based on ethical principles and values.

Our work improves previous proposals as it brings together information from a variety of internationally relevant sources (ie, research studies, data from websites of professional organizations, and standards governing the development of software for health or medical devices), whereas available ones have been developed narrowly, mostly using just one source (eg, studies on mobile apps ), sometimes using data of unknown scientific value (ie, mobile apps available on Web-based stores that have not undergone usability or validity studies ). This might be responsible, at least in part, for missing information in available guides. For example, in the case of the MARS , which is one of the most used rating systems, authors have failed to include some very basic items on their scale. Of particular concern are the issues of privacy and security of users’ information, which are not on the scale. The protection of users’ information is mandatory by law, so it is fundamental for all scales to include this as part of an integral evaluation of a mobile app. Likewise, the scale attaches little importance to whether an app is evidence-based or trialed in well-controlled studies. For example, a recent study that used MARS  to assess the quality of pain-related mobile apps showed that of the 18 apps, the 2 that had been scientifically tested were given the worst scores on the scale, and 1 of these had already been awarded a seal of quality from a public agency. It does seem that with MARS, the so-called commercial apps are better rated than those that have been scientifically tested and shown to provide valid and reliable information. This goes against the current trend in the area, which is seeking apps that have been scientifically tested and designed on the basis of evidence . Furthermore, Salazar et al  showed that when MARS is used, an app developed with a highly specific objective in mind (eg, to measure pain intensity) will show lower scores (and will, therefore, be assumed to provide worse measurements) simply because of its specificity. Finally, the questions on the rating scale developed by Stoyanov et al  were mostly written to be answered by end users and require responses that are highly subjective or cannot be answered by a person who is not an expert in the field (eg, “Is app content correct, well written, and relevant to the goal or topic of the app?”).

In addition, the preliminary data on the comprehension of the criteria showed that they can be understood by different profiles of stakeholders, as intended. However, a few of them reported having problems with some criteria, which were solved after giving additional explanations. Therefore, it is important that the information is presented with the least technical wording possible to facilitate comprehension. Nevertheless, additional studies with more participants to validate and extend the findings are warranted.

The resulting guide with this set of criteria describes the standard to follow, identifies the main categories of criteria, and provides stakeholders with a systematic approach by which they can determine the general requirements of a mobile app if it is to be considered of high quality. An app that meets these criteria is one that will provide users with the greatest security and confidence in performance and the objectives being fulfilled.

# Limitations
This study has limitations that should be considered when interpreting the results. First, our search strategy was limited to papers written in English or Spanish, pain-related apps, and guidelines and standards published in specific regions and countries. We made these choices because it was what we could feasibly do, but we cannot be certain that we have included all the important criteria. For example, some issues could be seen as more important by developers of pain-related apps compared with developers of apps related to sexual health (eg, pain-related apps are biased toward treatment rather than diagnosis; pain-related apps may primarily be targeted at the patient, rather than health professionals or carers). We analyzed the studies on pain-related apps, and the information was combined with that from the most important markets for mHealth apps and on guidelines and standards available, as a way to complement each other and solve the potential limitations. Nevertheless, the final result of our analysis is limited in ways that we cannot completely foresee. Therefore, future studies on the validity and reliability of this set of criteria are warranted. Second, the comprehension test was conducted with a small group of 18 individuals from three groups of stakeholders. Although the number of participants was enough for a preliminary analysis, the sample is not representative. Thus, additional studies, including samples with more participants, are needed. Despite these limitations, this study provides important new information to help advance the field.

# Conclusions
This set of criteria can be readily used by health care providers, engineers and developers, researchers, patients, and regulators. The data have shown them to be comprehensible and of importance for a group of stakeholders. Nevertheless, future
JMIR Mhealth Uhealth 2020 | vol. 8 | iss. 3 | e13057 | p. 7
(page number not for citation purposes)
# JMIR MHEALTH AND UHEALTH
# Llorens-Vernet & Miró
Studies will have to empirically test the validity, reliability, and suitability of this set of criteria. Furthermore, they should be analyzed in terms of their significance to all stakeholders so that the set of criteria could also be used as a guide to the quality of the apps by all interested parties.

# Conflicts of Interest
None declared.

# Multimedia Appendix 1
Full list of criteria.