Changing employees’ habits and routines is complex and requires resources. However, it is not about redrawing entire organizational structures, but rather about moving holistically and purposefully one step further towards usable security.

# Create Awareness
As we illustrated in the results, awareness of usable security is crucial. While we identified companies that focused on user-centered requirements or needs and implemented respective methods into their processes, they were not aware of the important interplay of usability and security. Instead, they made usable security decisions unconsciously (cf. Sections IV-F, V-B). The fact that decisions about usable security are often made unconsciously reinforces our assumption that awareness is fundamental to start a conversation about usable security and, consequently, to actively make decisions adapting the SDP towards usable security. Nevertheless, awareness alone is not sufficient to change behavior and establish habits that support usable security (cf. Section IV-D).

# Understanding Users and Their Context
Some contexts did not integrate measures for usability in their SDP. In order to make a system, and especially its security components, usable, it is crucial to understand the users’ needs, capabilities, goals, and most importantly, the context in which they interact with the software. We have seen that all of the contexts from Section IV-B were actively engaged in learning more about their users to build a more usable and secure product. To establish a better user understanding, we recommend sharing this information with other stakeholders, as the participant from C5 did while building an authentication mechanism for a postal delivery company. For a systematic approach, human-computer interaction research has established an extensive knowledge base (e. g., ) and toolbox (e. g., , ) that software professionals can use to improve usable security.

# Improve Communication between Experts
In all contexts from Section IV-B, we noticed the gap between usability and security expertise being much smaller than in the other contexts. We attribute this to extensive communication between security and usability experts. Tools such as personas or scenarios, known for decades as communication and modeling tools, are particularly suitable for helping software professionals to understand their users’ needs, experiences, behaviors, and goals. Even further, P13 described that they performed threat modeling as a group activity with both security and usability experts.

# Shift Usable Security Left
Usable security should become part of the SDP early on. We observed that usable security requirements are currently not specified concretely in almost all contexts. That said, usable security should be explicitly included in requirements engineering and addressed in early discussions with customers and other stakeholders – ideally from the very beginning. The analysis of decision-makers and decision chains (Section V-B) revealed that the requirements which are handed over to development teams, along with their level of detail, substantially determine the extent of available resources and the scope for interpretation of usable security.

# Measure and Track Usable Security
The celebration of short-term goals is a common activity to drive change forward . Hence, we recommend tracking usable security progress for both the process and the product. Furthermore, this helps to understand and improve usable security in existing processes. Performing regular usable security measurements as part of the SDP may also prevent a trial-and-error approach and save resources. To the best of our knowledge, there are no explicit measures to assess usable security. Instead, we recommend using conventional usability evaluation methods for security features to assess products’ usable security. This could include but is not limited to A/B testing, beta tests, or active feedback gathering, as prevalent in the contexts of Section IV-B. There may be other indicators or proxies; in C5 the reduced number of support tickets opened by users after a major redesign was an indicator of improved usable security.

# Usable Security Champions
In the context of security, security champions are a common role within teams. Similarly, we identified usable security champions as having interdisciplinary knowledge in usability and security as well as taking care of usable security. Usable security champions were available in three out of five contexts (C2–C4) in Section IV-B. Those champions are rare, like in C11 (Section IV-D), or could not be found or hired as in C13. Champions were unavailable in the other two contexts that also achieved usable security. Instead, in C5, the designer was the pivot point and initiator of a successful usable-security-driven process – without having security knowledge. However, this needs extensive communication, which can be a higher burden compared to a usable security champion as there will be no communication overhead. Therefore, we conclude that a usable security champion may not be needed when there is enough knowledge and skills for usability and security in the team and the respective members are collaborating.

# 2) Usable Security Defaults and Tooling
We identified a gap between usability and security for developers and
stakeholders as expertise in both is often unavailable at the same time. A general approach from the security area is the security by default principle. We suggest transferring this to usable security by default. For example, a web framework might have a module for user authentication. Extending this by usable security principles would allow software creators to easily create a secure and usable software feature out of the box, requiring little or no effort. Consequently, this approach appears suitable for those unaware of usable security or unable to climb the competence curve.

To the best of our knowledge, the current software development ecosystem lacks this support, as there is no tooling, no special documentation, guidelines, or standards for usable security. As a starting point, we propose creating guidelines and checklists for usable security in specific use cases. These then can be incorporated into tools and frameworks. Even if these measures may only be directly related to individual and not all stakeholders (e. g., a framework that only front-end developers use), they consider other contextual factors such as limited resources and knowledge. Nevertheless, the approach is not as holistic as the competence curve. However, this could be a way to systematically address the simpler usable security pitfalls. Overall, we recommend more research to explore this avenue.

# D. Recommendations for Human Factors in Security Research
Researching human factors in security has been an active field in the security community since the 1990s. However, we identified a low awareness (Sections IV-C, IV-E) and fundamental misconceptions (Section IV-G2) for usable security among practitioners. While it remains unclear how practitioners learn about usable security, it shines through all our observations that the past decades of usable security research contributions have not received widespread attention in the software industry so far. Hence, there seems to be a huge gap between the status quo in academic research and the adoption by the software industry. However, we are convinced that our community should try to close this gap by better transferring our expertise and knowledge to practitioners who build software. That way, research could increase its impact on society and improve security for millions of users. Furthermore, we discuss the following.

# Emphasize Context
Prior research has investigated pitfalls created by individual developers and other software professionals as highlighted in Section II. However, we found that context factors and culture are essential for success with usable security. This highlights the need for further research not limited to individual developers and extends the focus more towards context factors. This includes supporting factors and structures for usable security but also blockers and challenges posed by context factors. Therefore, research should move beyond developer training, education, and support, which is indeed an important approach. However, we also advocate for the research and development interventions that target the production context as a whole and not only single steps from the SDP like the coding by developers. Such a holistic approach should consider the context, including the company and all stakeholders, and processes as important factors influencing usable security. We hypothesize that a holistic approach could also be more sustainable as it does not focus on a single group of individuals, e. g., developers that may leave the company anytime, or technology and defaults changing over time.

# Tooling vs. Mindset & Knowledge
Two main approaches can be identified in our research community. One is tooling and technical solutions whose main idea is to support humans, for example, by providing suitable tools , ,  to enable non-experts to develop secure software. Beyond that, some approaches aim to “have an impact on the human”, e. g., the mindset, knowledge, or skills of stakeholders. Both have advantages and limitations; for example, using a tool is often easier than learning new skills or changing a mindset, but building a mindset for usable security might be more sustainable. We argue that both are orthogonal approaches, and both can be beneficial for different contexts. However, choosing one of those approaches in a specific scenario is not obvious and requires more research.