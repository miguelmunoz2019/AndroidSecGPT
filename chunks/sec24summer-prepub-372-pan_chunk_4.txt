Our dataset. We collected a new large-scale privacy policy dataset from existing apps on the Google Play Store. We also collected app metadata from AndroZoo , which is a large-scale and growing Android app collection extracted from multiple sources, including the Google Play app store. We removed duplicates and apps from other app markets and then randomly sampled 268,500 apps as our initial app dataset, which is around 10% of the whole app population. From this initial sample, we observed that some apps are either invalid or not usable. These were mainly dummy apps or student apps with a package size normally less than 10 KB, so we removed invalid apps like these. We further excluded unavailable apps that returned error messages on their Google Play page. Apps can be unavailable for many reasons including geographic differences  caused by government censoring, or being removed by Google because of disruptive adware, malware, restricted content, or other reasons. After these exclusions, we were left with 99,194 usable apps and their metadata. We then employed google play scraper  to obtain app information including privacy policy links, app categories, and required device permissions. Based on the available privacy policy links shown on the app’s homepages, we further utilize the BeautifulSoup  and Selenium  python packages to download those websites. Eventually, we obtained 46,472 privacy policies, and we refer to this privacy policy dataset as “Crawled Privacy Policy Collection.” We conducted the above data-gathering process in March 2022.

# 3 Missing Links and Unavailable Privacy Policies
Providing a privacy policy is essentially required by platform principles and privacy regulations, however, we observed that 15% (15,572/99,194) of apps do not provide a privacy policy link on their Google Play homepage. A previous study  reported that this statistic was 49% in 2019. Seemingly, as more regulation has been introduced, more apps have provided a privacy policy. However, we found that 37% (37,150/99,194) of privacy policy links lead to unavailable websites with error messages such as “403 Forbidden” or “404 Not Found.” This problem could be caused by potential reasons such as deliberately providing a dummy link, an outage, or the removal of the website server. Hence, in addition to simply requiring app developers to provide the privacy policy, the mobile app market also needs to frequently and regularly verify the validity of provided privacy policy links. Also, a permanent hosted privacy policy link provided by APPGs can help developers to mitigate availability issues to some extent.

# 3 Low-Quality Privacy Policies
Several previous studies  reported that it was not rare that some apps only provide a low-quality privacy policy, and we observe similar issues in our dataset. Firstly, some privacy policies do not contain meaningful privacy-related context, or are just dummy websites. For example, “Bway App” is a free app that provides football results, statistics, trends, and match result predictions, with over 10,000 installs; however, their privacy policy website  does not contain any content, and the file size of the crawled privacy policy is close to 0 KB. In addition, some are apparent “homemade” privacy policies that are too general to include essential data practices. For instance, “Easy Communication” is designed to help people with autism, cerebral palsy, dyslexia, intellectual disability, and other special needs to communicate easily. Its privacy policy  only has 156 words, and ambiguously mentions required device sensor permissions without any elaborations. Based on our observations and previous work, we empirically set the file size threshold as 2 KB , and the document length threshold as 200 words . If a crawled privacy policy does not meet both criteria, it will be regarded as a low-quality privacy policy. In total, we identify 22% (10,375/46,472) low-quality privacy policies.

# 3 Observations on Status Quo
In this section, we report an analysis of app privacy policies and identify three common problems in existing apps: missing/unavailable privacy policies, low-quality privacy policies, and language non-localization problems. Although similar problems were discussed in several previous studies.

# 3 Language non-Localization Problem
Language localization is necessary to promote apps in a global market. Although app UI and content can be translated, app developers may neglect the privacy policy. We employed the Python package langdetect  to detect the language of the crawled privacy policy documents and found 20%
(9,523/46,472) of apps do not provide an English privacy policy, although these apps were released in markets where the primary language is English. Interestingly, the top five non-English languages are Spanish (15%), Portuguese (9%), German (8%), Korean (8%), and French (7%). This trend might be attributable to the implementation of the European GDPR and Brazilian LGPD. We observed this problem even with top apps from some large companies. For the privacy policies of the top 1,000 most installed apps (all > 500k installs) in our dataset, there are still around 14% that do not provide an English privacy policy. APPGs may be a solution to language non-localization problems. Only APPG #1 Iubenda supports multilingual generation, but some APPGs (#4, #7, and #9) have included placeholders for future options for language selection.

# 3 Synthetic Apps and Generated Privacy Policy Collection
To identify whether privacy policies could be generated by APPGs, we first need to build the ground truth with self-generated privacy policies for each APPG. As shown in Table 1, seven APPGs require users to register an account to use the service, and six of them also require users to pay subscription fees to unlock all features. We registered as required and paid subscription fees. Synthetic apps are commonly used in similar empirical studies such as . We designed and tailored 3 synthetic apps specifically based on APPGs’ features and characteristics as summarised in Table 2 and Table 3. This was so that the boilerplates and pre-defined clauses of every APPG can be fully explored and reflected in the generated privacy policies. The functions and features of these synthetic apps are as follows:
- Synthetic App 1. A toy-like app that collects only general personal information and does not need to comply with GDPR, CCPA, or LGPD.

- Synthetic App 2. A social app that enables people to interact and communicate with others. Users need to create an account by providing their general personal information, and the app requires all device permissions. The app also accesses third-party services and only needs to comply with GDPR.

- Synthetic App 3. A hypothetical omnipotent app that requires users to provide all general and sensitive personal information to function. The app also needs all device permission and access to third-party services. This app needs to meet the requirements of GDPR, CCPA, and LGPD.

These three synthetic apps are various in terms of functionality and sophistication, and they decently cover all data use mentioned in Table 3. Therefore, they are capable of being the boilerplate apps for APPGs’ ground truth in the majority of cases. For each APPG, we created the same three custom privacy policies to test whether a privacy policy can be generated by one of analysed APPGs. Given ten APPGs and three synthetic apps, we obtained 30 privacy policies as “Generated Privacy Policy Collection” in total. We utilized it and “Crawled Privacy Policy Collection” to conduct the following market penetration analysis.

# 3 Market Penetration Analysis
We report a market penetration analysis to highlight the extent to which APPGs are used and to provide insights about why some APPGs are more popular. Specifically, we employ two methods to detect whether a privacy policy could be created by one of these APPGs: fingerprint keyword searching and document similarity comparison.

# Fingerprint Keyword Searching (FKS)
APPGs offer various publishing features, including the provision of a direct link as a permanent website host or an editable HTML document. We observe that to better advertise themselves, APPGs typically embed their company names into the URLs of the generated privacy policy websites or the editable HTML document. Consequently, we construct the fingerprint keyword set grounded in this feature. To cultivate this set, we manually inspected these APPGs and the collection of generated privacy policies. To mitigate the likelihood of false positives, we verified the authenticity of all keywords individually. Specifically, we incorporated a candidate fingerprint keyword into the set only if it appeared consistently across all three ground-truth privacy policies crafted for synthetic apps. All keywords are deliberately sensitive to case and format. The full keyword list is available at.

Then, the collected keyword set is employed to perform FKS in the crawled privacy policy collection. For each privacy policy in our collection, if we find a match in either its website link or its document context with one of the fingerprint keywords, the policy is considered to be generated by the corresponding APPG. For example, during the examination of policy website URLs, we use the keyword “iubenda.com” to search URLs like "www.iubenda.com/123abc..." for APPG #1 Iubenda. Similarly, while scrutinizing policy HTML documents, identifiable phrases like "iubenda hosts this content" were utilized as markers.