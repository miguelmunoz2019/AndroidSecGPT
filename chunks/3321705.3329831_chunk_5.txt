P10 & P11: Vulnerabilities due to uninitialized data. Uninitialized data is another traditional vulnerability , and pattern P10 and P11 cover its two scenarios. The first scenario misses using memset() to initialize memory buffer, and the second forgets to assign an initial value (e.g., 0 and NULL) to a certain data variable. These uninitialized data might be exploited to leak information about memory layout.

P6: Use-after-free and double free issues. This type of vulnerabilities is due to incorrect use of memory free functions (e.g., osi_free() and kfree()). In some vulnerabilities, such as CVE-2017-13257, a memory free function was placed at a location where the data was still in use, causing an use-after-free issue. In other cases, such as CVE-2018-9356, a memory buffer was freed two times under a certain control-flow branch, resulting in a double free issue.

P16: Data race due to missing lock/unlock. The last traditional vulnerability pattern we clustered is about data race, where lock/unlock functions (e.g., spin_lock/unlock() and mutex_lock/unlock()) are not placed to prevent race conditions in a multi-thread system such as Android.

# Key Takeaway:
Our clustering algorithm automatically generates good-quality clusters of patch code fragments, with 84% clusters associated with certain patterns. We thus can extract 16 vulnerability patterns from 19 security-oriented clusters, including six new ones not known in the literature and four specific to Android. We further analyze the characteristics of these patterns via case studies.

# 4 Implications of Our Analysis Results
In this subsection, we further discuss four implications of our analysis results presented earlier.

Implication 1: Our analysis quantitatively points out the seriousness of system-level vulnerabilities in Android. By analyzing the severity of all 2,179 vulnerabilities in §4, we found that 81% of them are rated as high or critical severity. This suggests that detecting system-level issues is equally, if not more, important than app-level vulnerabilities. Indeed, a considerable portion of Android malware in the wild leveraged system vulnerabilities for root exploits . Therefore, it is especially important for security researchers to detect and patch zero-day Android vulnerabilities ahead of hackers.

Implication 2: The results of vulnerable modules can help system developers avoid making similar mistakes in the same module or code. This is a further usage of our vulnerable module results beyond the statistical data presented in §4. Specifically, when an Android system developer or a third-party ROM maker starts to work on a particular Android module, he/she can first go through previously
# Session 4A: Mobile Security
# AsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand
reported vulnerable code examples in the same module. In particu-
lar, our module results contain detailed code file paths (e.g., Table 3 in §4) and their associated patches. To help developers easily re-
trieve such information, we are on the way of implementing a web portal to make our results browsable and searchable.

# Implication 3:
Since implementation bugs are an important source of Android system vulnerabilities, it is necessary for future defense systems to adopt them into threat models. Existing research efforts on securing Android OS have proposed mandatory access control (e.g., SEAndroid [ 62 ] and ASM [ 36 ]) and information flow control (e.g., Weir [56 ] and Aquifer [ 57 ]). These defense systems typically assume no implementation vulnerabilities in Android platform components. For example, SEAndroid [ 62 ] admits that it cannot mitigate kernel vulnerabilities or address threats from other platform components, while Weir [ 56 ] explicitly includes Android OS as its trusted computing base. However, as revealed by our analysis of patch code complexity in §4, a significant portion of Android vulnerabilities are likely implementation bugs. These implementation weaknesses could then turn down an originally secure system design.

# Implication 4:
Our patch code patterns can be leveraged for automatic vulnerability detection using program analysis techniques. A key problem in using static program analysis for vulnerability detection is to determine patterns, and our analysis in §4 can serve for this purpose. Specifically, extracted vulnerability patterns can be utilized in two ways. First, some patterns are context-independent (e.g., P1 and P2) or can be tracked using data/control flows (e.g., P3, P6, P10, P11, and P15), and thus can be directly inputted to a static analysis tool. For other patterns that are fully related to program contexts, learning-based methods (e.g., VulDeePecker [ 51 ]) can be further employed to distinguish different contexts.

# 5 RELATED WORK
In this section, we present the research related to Android system vulnerabilities, vulnerability report analysis, and similar or cloned code detection.

# Research on Android system vulnerabilities.

While most prior work was concerned about app-level vulnerabilities (e.g., [ 22 , 24 , 25, 27 , 30, 34 , 42 , 48 , 54 , 58, 66 – 69, 72 , 79 , 80 ]), there are some recent studies specialized for Android system vulnerability detection. Notably, ADDICTED [ 77 ] made a first attempt in analyzing the (in)security of Android device drivers and they found that a large number of device drivers customized by vendors are under- protected with downgraded permissions. Following this direction, several studies of mobile device drivers were further performed, on a new dynamic analysis [ 63], on the ION driver insecurity [ 74 ], and on an Android-specific kernel driver called Binder [ 18 , 28]. Compared to drivers, Android framework received more security re- search. For example, Kratos [ 60 ], Kywe et al. [ 46 ], Gu et al. [ 35], Ace- Droid [16 ], and ACMiner [ 38 ] discovered inconsistent security pol- icy enforcement in the Android framework, while ASVHunter [ 37] and KMHunter [ 64 ] examined denial-of-service attack issues. Different from these studies on detecting unknown vulnerability in- stances, we aim to obtain insights from reported vulnerabilities.

# Analysis of vulnerability reports.

Our paper belongs to the general research category of analyzing vulnerability reports. The most related are two works [ 41 , 52 ] that also analyzed Android vulnerability reports. Compared with our large-scale study via an automatic analysis framework, these two studies relied on significant manual efforts and used only a small set of vulnerabilities for analysis. Moreover, they did not present in-depth analysis, e.g., clustering patch code patterns as we did in this paper.

In the research of other vulnerability reports, Chen et al. [ 20 ] made a pioneer work on using a finite-state machine (FSM) to model and analyze memory corruption vulnerabilities in 2006. In 2011, Chen et al. [19 ] performed a high-impact study on analyzing 141 Linux kernel vulnerability reports. In 2017, Li and Paxson [ 47 ] conducted a generic measurement study of all kinds of security patches. There were also some studies surveying vulnerability reports as part of their research. For example, UniSan [ 53 ] surveyed the root causes of kernel information leaks reported after 2013, and InstaGuard [ 21 ] measured the patch delays of 12 vulnerabilities in Android system programs and also evaluated their patch solution in 30 selected Android vulnerabilities. Furthermore, a recent work, SemFuzz [ 73], leveraged vulnerability-related text from CVE reports and Linux git logs to guide automatic generation of proof-of-concept exploits.

# Detection of similar or cloned codes.

Code clone detection is a long-lasting problem in the software engineering and security areas. Back to 1998, Baxter et. al. [ 17 ] had proposed to use abstract syntax tree (AST) for clone detection. To improve the scalability, CCFinder , CP-Miner [49 ], and ReDeBug [ 39 ] splitted code into token sequences for a multilinguistic clone detection in large-scale source code, while Deckard [ 40 ] computed characteristic vectors for approximating ASTs and thus can cluster similar vectors only. VulPecker [50 ] and VUDDY [44 ] further abstracted vulnerability- related features specifically for vulnerable code clone detection. More recently, deep learning is also exploited for clone detection in source code [ 51 ] and binary code [ 71 ]. However, these clone detection works are not designed for finding similar code “changes”, thus not suitable for our patch code clustering problem. Only two recent works, Kreutzer et al. [ 45] and Paletov et al. [ 59], also worked on clustering code changes. Our clustering algorithm differs these two by extracting patch code’s essential changes and leveraging affinity propagation for automatic clustering without assuming any pattern template or structure.