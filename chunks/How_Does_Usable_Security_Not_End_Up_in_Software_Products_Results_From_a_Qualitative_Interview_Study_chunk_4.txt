No Usable Security Awareness, some User-centered Measures (n = 2), Sec. IV-C
No Usable Security Awareness, few or no User-centered Measures (n = 10), Sec. IV-E
Usable Security Awareness and Follow-through We placed five of 23 contexts (C1–C5) into the top-right category in Figure 2 because they followed a process that is characterized by user-centered methods, and they were aware of the underlying principles of usable security:
“Actually, I think that the security issues should be solved as much as possible technically and should not bother the user. Most of the time, the user is not an expert [. . .] That is, all the decisions that can be made for him, should be made in advance.” (C1)
one expert for either usability or user interaction and security worked closely with the development team. Even if they were not members of the software development team, they were actively involved in the process. Within C5, the UX expert was the pivot point for creating the interaction design. They actively involved a variety of stakeholders and pushed the user-centered thinking forward:
“Usually, with the stakeholders or directors, you are not really in direct contact with them. But for me, I developed a relationship with each of them [. . .] I made sure that they were more to date every week, [. . .] sometimes the developers get left out [. . .] so I made sure that the developers and the stakeholders were very involved in the design process.” (C5)
In addition to the availability of expert knowledge, we found an organizational structure that supports close interdisciplinary collaboration between different expert groups to be one of the key factors enabling usable security. In the above example (C5), the motivation to invest in a redesign of a security feature was based on past experiences with problems, i.e., customer complaints. Good usable security was thus the main driver for the project, and most stakeholders were aware that was the case. This participant also reported that user-centered processes were common in this company context: The team systematically examined the old application, and the problems users had with it. Therefore, the UX team was in continuous exchange with the development team to check which improvements were feasible. They conducted laboratory testing with real users to evaluate their design prototypes early. Moreover, they involved various experts from other teams like privacy experts or content designers to improve their product continuously. This is similar for the other four contexts in which we also observed that usability, including
898
Authorized licensed use limited to: IEEE Xplore. Downloaded on August 08, 2024 at 04:02:25 UTC from IEEE Xplore. Restrictions apply.

# C. No Usable Security Awareness, some User-centered Measures
Within this category, we found two contexts (C6, C7) that showed elements of a user-centered development culture – without concrete awareness of usable security concepts as such. Both participants reported that usability had high priority. One company developed and improved its product incrementally based on user feedback. Therefore, they had specific testing groups for usability and actively gathered feedback, recorded usability issues, and prioritized them in development. By contrast, security ranked lower in importance, and neither security experts were involved nor were security measures applied. Security features in the user interface were treated similarly to other features without additional effort:
“They were more concerned about usability. Like I said, they even made decisions which sort of decreases security, develop the product just so that it is more usable. [. . .] So, when we decide to go ahead with implementing a security feature, we then do not look at the original idea of the usability of it at all.” (C6)
For the other company, the customer explicitly requested security, and functional feature requests often included a security-relevant function (e. g., access control of cars). Still, their main focus was on usability. They did not involve designers and only brought in external security experts in certain development phases. Driven by specific customer requests, security mechanisms were adapted to customer needs (e. g., trying to make authentication as easy as possible for truck drivers). While their processes were user-centered, we found fundamental misconceptions about the interplay between security and usability (e. g., the trade-off myth). These misconceptions were present both in product descriptions given by the participants as well as in their direct statements:
“if we created an easy authentication method, I think its more likely to be vulnerable at some point, because usability cause security. . . security. . . don’t know, security risks. . . ” (C7)
# D. Usable Security Awareness, Little or no Follow-through
We observed that the development teams in six out of 23 contexts (C8–C13) may have been aware of usable security and may have even been interested or motivated to implement it. However, there were no supporting structures. All except one of these companies (C9) had dedicated security experts working on the projects, with a strong focus on security. One participant spoke of a “very strong security focus” (C10), and another said they “put security at the forefront, and privacy and data protection” (C8).

Only one of those companies (C11) had a designer or UX expert actively involved in the development process. In the other five contexts, design decisions were often made by developers and project leads. All participants reported that they followed an agile philosophy in their company. However, we found neither specific methods for evaluating usability nor dedicated measures for user research. Compared to the two previous categories, the interviewees did not report notable user-centered approaches. While some of them reported having tried some user-centered methods, they were used to a lesser extent. Two contexts, C8 and C10, however, had at least a public community of users. Nevertheless, compared to some of the companies described in Section IV-B who actively used their communities to request feedback, the relationship here can be described as more passive. However, participants were aware of concepts underlying usable security and sometimes even the terminology. Most attributed importance to usable security in their product but had not implemented mature measures for usable security in their processes. In the other companies in this category, designers or UX experts were not available. One participant of a medium-sized security company C13 described how they design interfaces themselves, because they were unable to hire an employee with skill sets in UX design and security:
“No, actually, we had for a very long time an open position for a UI/UX designer. . . but if you are looking for a UI/UX designer with additional qualification in the security environment. . . then, yes, you have to make one yourself.” (C13)
Other statements suggested that there is no need for a dedicated UX expert or designer:
“We are relatively small as a company and [. . .] don’t have a usability expert now, unfortunately. But mainly . . . , those are things that everyone has to learn themselves to a certain extent.” (C11)
We also observed that, unlike security, there were no specific requirements for usability. Usability was partly described as a handiwork of the developers:
“We give the developers a lot of freedom to design and implement features, so there are corporate design guidelines for colors and fonts and stuff like that, but interaction patterns and so on are more up to the developers themselves.” (C11)
Unlike the vague description of usability requirements, security was specified precisely. One participant told us that certification by a national office for software security means meeting concrete security requirements is a priority, even if this negatively affects usability. Other participants also mentioned that complying with security standards had an adverse impact on usability:
“So a thing, in general, is the interplay between security, especially in terms of approval, certification, and user experience, because I often find myself having to argue against a user experience thing because of some security thing, some box that has to be checked in order to get certification.” (C13)
# We discuss conflicts created by security compliance standards in Section IV-G4.

We made two key observations: Firstly, some participants considered their processes to be sufficient for achieving usable security. Secondly, some participants openly admitted that they did not know how to implement certain security requirements without compromising usability.