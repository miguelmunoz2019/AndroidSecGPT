USENIX Association 32nd USENIX Security Symposium 5473
# 6 Summary of Capabilities and Limitations
In this section, we described our framework to run mobile applications based on previous work and own additions to provide interaction capability. We are able to automatically download, install, run, interact with, collect traffic, and remove apps for both Android and iOS. Furthermore, we are able to extract and analyze displayed consent dialogs while monitoring transmitted traffic. However, our approach does come with limitations:
- Choice of System and Configuration: We leverage a rooted Galaxy A13 for Android and a jailbroken iPhone for iOS. Either method of gaining administrative access can be detected by apps potentially leading to different behavior as when run on a vanilla mobile phone, e.g., some banking apps are known to refuse running on a rooted device for security reasons while other apps might alter their data collection behavior. This does impact the amount of successful app analysis and might impact the observed traffic. Furthermore, despite leveraging SSL KillSwitch and Objection and installing our mitmproxy certificate on the phones, apps do deploy SSL certificate checking not affected by those measures. Consequently, not all requests can be successfully intercepted.

- Limited Interaction: We only interact with a detected consent dialog to either give or deny consent. This results in two measurements if both an unambiguous accept and a reject button are present. This limited interaction may lead to missed dialogs that appear later during app usage or otherwise missed transmission behavior that is triggered by user interaction.

- Wrong Dialogs/Violations Detection: Apps may contain text elements and buttons that indicate a dialog to our implementation but a human inspector would overturn such a verdict. We optimized our approach of dialog detection and analysis to rather miss a dialog if it is not clear cut. Due to this optimization, we may miss dialogs that could be detected using more lenient rules.

- Limited Legal Clarity: Our stated design requirements are based on our legal understanding of the sources we found. However, as always with legal matters, it is not always clear cut whether something is against the law or not and opposing opinions do exist. Consequently, every classification by our implementation, indicating some form of GDPR violation, should be treated as opinion rather than fact unless substantiated by a court of law.

Our methodology and consequently any analysis based on it has to account for those limitations. The first two limitations limit the apps and app traffic we are able to monitor and potentially reduce the amount of detected leaked information. The third limitation affects the amount of dialogs we are able to extract and analyze, thus, limits the result set. The last limitation reduces the amount of consent dialogs we are able to identify. Thus, our overall work and results are in favor of the applications we analyze as we consider a missing consent dialog and undetected personal information leakage less severe than detected ones.

# 7 Analyzed Consent Dialogs in Numbers
In the previous chapters, we discussed motivation (Section 3), and methodology (Section 6), as well as our initial static analysis on the popularity of CMPs (Section 5). Now we present the raw results obtained by our dynamic analysis of Android and iOS Apps. We start by performing a manual spotcheck of our results, then detail the numbers of detected dialogs, dialog types, and contained Dark Patterns. Afterwards, we present how data collection behavior of apps differs before and after agreeing or rejecting consent as well as our detection of TCF-related string properties set in apps.

We were able to analyze 3654 apps. On iOS we successfully analyzed 1520 apps (85%), whereas under Android we were able to successfully analyze 2134 apps (71%). An unsuccessful measurement can have different reasons. The most trivial reason is that an app refused to start or stops running at some point during the analysis. This behavior could be due to bugs or the app refusing to start, e.g., due to being run on a rooted/jailbroken device (ref. Section 6). The client of Appium running on the device was also observed to crash, leading to an unsuccessful and consequently missing measurement. Furthermore, Appium is not always able to extract elements or screenshots. Those Appium related limitations are not necessarily deterministic and it is possible that an App exhibits multiple failures across multiple measurements. Remember that we require multiple measurements to collect traffic and interact with a privacy consent dialog. An iOS specific limitation is the lack of a working jailbreak for the current version. Consequently, we are forced to work with iOS 14, and 169 (9%) required a more recent OS.

Each App exhibiting a measurement error is excluded from our analysis and, thus, incomplete measurements and missing elements or screenshots do not impact our results. However, this also means that we do not observe those apps data collection behavior or privacy consent dialogs, this might introduce
a measurement bias as we miss apps that, e.g., refuse to run on a rooted/jailbroken device.

# 7 Manual Validation of Results
Overall our results demonstrate that only a subset of apps display a dialog and even if they do display a dialog they leverage design choices to nudge a user towards consenting. To underline our results we perform a manual inspection of a subset of apps to understand the performance of both our taxonomy as well as our dialog design pattern detection. We inspected 500 apps concerning their taxonomy and 40 concerning the detected design choices.

For our manual inspection we use artifacts collected during our automated app analysis as Appium allows not only to take a screenshot of the whole app but also of individual elements. Thus, we are able to reconstruct the classification and interactions our measurement implementation did.

Overall the results demonstrate that our implementation is in favor of the app developer as we are under reporting the amount of privacy consent dialog and, thus, the amount of apps that are deploying hostile design patterns to nudge users towards giving consent. Furthermore, our analysis on why our implementation made mistakes shows that errors are due to technical limitations and side cases in phrasing or design choices that require a human to make a proper decision.

Finally, our manual inspection of detected dialogs confirmed our expectation of a broad spectrum of privacy consent dialogs. We encountered dialogs that contain short catch-all texts as well as extensive texts with explicit description of the legal basis for data collection.

# 7 Taxonomy
The manual inspection of initial app screens demonstrates that we are able to distinguish between our four different types of privacy consent dialog (None, Link, Notice, Dialog) and do not paint a worse picture than actually exists. We look at the initial display content of an app, i.e., the elements we are basing our taxonomy classification on and check, whether a human inspector would perform a similar judgement as our implementation. Finally, we also look for indicators that a consent dialog could be hidden behind initial privacy consent dialog unrelated interactions, but is not directly accessible to the user after the app is started.

The manual inspection revealed that our implementation is in favor of app developers as we are underreporting the amount of privacy consent dialogs with 53 apps displaying some stronger form of privacy consent dialog than detected by our implementation. Each app that does not have a privacy consent dialog is negligent in their approach towards user privacy whereas an app that uses Dark Patterns in their privacy consent dialogs could be considered malicious.

We also detected 9 privacy consent dialog apps that were displaying a weaker form of privacy consent dialog. However, only 3 of those relate to a proper privacy consent dialog being part of our design requirement analysis: We detected one dialog due to Appium extracting more than was visually displayed including multiple dialog associated keywords and button labels leading to the wrong classification. The identification of a link as a dialog was due to the unusual structure of the displayed app, dedicating a heading to a privacy link, leading to the wrong classification. Finally, the wrongful identification of a notice as a dialog was due to the app opening a keyboard including a dialog associated button label, leading to the wrong classification. In each case the technical detection of a dialog was correct, however, the context of the detection lead to a human inspector to overturn the classification. A summary of the taxonomy classification check are given in Table 2.

During our visual inspection, we detected 6 apps for which the display indicates that further interaction will lead to a consent dialog, either by saying so or due to an dialog partially hiding a privacy consent dialog. Those numbers show that further work on the open research question of in-depth app interaction is required. However, detecting those dialogs is out of scope for this work, as we are focusing on initially displayed consent dialogs.