Interestingly, we noticed that the structural information in the manifest documentation can help build domain-knowledge and identify sentence contexts. Specifically, (1) the omitted entities are often in a structure context. For example, there is a sentence in the documentation for <activity> ‘The name must be specified’, the omitted <activity> is exactly the name of the documentation. (2) The element and attribute names in the titles of each section (such as contained in) yields a dictionary as well as the structure of manifest-related entities, which can be used to build the domain knowledge and filter out the irrelevant and misplaced ones.

The Document Collector traverses the documentation pages by starting from the documentation page of the root element <manifest>, then recursively visiting the documentation pages of each child element.

# 4 DETAILED DESIGN
The workflow of ManiScope is shown in Figure 3. At a high level, it contains five key components: Document Collector (§4), Positional Constraint Extractor (§4), Quantitative Constraint Extractor (§4), Scheme Generator (§4), and finally Manifest Validator (§4). In this section, we present the detailed design of these components.

# 4 Document Collector
As described in C1, we need to automatically collect the documentations related to the manifest file, and extract the structured sections and descriptions for positional and quantitative constraint extraction, respectively. To avoid overly capturing the irrelevant elements and attributes when only using the structure of a document to determine whether it is related to an app manifest, we use a recursive top-down traversal algorithm to identify the attributes and elements related to manifest descriptions.

# Detecting and Measuring Misconfigured Manifests in Android Apps
CCS ’22, November 7–11, 2022, Los Angeles, CA, USA
# 4 Positional Constraint Extractor
Given the collected manifest documentation pages, our Positional Constraint Extractor parses each documentation page and extracts child elements under ‘can contain’ and ‘must contain’ sections and attributes under attributes sections, respectively. These child elements and attributes are used to construct positional constraints, i.e., valid child elements and attributes for each parent element. For example, when parsing the document example in Figure 4, there is an android:name in the attributes section; therefore, we infer that <action> can have a child attribute of android:name. We also infer that the <action> element has no child elements because there is neither ‘can contain’ nor ‘must contain’ sections in its documentation page. When all the positional constraints are extracted, the parser generates a dictionary of all of the names of valid elements and attributes, which is used for filtering out non-manifest related constraints that may be mistakenly identified by the NLP parser. In addition, the parser also extracts descriptions of elements under the descriptions section, and attributes under each attribute name, which are required to extract quantitative constraints as described next.

# 4 Quantitative Constraint Extractor
Since the quantitative constraints are located in descriptions, our Quantitative Constraint Extractor uses NLP techniques to extract these constraints from free-form sentences in the descriptions. However, these natural language sentences are usually ambiguous and incomplete. To deal with the challenges of complex sentences (C2) and improve extraction precision (C3), we design two sub-components: (1) Entity Recognizer (§4) to identify manifest entities (i.e., elements and attributes) and handle ambiguities, and (2) Constraint Filter (§4) to filter out non-manifest related constraints.

# 4 Entity Recognizer
As discussed in C2, to extract constraints from free-form sentences, we need to extract manifest entities, their relationships, and handle missing references. To illustrate these challenges, we present two sentences in Figure 5 with a normal voice (containing nsubj dependency) and a passive voice (containing nsubjpass dependency). The first sentence is written in normal voice, and it suggests that there is a minimum constraint for the child element <action> in the parent element <intent-filter>. We observe that these sentences often appear in Subject-Verb-Object structure. For instance, the subject phrase could be ‘An <intent-filter> element’, and the object phrase could be ‘one or more <action> elements’. Therefore, we can extract the parent and child entity from the subject phrase and child phrase, respectively. However, since these phrases still contain complex structures such as modifiers and conjectures, we still need to locate the exact word such as <intent-filter> from these phrases, and to handle sentences where object phrases are omitted (e.g., ‘The name must be specified’). To this end, we extract this information by first (𝑖) recognizing sentence dependencies using a Finite State Machine (FSM), then (𝑖𝑖) handling missing entities using contextual information.

# (I) Recognizing Sentence Dependencies
We observe that in sentences specifying manifest constraints, the parent and child manifest entity appear in subject and object phrases, respectively (e.g., the child element <action> is in the object phrase ‘one <action> element’). Therefore, our Entity Recognizer extracts the parent and child entity by identifying the dependencies of subject and object phrases.

# CCS ’22, November 7–11, 2022, Los Angeles, CA, USA
# Yuqing Yang et al.

# Rules to filter out non-manifest constraints
# Rules to identify misspelled elements and attributes
object phrases until it finds a manifest entity or aborts the parsing must be specified’ appears in the description of the android:name based on the FSM, according to the dependency encountered at each word. We first identify dependencies used in the extraction procedure, including subjects (nsubj, nsubjpass), direct objects (dobj), adjective and noun modifiers (amod, nmod), compound state- ments (compound), and determiners (det) such as the name of an element. We then process these dependencies using the FSM to trace dependencies and identify entities as shown in Figure 6.

In the following, we discuss how our FSM-based approach works using an example of extracting the parent element <intent-filter> from the first sentence in Figure 5. Specifically, as shown in Figure 6, starting at the state verb (points to the word ‘contain’ in the input as shown in Figure 5), our Entity Recognizer first moves to the noun state (points to word ‘element’) based on the state transition of nsubj. Next it moves to adjective state through amod and points to the word ‘<intent-filter>’. Since there are no more dependencies according to the parsed dependencies illustrated in Figure 5, the Entity Recognizer moves to a special identified state through the none edge. A none edge is a special edge where the state cannot be transferred. As such, when reaching the identified state, we successfully identify the word ‘<intent-filter>’ as a manifest entity. If there is no object phrase in the sentence (e.g., no object phrase after ‘specified’ in ‘The name must be specified’), the Entity Recognizer regards the corresponding entity as missing and holds its processing until more context information is collected, which will be handled in the next step. If the Entity Recognizer moves to the exit state without reaching the identified state, the tracing process aborts and no constraint is extracted from the sentence.

# Identifying Context Information
Due to the complexity and ambiguity of sentences, there is a chance where manifest-related constraint is not uncovered by our Entity Recognizer. In general, there are two scenarios where a sentence containing manifest constraints may be missed: 1) when the sentence has a missing entity that needs context information to be resolved (e.g., ‘The name must be specified’), and 2) when the identified word does not point to a specific manifest element or attribute (e.g., ‘this element must be placed inside the <manifest> element’). Therefore, we need to handle these incomplete and ambiguous manifest entities to avoid missing manifest constraints. To accomplish this, we notice that contextual information in documentation sections and paragraphs provide enough hints for inferring these missing entities.

# Section-level Context
Section-level context refers to information about element and attribute names associated with section titles in the documentation. For example, if the sentence ‘The name must be specified’ appears in the description of the android:name attribute in the documentation section for <activity>, we can associate it with the <activity> element as its attribute. When a parent entity is missing, we associate the parent entity with the element name in the title of documentation (because only elements can be parent entities that contain child elements or attributes). When a child entity is missing, we associate the entity with the nearest section context: if the sentence is in the description of an element, we associate the entity with the element name; if it is in an attribute description, we associate it with the attribute name.