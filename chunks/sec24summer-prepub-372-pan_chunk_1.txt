# Is It a Trap? A Large-scale Empirical Study And Comprehensive Assessment of Online Automated Privacy Policy Generators for Mobile Apps
# Shidong Pan∗ Dawen Zhang Mark Staples
# CSIRO’s Data61 & ANU CSIRO’s Data61 & ANU CSIRO’s Data61
# Zhenchang Xing Jieshan Chen Xiwei Xu Thong Hoang†
# CSIRO’s Data61 & ANU CSIRO’s Data61 CSIRO’s Data61 CSIRO’s Data61
# Abstract
Privacy regulations protect and promote the privacy of individuals by requiring mobile apps to provide a privacy policy that explains what personal information is collected and how these apps process this information. However, developers often do not have sufficient legal knowledge to create such privacy policies. Online Automated Privacy Policy Generators (APPGs) can create privacy policies, but their quality and other characteristics can vary. In this paper, we conduct the first large-scale empirical study and comprehensive assessment of APPGs for mobile apps. Specifically, we scrutinize 10 APPGs on multiple dimensions. We further perform the market penetration analysis by collecting 46,472 Android app privacy policies from Google Play, discovering that nearly 20% of privacy policies could be generated by existing APPGs. Lastly, we point out that generated policies in our study do not fully comply with GDPR, CCPA, or LGPD. In summary, app developers must carefully select and use the appropriate APPGs with careful consideration to avoid potential pitfalls.

# 1 Introduction
Mobile phones and apps are now a ubiquitous part of digital life. There is a large variety and volume of data collected and used by mobile apps, which inevitably brings many privacy issues . Privacy policies inform users about what, why, and how their personal data are collected and used. These privacy policies have become an important element of responsible technology in mobile app ecosystems. They also form part of legal agreements for apps and services. Specifically, they are required under regulation in many jurisdictions, such as European General Data Protection Regulation (GDPR) , California Consumer Privacy Act (CCPA) , Brazilian Law of General Data Protection (LGPD) , Australian Privacy Principles (APP) , and Chinese Personal Information Protection Law (PIPL) . For example, APP [Art. 1, §1] imposes an obligation on organisational entities to “have a clearly expressed and up-to-date APP Privacy Policy about how the entity manages personal information.” Privacy policies must be consistent with the data collected and functions provided by service providers, and inadequate policies can create significant business and legal problems.

Developing privacy policies is a complex process, demanding both the knowledge of app features and corresponding legal requirements. While larger companies have greater resources and legal expertise to create high-quality privacy policies for their apps, most (citizen) developers do not have legal support and struggle to prepare accurate privacy policies . To develop privacy policies, developers may copy-paste-modify existing privacy policies, ad-hoc. As part of this big picture, app development by non-professional developers is growing quickly, supported by trends of using no-code/low-code automated app development tools  and pre-trained Large Language Models (LLMs). To address these needs, Online Automated Privacy Policy Generators (APPGs) can provide more automated solutions and more systematic support for developers to create privacy policies for their apps, rather than through ad-hoc reuse. Figure 1 provides several illustrative examples. Most APPGs are questionnaire-based tools, which work by asking app developers a series of privacy-related questions about the app, and using those answers to generate privacy policies. APPGs can create privacy policies, but their quality and other characteristics can vary and are not yet deeply understood.

As we observe in this paper, many apps fail to provide a privacy policy, perfunctorily provide only a low-quality privacy policy, or provide a privacy policy not in local language. APPGs are becoming an increasingly popular solution used by developers, but developers can be unaware of hidden issues in APPGs . Potential design flaws may reflect in the policies, amplify vulnerabilities, violate users’ trust assumptions, and ultimately harm end-users. Thus, a comprehensive and systematic assessment of the capability and limitations of APPGs is necessary. To better understand the scale of potential issues...

# App Name
Please provide an App Name!
# 1. Contact Information
Email Address
# Personally Identifiable Information
Personally Identifiable Information you collect (comma separated)
# App Type
Select app type
# Mobile OS
Select mobile OS
# Policy Effective Date
05/06/2023
# Owner Type
Select owner type
# Examples of APPGs
(a) #1 Iubenda, UI-mode
(b) #2 App Privacy Policy Generator, questionnaire-mode
(c) #3 Termly, questionnaire-mode
(d) #10 Lawpath, document-mode
Potential problems and their broader impact, it is worthwhile to conduct a market penetration analysis on mainstream APPGs. Moreover, by scrutinizing the features of popular APPGs, we can glean insights into the demands and preferences of both the market and developers.

Numerous previous studies have analysed privacy policies  from various perspectives. However, the majority of existing compliance analyses in relation to privacy regulations lack fine-grained scrutiny of specific clauses and requirements. APPGs often claim the generated policies are compliant with privacy regulations. A more nuanced analysis that hones in on the specific requirements stipulated by privacy regulations is important for a deeper understanding of APPGs’ quality. Other issues relate to mobile apps’ dependence on device permissions, for instance, LOCATION and CAMERA, to function normally. Generally, we find users are more vigilant when directly providing personal information, but underestimate the impact brought by device permission requests, which when granted by a user allow apps to continuously collect critical personal information without further user approval or consent. Therefore, it is significant to examine whether developers correctly display the needed device permissions in the generated privacy policies with APPGs for mobile apps.

# Research Questions
To evaluate current APPGs and their use, we investigate the following research questions:
- RQ1: What APPGs exist for mobile apps? What are the differences between them? (Section 2)
- RQ2: How many mobile apps’ privacy policies could be generated by APPGs? Why are some APPGs more popular? (Section 3)
- RQ3: To what extent do APPGs comply with privacy regulations in terms of specific requirements, data rights, device permission disclosure, and self-integrity? (Section 4)
An overview of our methodology is shown in Figure 2. We first collected an initial set of APPGs. After removing duplicates and filtering out irrelevant results, we identified 10 APPGs for mobile apps as our research objects. We conducted an assessment on multiple dimensions, including their features and the recognition of the extent of data use. We then conducted a large-scale market penetration analysis. Based on a random sample of apps from the Google Play app store, we successfully downloaded 46,472 privacy policies (Crawled Privacy Policy Collection) as a large-scale dataset for mobile apps. We found that 15% of apps do not provide a privacy policy link, 22% of them are low-quality privacy policies, and 20% of these privacy policies fail to provide a privacy.

# Observed issues
# RQ1: APPGs evaluation
- Missing and unavailable privacy policies
- Low quality privacy policies
- Language non-localization
- Extent of data use
# Preprocess apps data
# Apps dataset
- Crawl apps from Google Play Store
- Remove apps without a privacy policy link
- Download privacy policies
# Privacy Policy Collection
# RQ2: Market penetration
- Fingerprint Keyword Searching
- Document Similarity Analysis
# RQ3: Privacy policy analysis
- Compliance against regulations
- Permission coverage analysis
- Contradiction analysis
# APPGs dataset
- Select APPGs applicable for mobile apps
- Design 3 synthetic apps
- Generate privacy policies for synthetic apps
policy in English, the first language in the target market. We then generated 30 privacy policies (Generated Privacy Policy Collection) using the 10 APPGs for three synthetic apps and conducted a market penetration analysis. Our results show 20% app developers favorably use APPGs to generate their privacy policies, and #2 App Privacy Policy Generator is the most popular one, boasting a 72% adoption rate. In an effort to more accurately assess compliance with privacy regulations, we scrutinized the generated privacy policies. Our findings revealed a substantial level of noncompliance with privacy laws and a frequent under-claiming of data rights and highly concerning privacy practices, especially the most popular #2. In addition, our results suggest dangerous permissions are commonly missing in the generated policies of APPGs, and inappropriate APPGs selection will hinder developers’ capacity to include essential device permissions. Furthermore, we found that APPGs might introduce more privacy policy contradiction issues, undermining the self-integrity.

# Contributions
To our knowledge, this is the first large-scale, exhaustive empirical study of automated privacy policy generators for mobile apps. Our observations, findings, and insights will benefit stakeholders beyond just app developers, including APPG providers and privacy regulators from the APPG design perspective and legal perspective. We make the following contributions:
- We perform a systematic empirical analysis of Automated Privacy Policy Generators (APPGs), covering various aspects, such as features, characterizations, and levels of recognition of data use.

- We conduct a systematic analysis of the privacy policies of 99,149 apps in the Google Play Store. Specifically, our dataset includes 46,472 privacy policies extracted from these apps and available at.