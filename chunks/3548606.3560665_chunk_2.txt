3. We identify 2887/12,598 (22%) apps use custom encryption/decryption for network transmission and storing content in the shared device storage; 2383/2887 (82%) of them transmit the on-device information that is commonly used for user tracking (e.g., advertising ID, router SSID, device email, list of the installed apps). More importantly, for at least one on-device info item, 2156/2383 (90%) of the apps send it only under custom encryption to at least one host, and 1719/2383 (72%) apps send it only under custom encryption. All these serious privacy leakages would be missed by existing analysis tools.

4. Besides privacy leakage, we also identify that the use of custom encryption channels can seriously undermine data security, e.g., due to the use of fixed keys, insecure cryptographic parameters and weak/broken cipher algorithms (e.g., RC4, DES). 299 apps transmit their insecure encrypted content over plain HTTP and non-HTTP protocols. In addition, we identified 22 apps that perform their authentication over a secure channel (HTTPS) and then expose their authentication token over an insecure channel (HTTP and non-HTTP). All these security issues enable a network adversary to read (even modify) sensitive plaintext information from encrypted traffic (e.g., using extracted fixed keys or breaking weak ciphers/keys).

5. We also identify security and privacy issues beyond custom encrypted channels. For example, we found that 102 apps transmit their neighbor’s wireless SSIDs to possibly track nearby users and their locations; 202 apps collect/share the Android dummy0 interface information (not protected by runtime/special permissions) that can be used for user tracking; 26 apps appear to allow UDP amplification, which can possibly be exploited in DDoS attacks.

6. Besides app servers, tracking domains also receive various on-device information via non-standard channels. For example, apps-flyer.com may receive (depending on the app that includes the appsflayer SDK) items such as WiFi ESSID, WiFi MAC, operator, device email, build fingerprint, ad ID, and device ID, from 1386 of our tested apps with cumulative installations of over 24 billions.

We will open source our tool at: https://github.com/SajjadPourali/ThirdEye. We notified Google about the major privacy issues that we observed. We also contacted developers of 47 apps with significant security risks.

# 2 THREAT MODEL
As we explore security issues due to the use of non-standard communication and custom encryption besides privacy exposure, here
# Hidden in Plain Sight: Exploring Encrypted Channels in Android Apps
# CCS ’22, November 7–11, 2022, Los Angeles, CA, USA
we also provide our threat model with different types of attackers, their capabilities, and goals. We exclude attacks that require compromising a user device or an app server. The attacks also do not involve other parties in the Android ecosystem such as device OEM providers, app developers, and app stores. The attacker cannot break modern crypto primitives, except when a key is exposed, or when a weak primitive is used—e.g., the attacker can brute-force a DES key, but not an AES-128 key (unless, e.g., a fixed AES key embedded in the app is used). The attacker can also monitor app behaviors on her own device (e.g., function hooking in a rooted phone), unless the app deploys active anti-analysis techniques that cannot be easily bypassed.

# On-path network attacker
This adversary has full access to the network communication between an app user and an app server, and can decrypt the encrypted content of network traffic, if insecure cryptographic keys (e.g., fixed keys extracted from an app), and weak algorithms (e.g., DES) are used. Such decryption will directly allow the adversary to access privacy-sensitive user information. The adversary may also get access to authentication tokens (if present) from such network traffic, which may lead to session hijacking and account takeover attacks.

# Co-located app attacker
This adversary has a regular app installed on the victim user’s device. With such co-located malicious apps, the attacker can access shared encrypted files saved by other apps on the same device, and decrypt such content, if insecure cryptographic keys or weak algorithms are used for encryption. This decryption may also expose a user’s private data.

# Device-owner attacker
In this case, we treat the device owner as the attacker, who would like to access protected (e.g., under custom Android encryption) service provider-content saved or processed on the device itself. This access may allow the attacker e.g., free access to Android device VPN premium/paid services from the app provider.

# 3 SYSTEM DESIGN
In this section, we provide our design details; see Figure 1 for an overview. To determine privacy and security issues resulting from non-standard and covert channels in apps, we leverage network traffic captured from communication channels (HTTP/HTTPS and non-HTTP protocols), and cryptographic API parameters, and file operations during app execution. Our methodology requires rooted Android devices, and consists of four main modules: the device manager controls test devices and ensures that test prerequisites are satisfied; the UI interactor traverses and interacts with app menus to maximize code coverage; the operations logger locates cryptographic APIs, instruments cryptographic API parameters, and captures network traffic, extracts file operations; and the data flow inspector processes data flows to detect privacy and security issues.

# 3 Device manager
As part of setting up the prerequisites, the device manager initiates a connection between the test desktop and Android devices through ADB, and ensures that the devices are connected to the Internet. If the connection through ADB is successful, we uninstall all non-system apps (e.g., YouTube, Google Chrome) except our helper app that fixes the GPS location, and prepare the device(s) for orchestration.

# 3 UI interactor
During app execution, the UI interactor interacts with the app to increase the code coverage. We ensure that the target app is running in the foreground, and then explore and find different UI elements (including buttons, inputs, check-boxes) and interact with them. To find inputs/clickable UI elements, we use a predefined keyword list in English. To accommodate UI elements with non-English labels, we use the googletrans Python module to translate the labels into English. We then populate the input fields (if any) using.

# CCS ’22, November 7–11, 2022, Los Angeles, CA, USA
# Sajjad Pourali, Nayanamana Samarasinghe, & Mohammad Mannan
a predefined list of inputs, and trigger the clickable UI elements based on the priority of a clickable element, which is determined based on its position in the list of keywords (e.g., the keyword of not now has a higher priority than click). After each click, we add the clicked element to a list to avoid redundant actions. Clicking on an element may open new activities or trigger actions, and we follow the same steps for those new activities until all elements in the foreground app UI are explored. The back button is clicked to go to the previous UI window (also used to avoid pop-up advertisements and in-app purchase windows). We also identify and utilize the sign-up/sign-in functionalities to login to apps, e.g., by first using our Google test sign-in credentials in supported apps, and then creating an app-specific account (if possible); see Sec. 4 for details.

# 3 Operations logger
Apps may use socket APIs to communicate through non-HTTP channels in the transport layer and above (i.e., over TCP/UDP). We use tcpdump  to store all network traffic in pcap files, and thus, capture both HTTP and non-HTTP flows. We also log network tuples by hooking relevant APIs using Frida, to capture app specific network communication over sockets. For detecting covert channels and misuses in shared storage, we hook open and move file API methods, to detect files that are opened/moved during an app’s execution; we save these files for further analysis. We use mitmproxy to capture/decrypt HTTPS traffic. The tcpdump data (not limited to HTTP/HTTPS) along with mitmproxy traffic obtained during network instrumentation is used to identify non-HTTP traffic.

For cryptographic instrumentation, we capture (through Frida API hooking) API parameters used in cryptographic operations: plaintext, ciphertext, keys, initialization vectors (IVs), and cipher algorithms. To extract the parameters of Android SDK API, we hook init(), update() and doFinal() API methods (of javax.crypto.Cipher API ); note that getIV() and getAlgorithm() methods are called by the init() hook. We define a non-SDK API as a third-party library used in an app, or a custom functionality implemented in an app that is not part of the Android SDK. Currently, we do not specifically handle obfuscated non-SDK APIs; we look for encrypt and decrypt strings in method names to identify non-SDK APIs, and such keywords matching will not work with all obfuscated code. If we find that an app uses encrypted/covert channels, we test the app on two separate devices, to identify fixed cryptographic keys used by the app. We label a cryptographic key as fixed, when the same key value is returned from multiple runs of the instrumentation (on the same device and on different devices).