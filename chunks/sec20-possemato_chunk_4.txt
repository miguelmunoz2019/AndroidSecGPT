# 5 Dataset Exploration & Weaknesses
Methodology. After extracting the policies from the apps, we first perform clustering to highlight common patterns and whether two or more apps share the same exact policy (or specific portions of it). In particular, we group two policies in the same cluster if they contain the same nodes, attributes, and values, in any order. This approach also helps us to determine whether apps developers “copied” policies from known developer websites, such as StackOverflow. We then analyze the clusters to identify peculiar configurations or weaknesses. Once an interesting configuration has been identified, we then proceed by performing queries on the entire dataset (that is, inter-cluster) to measure how common this specific aspect of the configuration is and whether it affects many apps. We then performed an additional analysis step, which is based on similar clustering techniques, but performed over a normalized dataset. We refer to a policy as “normalized” after we remove artifacts that are clearly specific to an app. We replace all the concrete values of domains with the value URL, all certificate hashes with HASH, and all the expiration dates with DATE. The rationale behind this normalization step is to be able to group policies “by semantics,” which is not affected when some specific concrete values differ.

Overview. One of the first insights is that, even though the NSP was firstly introduced in Android 6 in 2015, we note how 109,087 of the apps do not implement any policy (in either of the two forms). Of the remaining 16,332 apps that do implement a policy, 7,605 of them (6% of the total) adopt the original version of the policy (available in Android 6), while 8,727 (6%) adopt the new, more expressive policy format (available in Android 7). Our dataset is distributed as follows: 0% of the apps (83) target API level 29, 75% (12,261) API level 28, 11% (1,803) API level 27, 12% (2,077) API level 26, and the remaining 0% (108) target API level 25 or lower. The first clustering process creates in total 271 clusters (where a cluster is formed by at least two apps): these clusters group 7,184 apps out of the 8,727 apps defining the policy—the remaining 1,543 policies were unique and did not fit any cluster. The clustering process on the normalized dataset, instead, generates 170 clusters, this time with only 311 applications not belonging to any group. The remainder of this section discusses several interesting insights and common patterns.

Cleartext. Among the generated clusters, one is particularly big: it is formed by 1,595 apps. All these apps share the trivial policy of “allowing cleartext globally.” The exact same configuration is also used by other 2,016 apps belonging to 60 different clusters. Among the apps not belonging to any cluster, this configuration is used by 199 of them. Thus, in total, 4,174 apps of our dataset allow cleartext for the entire app. We then investigated how many apps opted out from cleartext and we found that only 156 apps block cleartext for the entire app. Then, we considered also apps using the first version of the policy since it also allows a developer to fully opt-in, or opt-out, from cleartext. Among the 7,605 apps using the first version of the policy, 97% (7,416) of them allow cleartext protocols, while only the 2% (189) opted out from them. As previously discussed in Section 3, the cleartext attribute can also be enabled by default if an app is targeting an API level lower or equal to 27 and it does not override it. By considering also the default settings, the numbers are even more worrisome. We noticed that among the 16,332 apps with a NSP, the 84% of them (13,847) allow the usage of cleartext protocols. The 12% (1,837) of them enable cleartext due to the default configuration not being overridden. To conclude, only the 1% (170) opt-out from cleartext just for a specific subset of domains.

348 29th USENIX Security Symposium USENIX Association
The figure shows the CDF of the number of domains defined within policies. Note how 62% of the apps do not define a custom policy for any domain. The 21% of the apps define exactly one domain, while the 8% specifies up to 2 domains within the policy. Note that the CDF has a long tail, with several apps defining more than 30 domains within the same policy, and two apps specifying 368 and 426 policies.

# Domains
We then proceed by looking at apps using the cleartext attribute on an explicit list of domains (using the domain node). We identified only 2,891 apps allow cleartext for a subset of domain while only 219 force the domain in the list to be reached only securely. Figure 1 shows the cumulative distribution function (CDF) of the number of domains defined within policies. In general, most apps (∼ 95%) specify custom policies for at most three domain names.

# Policy for 127
We then looked at clusters of more complex policies, in terms of nodes and attributes, and we noticed some interesting patterns. We identify how 492 apps configure a veryspecificdomain-config node for the IP address 127, localhost. Even if this policy does not introduce any security vulnerability and should be considered as a safe policy, we found it interesting: while it may be common practice to spawn a local server, it is very uncommon that all the 492 apps define the same policy for localhost. This configuration, however, is very common among other apps: in total, we identify other 512 apps belonging to 43 different clusters having the same domain-config setup, and 109 apps not belonging to any cluster. Thus, this specific domain configuration is used by 1,113 apps. We then set out to pinpoint the underlying source of this policy, and we eventually determined that this policy is defined by the Audience Network Android SDK, the Facebook advertisement framework. In particular, we noticed how a developer who wants to use this library must modify the policy to include this specific configuration to avoid unintended behavior. The official library’s documentation makes clear that this modification is mandatory due to the internals of the library itself. This finding opens a scenario that is different than the simple “developers copy policies”: in this case, an advertisement library explicitly requested the developer to modify her policy to make the library work. We suspected that this pattern could be common to many other advertisement libraries. Unfortunately, our suspicion proved to be correct: we identified several ad libraries that explicitly request developers to copy-paste a given policy. Moreover, we found how the ad libraries’ documentations often attempt to convince developers by including misleading and/or inaccurate arguments, and how many of such policies’ modifications actually negatively affect the overall security of the entire app. We postpone an in-depth discussion of these findings to the next section (Section 6).

# Trusted Certificates
Another interesting cluster is formed by 427 apps, which use a trust-anchors node for the entire app to trust the union of System and User CAs. As previously discussed, this configuration might allow, under specific circumstances, to perform a MITM over SSL/TLS connections (see Threat Model 3). Nonetheless, we notice how this specific configuration is shared among other 1,083 apps, 600 of which belong to 24 different clusters. We then investigate how many apps use the same configuration for a subset of domains ending up identifying 73 apps: thus, in total, we identified 1,159 apps adopting this configuration, among which 1,038 of them allow their SSL/TLS traffic to be potentially intercepted.