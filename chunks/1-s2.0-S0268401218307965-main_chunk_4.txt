In addition to prior privacy experience, computer anxiety, and perceived control, we propose app permission concerns as an antecedent of MUIPC. In a recent study by Gu et al. (2017), two factors related to app permission requests have been found to have a significant impact on information privacy concerns: (1) permission sensitivity in terms of the risk level of app permission requests (for example, “access to the vibrator” as a low-risk permission request, and “access to location information” as a high-risk permission request), and (2) permission justification regarding how collected information is used (for example, the justification for “access to the vibrator” is to “remind users when there is a new announcement”). While permission sensitivity and justification relate to distinct characteristics and designated purposes of app permission requests, in our study we focus on app permission requests that relate to the growing collection of personal information through mobile apps per se, which can result in the excessive collection of data and lead to information privacy concerns. Excessive app permission requests that “go beyond the necessary function of the app” (Harris et al., 2016, p. 445) are considered to be less likely accepted by mobile users due to privacy concerns about their personal information (Chin, Harris, & Brookshire, 2018). For example, it has been reported that more than 100,000 apps in Google’s Play Store collected mobile users’ data that was not consistent with their stated functions such as unnecessary location tracking or excessive access to contact lists . We integrate app permission concerns in our research model for two reasons: first, in order to measure the impact of app permission concerns on MUIPC regardless of whether mobile users perceive permission requests to be sensitive or justified; and second, in order to compare app permission concerns to other privacy-related antecedents, i.e., prior privacy experience, computer anxiety, and perceived control. We hypothesize that growing concerns for app permission requests will lead to an increase of users’ overall discomfort about their privacy. Thus, we propose the following hypothesis:
# H4. App permission concerns positively influence mobile users’ information privacy concerns.

Finally, following Wottrich et al.’s (2018) recent findings, we expect that a higher degree of privacy concerns will lead to the outcome that requested app permissions will be less likely accepted. We further base the hypothesis of the effect of privacy concerns on intention on numerous other studies (for example, Gu et al., 2017; Osatuyi, 2015; Smith et al., 1996; Stewart & Segars, 2002; Xu, Gupta et al., 2012). It is suggested that “individuals with higher levels of concern about information privacy practices may be more likely in the future to refuse to participate in activities that require the provision of personal information” (Smith et al., 1996, p. 187). We reason that as privacy concerns increase, users will less likely intent to accept app permissions, which will eventually lead to a decline to install an app. Since app permission acceptance usually involves the provision of personal information, we present the following hypothesis:
# H5. Mobile users’ information privacy concerns negatively influence the intention to accept app permissions.

Since we are not actually measuring an action, we refer to one well-known theory, the Theory of Reasoned Action (TRA) (Ajzen & Fishbein, 1980), which explains that one’s intention to act actually leads to an action. Numerous studies have demonstrated this relationship in prior research including several studies in an information privacy context (Belanger & Crossler, 2019; Keith, Thompson, Hale, & Greer, 2012; Lowry, Cao, & Everard, 2011; Pavlou, Liang, & Xue, 2007; Wang & Herrando, 2019). Hence, we presume that with increasing intentions, there will be a growth of users’ actual acceptance of app permissions.

# 4. Research design and measurements
To test the proposed hypotheses, we designed an online survey and recruited participants from an online social networking website. Due to accessibility, we targeted participants from the United States. We offered incentives in the form of three $50 Amazon gift cards, and participation in the survey was completely voluntary. In survey methodology, it is common practice to offer incentives in exchange for survey participation . We recruited participants by posting announcements, which provided background information about the study. To reduce bias possibility regarding self-selection among survey respondents, we did not disclose in the announcements that privacy concerns were the focus of our study. In the announcements, we asked participants to give their opinion about a mobile social networking app. The subjects could easily participate by using the URL provided in the posting. A total of 918 subjects participated, with 775 producing usable data. Of the 775 participants, 68% were female, 39% were below 20 years and 36% were between 21 and 30 years. Most of the participants were from Georgia (7%), Pennsylvania (6%), and Texas (4%), 59% were students and 25% were employed, and mainly used Android (31%) or iOS (66%). A complete list of participant profiles is provided in Appendix A.

For the operationalization of the latent variables of our research model, we measured the core constructs using reflective multiple-item scales, drawn from pre-validated measures where possible. For the antecedents, we measured prior privacy experience with items adapted from Xu, Gupta et al. (2012) using a 7-point rating scale, which ranged from “not at all” to “very often”. Computer anxiety was measured with a 7-point Likert scale from “strongly disagree” to “strongly agree” adapted from Stewart and Segars (2002), and perceived control with a 7-point rating scale from “no control” to “full control” adapted from Xu, Teo et al. (2012). To measure app permission concerns, we used a 7-point Likert scale ranging from “strongly disagree” to “strongly agree”, which we adapted from Smith et al. (1996) who originally used the scale in a context where companies collected personal information from individuals. Their items were adapted to our mobile user context, more specifically, to our context where mobile users are requested to accept or decline app permissions. In order to allow participants to make sense of app permissions being requested, we presented a scenario in which a hypothetical social networking app required access to various types of information, of which three most common app permissions were presented: location, contacts, and photos. The scenario is provided in Appendix B. For the MUIPC construct, we used 7-point Likert scales ranging from “strongly disagree” to “strongly agree” for the dimensions of perceived surveillance (adapted from Xu, Gupta et al., 2012), perceived intrusion (Xu, Dinev, Smith, & Hart, 2008), and secondary use of personal information . For the outcomes, we measured intention to accept app permissions using a 7-point semantic differential scale with items adapted from Malhotra et al. (2004), who originally used the scale in an Internet user context. The survey instrument is provided in Appendix C.

# 5. Data analysis and results
We conducted partial least squares structural equation modeling (PLS-SEM) with SmartPLS to analyze the collected data. All indicators were modeled as being reflective of their respective constructs. The measurement items loaded between 0 and 0 on their respective constructs, therefore exceeding the recommended threshold of 0 (Hair, Hult, Ringle, & Sarstedt, 2017) and the minimum criteria of 0 , thus demonstrating adequate indicator reliability and convergent validity. The internal consistency of the scales showed composite reliability (CR) ranging from 0 to 0, and Cronbach’s
# K. Degirmenci
# International Journal of Information Management 50 (2020) 261–272
Convergent validity of measurement model.

Notes: PPE = Prior privacy experience, CA = Computer anxiety, PC = Perceived control, APC = App permission concerns, PS = Perceived surveillance, PI = Perceived intrusion, SU = Secondary use of personal information, INT = Intention to accept app permissions.

Latent variable correlation matrix.

Notes: PPE = Prior privacy experience, CA = Computer anxiety, PC = Perceived control, APC = App permission concerns, PS = Perceived surveillance, PI = Perceived intrusion, SU = Secondary use of personal information, INT = Intention to accept app permissions; value on the diagonal (bold) is the square root of average variance extracted (AVE).

alpha ranging from 0 to 0, which were exceeding the recommended value for construct reliability of at least 0 , thus meeting criteria for internal consistency. Average variance extracted (AVE) ranged from 0 to 0, exceeding the recommended lower limit of 0 and thus indicating convergent validity (Fornell & Larcker, 1981). Table 1 provides an overview of the convergent validity of the measurement model.

For discriminant validity (Fornell & Larcker, 1981), we analyzed loadings and cross loadings of the measurement model (see Table 2). All items loaded higher on their constructs than any other constructs and the differences were greater than 0.

We further assessed discriminant validity in a latent variable correlation matrix (see Table 3). The square root of the AVE for each construct was larger than the correlation of the construct with any other constructs in the model, which demonstrated discriminant validity (Fornell & Larcker, 1981).