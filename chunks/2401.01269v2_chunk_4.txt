# 6 DICUSSION AND FUTURE WORK
The field of leveraging Large Language Models (LLMs) to enhance Software Engineering tools and improve our understanding of large projects is a very active research area. There are numerous parameters and processes that can be optimized based on the specific functionality desired. We explore a basic prompting strategies for LLB however a more structured pipeline with multiple agents could significantly improve the performance of LLB as an analyzer. We also wish to highlight that each vulnerability we scan for is considered as a single scanner and there is clear value to exploring making this process less resource intensive by sharing information between scanners and choosing which ones to run based on the type of codebase and artifacts present within it.

We also wish to compare the results with those obtained from existing approaches in an empirical study. While our current framework does not integrate static analysis, we acknowledge its potential value and are considering its incorporation in future iterations. Overarching the entire methodology is a constant focus on improving software vulnerability identification, reducing false positive rates, and streamlining the process of enhancing Android app security. We believe our study serves as a basis to attempts to merge state-of-the-art language models with static analysis, potentially establishing a more reliable, accurate, and efficient android vulnerability detection approach. “What existing tools and code level analysis results can be supplied to the LLM to take a more informed decision?” remains an open question.

The results of the LLB case study on vuldroid highlights a shortcoming in the current implementation. This can be easily handled by indexing the code into a vector database and allowing vector search and retrieval to identify relevant files rather than building outwards from a set of files. Further summaries were not incorporated in the LLB package due to their tendency to induce hallucinations in the report. We plan to address this by increasing our granularity to a file level and incorporating critique mechanisms like have been employed in recent works in other domains that attempt to leverage LLMs.

# 7 THREATS TO VALIDITY
Prompt engineering, while a powerful tool to guide LLMs, is also subject to limitations. The effectiveness of prompt engineering is heavily reliant on the skill and experience of the user. Poorly designed prompts can lead to suboptimal results, as the model’s responses are only as good as the questions posed. There’s also the risk of introducing bias through prompts, which can skew the model’s focus and potentially overlook certain types of vulnerabilities.

A point which we highlighted earlier is about leaking semantic information about the class of the problem due to artifacts in the code. We replace keywords to clean our data but there could be implicit data that leaks this information to the LLM which we might not have accounted for in our analysis. Further capability of LLMs is very diverse with some performing drastically different compared to others. While we set seeds to ensure replicability of our results these can vary drastically over time.

# CS858, Project Proposal, LLbezpeky
Noble Saji Mathews, Yelizaveta Brus, Yousra Aafer, Meiyappan Nagappan, and Shane McIntosh
Another concern is the dynamic nature of both Android platform and cybersecurity threats. As Android continuously evolves, new types of vulnerabilities emerge, which may not be immediately recognized by an LLM trained on outdated data. Similarly, cyber threats are constantly evolving, with attackers devising new methods to exploit systems. This requires continuous updates and retraining of the LLM, which can be resource-intensive.

# 8 CONCLUSION
In our research, we explore the utilization of Large Language Models (LLMs) for detecting Android vulnerabilities. We successfully demonstrate the power of LLMs for Android Vulnerability detection and remediation. Our experiments using Prompt Engineering on the Ghera Vulnerability Dataset show promising results and bring up new and interesting directions which can be explored towards improving the efficacy of such systems. Further, we utilize the results and insights from our experiments to create a highly configurable python package that allows easy modification of the LLM being used as the reasoning engine and also supports extension to multi-agent architectures. In terms of the questions we set out to answer, it is clear that LLMs are incredibly powerful tools that can revolutionize Software Engineering tools as we know them, but it is also clear that they do not work magic out of the box and clearly require work in terms of drafting and structuring a better analysis pipeline architecture and optimizing the context available to the LLM.

# 9 ACKNOWLEDGEMENTS
This project report is a part of the course CS858 at the University of Waterloo. I express my sincere gratitude to my course instructor, Yousra Aafer, for her invaluable guidance and support throughout this project. Her expertise and insights have been fundamental in shaping the research and its outcomes.

I would also like to extend my thanks to my supervisors, Meiyappan Nagappan and Shane McIntosh. Their input and feedback have been instrumental in refining the research methodologies and enhancing the overall quality of this work. Their perspectives and suggestions have greatly contributed to the depth and rigor of the research.

I am thankful for the collaborative environment provided by the University of Waterloo, which has been conducive to academic exploration and innovation. The resources and support offered by the university have played a crucial role in the successful completion of this project.

Lastly, I appreciate the efforts of all those who have directly or indirectly contributed to this research, including my peers for their constructive criticisms and the university staff for their administrative support..