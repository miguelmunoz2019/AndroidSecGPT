Another threat in this category is represented by the presence of abandoned apps, which might have influenced the achieved results. Detecting abandoned apps represents a difficult problem, especially because it is hard to distinguish these apps from those that have completed their features and do not require further maintenance ; more importantly, while some identification heuristics have been proposed so far, none of them are fully tested and reliable (Khondhu et al. 2013; Coelho and Valente 2017). This is the reason why we did not consider this aspect in our study. However, the large scale nature of our empirical study substantially increased the ecological validity of our results. Moreover, our dataset is mostly composed of real-world apps that are active on the GOOGLE PLAY store . As a consequence, we reduced the likelihood to consider abandoned apps. In other words, while we cannot exclude the presence of abandoned apps in our dataset, their influence on the results are limited by the size of the empirical study.

In RQ 2 there might have been other factors related to the success of the apps presenting the update patterns investigated as well as other factors influencing the trends followed to update libraries, e.g. size or activity of the considered projects. However, our large-scale analysis mitigates interpretation bias, as it enables a good ecological validity of the results.

# External Validity
Threats to external validity concern the generalization of results. Part of the 2752 apps that compose our framework, is coming from the F-DROID repository. The set of 291 apps represents a 95% statistically significant stratified sample with a 5% confidence interval of the 1181 apps, available at the time of mining on F-DROID, having more than 1 third-party library. Despite this, we are aware that we considered Android open-source apps.

only. Commercial apps, as well as the apps coming from other distribution platforms should be analyzed to corroborate our findings. Finally, in our survey study (RQ3 and RQ 3), we collected opinions from 73 mobile developers of the considered apps. While this number cannot ensure the generalization of our findings, we still believe that the considered answers provide a valuable source to understand what developers think about third-party libraries. However, also in this case, further replications would be desirable.

# 5 Related Work
The phenomenon of third-party libraries version changes (i.e., change propagation or ripple effect) is a topic that has been studied in the context of both desktop applications (Dig and Johnson 2006; Mileva et al. 2009; L¨ammel et al. 2011; Robbes et al. 2012; Raemaekers et al. 2012; Bauer et al. 2012) and mobile apps (Linares-V´asquez et al. 2014, Mojica Ruiz et al. 2012, 2014; Martin et al. 2017). At the same time, the research community devoted effort in understanding the effects of updates on non-functional attributes of source code (e.g., fault-proneness Linares-V´asquez et al. 2013).

# 5 Third-Party Libraries Usage in Mobile Apps
Mobile apps differ from traditionally studied applications (Minelli and Lanza 2013b; Syer et al. 2013). Thus, most of the previous empirical studies conducted on third-party libraries in desktop applications usage have been revised.

Linares-V´asquez et al. (2014) decompiled and analyzed 24379 Android Application Packages (APKs) from the Google Play Store, discovering that in 82% of the cases third-party libraries were used. Mojica Ruiz et al. (2012) studied code reuse in 4323 Android apps extracted from 5 categories of the Google Play Store, finding that 61% of all classes in each category of mobile apps occur in 2 or more apps, and 217 mobile apps are reused completely by another mobile app in the same category. Their study was extended  by considering 208601 apps, confirming the previous findings. Similar results were obtained by Minelli and Lanza (2013a, b) and Viennot et al. (2014). Our study builds on the line of research investigated in the aforementioned studies and extends the empirical knowledge of the research community on how and why mobile developers update third-party libraries: besides assessing the extent of their usage, we also conduct further experiments to understand what are the typical update patterns used by developers and the reasons behind the decisions of updating (or not) a third-party library.

Azad (2015) proposed a new tool able to analyze the APIs usage and suggest similar APIs based on STACK OVERFLOW discussions. Borges and Valente (2015) applied association rule mining to learn an API usage model. To this aim, they extended APIMINER  to collect usage patterns and APIs documentation and validated the obtained patterns. Backes et al. (2016) proposed a library detection technique that is resilient against common code obfuscation techniques and that is capable to identify the library version used in apps. While this set of papers proposed techniques to support developers when dealing with third-party library, our study presents empirical results that can be exploited by such techniques to provide developers with improved recommendations: for instance, the findings on the libraries that are more/less prone to be updated can lead to the definition of novel prioritization techniques that recommend APIs usage and update.

# 5 Effects of Third-Party Libraries on Mobile Apps
Linares-Vásquez et al. (2013) analyzed the effect of the change- and fault-proneness of Google APIs on the commercial success of mobile apps, discovering that apps having low ratings tend to use change- and fault-prone APIs. Such correlation has been confirmed by 45 Android developers . According to these findings, Linares-Vásquez (2014) proposed an API recommendation system able to avoid the introduction of defects. Tian et al. (2015) extracted APIs information and evaluated 1492 apps in terms of 28 factors along eight dimensions to understand how high-rated apps are different from low-rated apps. They found that size, number of images included in the web store page, and target SDK version are the most influential factors. Third party libraries also impact the apps security. Dering and McDaniel (2014) analyzed libraries and permissions of 450000 free apps, finding a strong correlation between the number of external libraries used in the apps and the number of requested permissions. Derr et al. (2017) performed an empirical study on third-party library updatability over 1264118 Android applications: the main result of their study highlighted that (i) most of the libraries can be upgraded without modifying the source code, and (ii) almost 98% of actively used library versions affected by a security vulnerability can be fixed with a library update. Our study enhances the state of the art in this direction by providing a preliminary evidence of the impact of third-party library updates on the commercial success of mobile applications. As such, our findings are complementary with respect to those reported so far.

Seneviratne et al. (2015) analyzed the differences between free and paid apps. They discovered that both free and paid apps collect personal information. Moreover, the authors showed that 20% of the apps were connected to more than three trackers, and that 50% of users are exposed to 25% trackers. The analysis of the libraries history of the top apps on Google Play Store is part of the work by Backes et al. (2016). Their results showed that app developers slowly adapt new library versions, exposing their end-users to large windows of vulnerability. Finally, Mojica Ruiz et al. (2016) focused their attention on the impact of library version changes on development effort. The results showed that almost half of the apps underwent the ads library. Also in this case, our results confirm some of the observations reported in previous studies. For example, we have observed that one reason leading developers not to update libraries is excessive refactoring effort, as shown by Mojica Ruiz et al. (2016); similarly, our findings on technical lag are perfectly in line with those reported by Backes et al. (2016).