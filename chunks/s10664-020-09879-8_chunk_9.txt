We then performed anomalies identification, which basically checks if the identified reachable privileged APIs are common or anomalous according to the permission re-delegation model. PREV detected that in 324 apps, the reachable privileged APIs are common according to the permission re-delegation model and therefore, they were classified as safe. The remaining 77 apps were classified as candidate vulnerable apps because the reachable APIs in those apps are anomalous. These candidate vulnerable apps were then subject to the test case generation phase of PREV, to automatically generate proof-of-concept attacks. PREV successfully generated attacks for 30 of these apps. (Note: we also used open source apps from those 77 apps to evaluate recall in Section 8.)
We then face the challenge of manually analyzing the apps for which a test case is generated, to label the analysis results as true positive (real vulnerability) or false positive (false alarm). To classify a reported app as vulnerable, first we check that permission re-delegation has occurred, i.e. that a test case makes the app execute a privileged API. Then we verify whether this case of permission re-delegation is a vulnerability. To limit subjectivity in verifying this second condition we adopt these guidelines (explained in more detail later when we discuss the results):
- Custom protocol: the vulnerability can be triggered only with a particular message that follows an application-specific invocation protocol;
- System intents: the vulnerable component subscribed for system-generated events, but it fails to check whether the notified event is actually generated by the system;
- Misuse of libraries: the vulnerable app performs an insecure use of a library that deals with sensitive data;
- App description: a permission re-delegation causes the vulnerable app to perform a privileged task that is not explicitly specified as a feature in the app description.

Analyzing the 1,258 subject apps, PREV reported 30 vulnerable apps — 7 open source apps and 23 closed source apps. Manual inspection on the reported vulnerabilities revealed that, for all of them, the test cases generated by PREV actually reached a privileged API. Moreover, all the cases represent permission re-delegation vulnerabilities according to our guidelines. In the following we discuss some of those cases in detail to highlight the reason for their classifications.

# Empirical Software Engineering (2020) 25:5084–5136
Custom protocol app components may use custom invocation protocols such as private actions only known to the app (e.g., not specified in the intent-filter) or use specific values in custom extra parameters. Private action is an action that is private to the AUT, because (i) the action name is not mentioned in the app intent-filter, where the call protocol is exposed to other apps; and (ii) the action name has the same prefix as the app package name, e.g., the action com.example.TestApp.TEST ACTION for the app com.example.TestApp; it is not from an included library or from the Android framework. Therefore, this action is likely for internal use, i.e., only for components of the AUT or only for apps developed by the same developers who know the internal details of the app. It is highly unlikely that this component intends to accept action requests from other external.

# Empirical Software Engineering (2020) 25:5084–5136
apps. Therefore, when there is a permission re-delegation scenario in which intent messages can invoke such components, we believe that this is a developer’s mistake or she/he adopts a security-by-obscurity approach. This is a vulnerability because it can be uncovered by an approach like ours. This guideline was applied to classify 5 vulnerable apps such as com.netdania and piproduction.frankthejew.

# System Intents
apps may subscribe for notification of system events via intent filters — events that Android platform generates. For example, the app com.superfanu.bryantbulldogrewards subscribed to be notified when the boot is complete, i.e., it has registered an intent-filter to receive an intent with ACTION BOOT COMPLETED action, which Android platform generates on completing the boot. However, the component of this app does not validate that this notification was actually sent by the system. It blindly assumes that any intent sent to this component is from the system and processes as such. Therefore, when the intent filter specifies a system action but the app code does not validate intent data, we assume that it is a programming mistake and we classify the case as a permission re-delegation vulnerability. This guideline was applied to classify 3 vulnerable apps.

# Misuse of Libraries
apps may be granted with special permissions to use libraries that deal with sensitive data; but they are expected to adhere to the security policies specified in the library documentations. Therefore, when an app uses a special library in a way that violates the library security policies, we assume that it is a programming mistake and classify the case as a permission re-delegation vulnerability. For instance, the apps com.appsdv.smsmefitr and com.aurorasi.aurorasfa use the OneSignal and Google Analytics libraries, respectively. However, the app components using those libraries process broadcasts without verifying that the intent, specified with the protected broadcast action ACTION MY PACKAGE REPLACED, is actually sent by the PackageManager (the system). System actions such as ACTION MY PACKAGE REPLACED are actions that can only be set by the system when sending an Intent. If an app registers to receive a broadcast Intent with such actions, the Android system guarantees that the Intent is sent only by the system. However, apps still have to verify if the Intent they receive is actually sent by the system by checking if the action matches exactly the one that they registered to receive. If an app fails to verify and simply assumes that the Intent came from the system, then the app is potentially vulnerable. This is because a malicious app may send an Intent directly to the vulnerable app component with an arbitrary action and trick the app into performing a privileged action. This guideline was applied to classify 5 vulnerable apps.

# App Description
if none of the previous consideration applies, we resort to the features described in the app descriptions to understand if permission re-delegation is intentional. From the descriptions, one can find out about the primary features of an app (e.g., accessing the camera by a photography app). It might be the intention of the developer to expose these primary features to other apps (and let other apps request this app to take pictures on their behalves). However, when features that require privileged permission but not described in the description are exposed to other apps, we assume that it is not the developer’s intention and classify the case as a permission re-delegation vulnerability. For instance the app com.appportunity.androidpreviewer is described as a gallery of apps, to help developers keep track of their apps. However, the app exposes camera features to other apps, without mentioning it in the description. This guideline was applied to classify 17 vulnerable apps.

Empirical Software Engineering (2020) 25:5084–5136 5115
In some cases, multiple guidelines apply. For example, com.bimandika. Congratulationsmalonepost misuses a library without checking for permission and it does not validate the sender for system intents.

Based on these results, we formulate the subsequent answer to RQ1:
Analyzing 1,258 apps, PREV reported 30 vulnerable apps without any false alarm (Precision=100%). The implication is that security analysts could use PREV to precisely identify vulnerabilities without any false alarm.

# 8 RQ 2: Cost
We investigate the cost of PREV in terms of analysis time. First we discuss the cost of learning permission re-delegation models:
Before testing any given AUT, the permission re-delegation models were learnt by running our tool on 11,796 apps, as described in Section 5. PREV took 250 hours of CPU time to learn the models from 11,796 training apps. The bottleneck was static analysis. Most of the time was spent on extracting reachable APIs (approximately 1 minutes per app). Natural language processing, clustering, and model inference was quite fast (a magnitude of minutes in total). Since Android is always evolving (e.g., change of permission mechanism), the models should be updated whenever newer set (or versions) of reference apps become available. But, first of all, this training step does not have any real-time requirement. For testing a given set of apps under test, this step needs to be conducted only once. Model update can also be done incrementally, by analyzing a new app or a new version as soon as it is posted on the app store. It is not necessary to conduct static analysis on the whole training set. This would reduce the training time to significantly less than 250 hours. Moreover, in this experiment, we used a personal computer; however in actual industrial settings the cloud could be used instead and the analysis of distinct apps can be scheduled as independent jobs on distinct cloud hosts. Hence, we consider this training cost as affordable.