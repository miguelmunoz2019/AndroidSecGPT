Evaluation. To evaluate the model, we randomly sampled 300 APIs from 6,394 APIs associated with 10 SDKs’ API specifications. We manually checked the API specification and labeled 153 privacy-sensitive APIs and 147 non-privacy-sensitive APIs. By setting a similarity threshold of 0, our approach achieved 87% precision and 93% recall on the annotated dataset. In total, our model discovered 1,094 sensitive APIs from 26,707 APIs of 40 SDKs meta-DB. We manually checked all of them and got a precision of 85%. Note that we only used the validated sensitive APIs in the XLDH detection.

4142 30th USENIX Security Symposium USENIX Association
# 4 Evaluation and Challenges in Detection
This section reports our evaluation study on XFinder to understand its effectiveness and performance, and the challenges in identifying XLDH from a large number of real-world apps.

# 4 Effectiveness
# Evaluation on ground-truth set.

We evaluated XFinder over the ground-truth dataset including a “bad set” and a “good set”, with 40 apps each. The apps in the bad set are integrated with 4 XLDH libraries (com.yandex.metrica, com.inmobi, com.appsgeyser, cn.sharesdk), which were found manually early in our research (before we built XFinder). The good set includes the apps randomly sampled from the top paid app list on Google Play . They are considered to be mostly clean and were further confirmed manually in our research to be free of XLDH libraries: we inspected cross-library calls in these apps against the top 40 SDKs (recorded in Meta-DB) and concluded that their corresponding data flows do not violate the callees’ ToSes. Running on these ground-truth sets, XFinder achieved a precision of 100% and a recall of 100%.

# Evaluation on unknown set.

Then, we evaluated XFinder on a large “unknown” dataset – Dg excluding 13018 apps integrating known XLDH libraries, which contains 1,328,130 free Android app in total with 40 SDK ToSes. XFinder reported 2,968 apps associated with 37 distinct XLDH libraries (distinguished based on their package names). To measure the effectiveness of XFinder, we randomly selected three apps for each identified XLDH library (105 in total) and manually validated the detection results: 32 (out of 37) identified XLDH libraries were true positives (a precision of 86%), affecting 93 out of the 105 apps. We performed manual end-to-end tests on seven XLDH libraries (including OneAudience, Mobiburn, and Devtodev) in real-world apps, and confirmed that they indeed exfiltrated Facebook user data to their servers (using Xposed  for app instrumentation and Packet Capture  for inspecting networking traffic).

Looking into the five falsely reported libraries, we found that three of them (com.parse, com.batch and com.gigabud) were caused by the taint analysis of XLA. As mentioned in Section 3, for better scalability, our taint tracking is object-insensitive. Specifically, after our approach taints a field f (holding a Facebook token) in an object obj of class C, which causes the whole class to be tainted; as a result, when the taint of the field f ′ (not storing a sensitive data) in another object obj2 of the same class is propagated to a sink, XLA could not distinguish the two objects and simply considers the token-related information to be exposed to the sink, thereby leading to the false alarms.

Another two false positives (com.xcosoftware and fr.pcsoft) were introduced because our current program analysis could not fully resolve the server endpoints of data exfiltration. Although XFinder found that the two libraries expose a Facebook access token to the Internet (so reporting them as XLDH), the libraries actually send the token to the Facebook server (to retrieve additional user data, e.g., name, ID, page likes), not an unauthorized recipient. Fully automated resolution of such an endpoint is challenging, since the Facebook endpoint used in the networking API is heavily obfuscated (using a complicated control flow to transform the endpoint string, see the code snippet in our released dataset ). We utilized one of the state-of-the-art tools  capable of statically resolving string values in Android apps (using a value set analysis approach, with backward slicing and string related operation analysis), which, however, still failed to handle a case. In our research, we also observed that certain XLDH libraries such as com.mobiburn fetch a dynamic exfiltration endpoint whose value cannot be resolved statically (see the evasion techniques in Section 5). Hence, for a better coverage, XFinder opts to report all exfiltration cases even if the endpoints could not be resolved, and then relies on a manual process to validate the results. Note that the percentage of such false cases is low in our results.

# Discussion of potentially missed cases.

Due to the lack of ground truth, determining the number of missed XLDH libraries on a large scale is challenging. In general, false negatives can be introduced for two reasons: (1) challenges in automatic data-sharing policy analysis on ToSes; (2) limitations of today’s static program analysis techniques, e.g., precise taint tracking, building complete call-graphs, and resolving reflection-call targets.

Specifically, although DPA achieved a high precision and recall in ToSes analysis (see evaluation), it missed vague and complicated cases as mentioned in Section 3. This can be improved in the future by investigating efficient dependency parsing on long sentences. Second, XFinder shares the limitations of current static analysis techniques. In particular, false negatives could be introduced due to the limited capabilities of taint tracking in complicated real-world apps/libraries. For example, an XLDH library could store the restricted data in the host app’s datastore (e.g., Android SharedPreferences, SQLite database, files ) and later use another thread/module to retrieve a specific date item and send it out. Such a complicated data flow could not be automatically taint-tracked by our current approach, nor could it be handled by other state-of-the-art tools like FlowDroid. We will leave the systematic study of the convoluted XLDH data practices to our future work. Furthermore, limited by the capability of DroidRA  to resolve targets of reflection calls, our approach may not identify all cross-library calls if the target class name and function name are stored in variables, passed from other threads, or obfuscated. Also, since we leverage FlowDroid to build the call graphs, which may not be complete, we may not find all cross-library calls based on the graphs.

USENIX Association 30th USENIX Security Symposium 4143
# 4 Performance
Running XFinder on 1 million apps and 40 SDK ToSes, it took around two months to finish all the tasks including DPA, Meta-DB construction, and XLA. Among these three components, XLA was the most time-consuming one (around two months). To analyze all 1M apps (Dg), we utilized a set of computing resources available to us, including one supercomputer (shared in our organization), two servers (20 cores/251GB memory, 12 cores/62GB memory respectively), and 24 desktops (4 cores/15GB memory each). We configured a 300-second timeout for taint tracking, with 83% of the apps successfully analyzed without timeouts or decompilation errors (11% and 4% of them with timeouts and decompilation errors respectively). DPA took 2 hours to extract 1215 (object, condition) pairs on a Mac machine with processor 2 GHz Quad-Core Intel Core i7 and memory of 6 GB 2133 MHz LPDDR3. Meta-DB construction took 4 hours to find privacy-sensitive APIs from the API documentations of the top 40 SDKs.

# 5 Measurement
Based on the detected XLDH libraries and affected apps, we further conducted a measurement study to understand the XLDH ecosystem. In this section, we first present the overview of the real-world XLDH ecosystem discovered in our study (Section 5), and then describe the scope and magnitude of this malicious activity, as well as the infection techniques and distribution channels of the XLDH libraries.

# 5 XLDH Ecosystem
Before coming to the details of our measurement findings, we first summarize the XLDH ecosystem. As outlined in Figure 6, an adversary, who owns an XLDH based data brokerage platform (e.g., OneAudience), releases an XLDH library that aims to harvest data from Facebook SDK. To this end, the adversary needs to distribute the library to a large number of real-world mobile apps, so he reaches out to app owners, especially those with popular apps embedding with Facebook SDK, to provide them monetary incentive to integrate the XLDH library. The app integrated with the library and the Facebook SDK, once passing the SDK vendor’s review and the app store vetting, is available for downloading. When innocent users install the app and log in Facebook, the XLDH library will stealthily access the Facebook token to harvest the user’s Facebook data and send them out to its back-end platform. Meanwhile, the app owner receives commissions from the adversaries based on the number of app installation (e.g., 0$ per installation for OneAudience). Finally, the brokerage platform monetizes users’ Facebook data by sharing it with a marketing company (e.g., Nielsen which offers political and business marketing).