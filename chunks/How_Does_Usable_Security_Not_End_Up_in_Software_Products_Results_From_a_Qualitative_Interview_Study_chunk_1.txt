# 2022 IEEE Symposium on Security and Privacy (SP)
# How Does Usable Security (Not) End Up in Software Products?
# Results From a Qualitative Interview Study
Yasemin Acar ‡, M. Angela Sasse ∗, and Sascha Fahl †, Marco Gutfleisch ∗, Jan H. Klemmer †, Niklas Busch †§
∗Ruhr University Bochum, Germany, {marco.gutfleisch, martina.sasse}@ruhr-uni-bochum.de
†Leibniz University Hannover, Germany, {klemmer, busch}@sec.uni-hannover.de
‡Max Planck Institute for Security and Privacy, Germany, yasemin.acar@mpi-sp.org
§CISPA Helmholtz Center for Information Security, Germany, sascha.fahl@cispa.de
# Abstract
For software to be secure in practice, users need to be willing and able to appropriately use security features. These features are usually implemented by software professionals during the software development process (SDP), who may be unable to consider the usability of these mechanisms.

While research has made progress in supporting developers in creating secure software products, very little attention has been paid to whether and how these security features are made usable. In a semi-structured interview study with 25 software professionals (software developers, designers, architects), we explored how they and other decision-makers encounter and deal with security and usability during the software development process in their companies.

Based on 37 hours of interview recordings, we qualitatively analyzed and investigated 23 distinct development contexts in detail. In addition to individual awareness and factors that directly influence the implementation phase, we identify a high impact of contextual factors, such as stakeholder pressure, presence of expertise, and collaboration culture, and the specific implementation of the SDP on usable security in software products. We conclude our work by highlighting important gaps, such as studying and improving contextual factors that contribute to usable security and discussing potential improvements of the status quo.

# I. INTRODUCTION
Software security is important. However, security alone is not enough. Instead, security features also need to be usable: Users have to use the security features and use them correctly.

Previous research demonstrated the ineffectiveness of poorly designed warning messages , , ,  the prevalent issues with passwords , , , or security and privacy problems due to wrong mental models and misconceptions. For example, most Android users do not pay attention to permissions and lack comprehension, which can lead to wrong security decisions . Secure systems, however, should account for all these human factors to be actually secure; namely, they should implement usable security.

The creators of software, such as software developers and designers, greatly influence whether security is implemented in a usable way. However, while many unusable security mechanisms are known to have created problems in the past , and while research has been done on how developers (fail to) implement security , , , the root causes for lack of usable security (or successfully implemented usable security) in software products is yet unknown.

In addition to software professionals’ individual factors, such as awareness and skill sets, we hypothesize that similarly to security , the entire software development process (SDP) and contextual factors impacts software product usable security. This software creation process involves many more stages than writing code, ranging from requirements engineering to deployment, and often involves multiple stakeholders, e. g., customers, management, and designers. In this study, we investigate how usable security is handled within the software development process in practice. Therefore, we conduct 25 semi-structured interviews with software professionals, including developers, architects, designers, and other decision-makers. We use qualitative coding to extract and explore problems, practices, and motivations for secure and usable software . With this study, we aim to explore the following research questions:
- RQ1: Which factors in the software development process and in companies influence usable security?
- RQ2: What are contributors and blockers for usable security in software development?
- RQ3: When and where in the development process are important decisions made that influence usable security?
Based on our results, we aim to deepen the understanding of how usable security can be achieved while also identifying factors that prevent usable security. We analyze how company culture and contextual factors contribute to usable security and suggest how academia and industry can improve the adoption of usable security by improving awareness, interdisciplinary collaboration, and developing measures that support a holistic usable security process.

The remainder of this paper is structured as follows: We give an overview of related work in Section II. In Section III,
# II. RELATED WORK
We discuss related work in three key areas: (1) the history of usable security, (2) studies and experiments with software professionals, and (3) organizational processes and security culture in software development processes.

# Usable Security
Usable security has been heavily researched for more than 20 years. In 1996, Mary Ellen Zurko established the term user-centered security and made the case that usability for different groups of non-security specialists (software developers, system administrators, and end-users) was a necessary condition for systems to be secure and function in practice . In 1999, Whitten and Tygar demonstrated in their seminal paper that the target users of PGP 5 were not able to operate it securely and identified the usability issues that were the cause . Stransky et al.  conducted a field study in 2021 and confirmed that end-to-end encryption for email is still a huge issue. Adams and Sasse found that the password policies common in organizations were hard to follow and led to constant skirmishes of workarounds and sanctions that did little to make non-specialists take security seriously . The usability of authentication and encryption for end-users has improved over the past 20 years. However, in many organizations, people still encounter impossible security tasks and are blamed when they cannot cope ,.

Over the past decade, the research community started to apply and transfer usable security principles to developers: In 2016, Green and Smith suggested supporting developers and presented ten principles for usable and secure cryptographic APIs , and Acar et al. proposed a research agenda for developer-centered usable security . Pieczul, Foley, and Zurko extended this approach and called for the development of new measures for developer-centered security in addition to the transfer of principles from end-users to developers.

# Studies and Experiments with Software Professionals
When software professionals choose insecure or unusable options, this impacts the end-users interacting with the software – so improving usability for this group improves security for everyone. Research on “developer-centered security” has produced important insights by conducting empirical studies with software industry professionals (e. g., developers, system operators) that document and analyze their knowledge (and knowledge gaps), attitudes, and behaviors around security. Naiakshina et al. – and Danilova et al.  found that developers struggle with the secure implementation of password storage. Fahl et al.  found that many developers fail to provide secure TLS implementations in Android apps, which is still a problem as recent studies by Oltrogge et al. demonstrate , . In 2017, Acar et al. examined the usability of Python cryptography libraries and identified several problems with those APIs leading to insecure code . The problem was also identified by others , . In 2017, Krüger et al. presented the IDE plugin CogniCrypt that assists developers in using cryptographic APIs securely . This tool was later extended by CogniCryptGEN to generate secure crypto code fully automatically . Nguyen et al. created the IDE plugin FixDroid and demonstrated that it significantly helps Android developers in writing more secure code . Acar et al. examined the impact of information sources on development and found the usage of StackOverflow to produce more functional correct but less secure solutions compared to the official Android documentation . Ruef et al. presented a novel contest for secure development and a quantitative analysis of emerging vulnerabilities ; Votipka et al. performed a qualitative analysis to understand what security mistakes are made by developers and why . All these studies focused on developers as users of programming languages, APIs, documentation, and tools necessary to create secure software products – but they do not support the usability aspects of security.

Another strand has studied how system operators and other expert users handle security. Krombholz et al. conducted an experimental study with system administrators and reported that they struggled with the complexity involved in implementing secure TLS , and an interview study revealed that the same group administrators have significant misconceptions about HTTPS . Yakdan et al. created and evaluated a usability optimized decompiler for malware analysts . While those studies provided in-depth insights into the nature of their difficulties, they only studied one specific group of software professionals on one specific security task in the implementation and deployment phase of the SDP. Research has also identified obstacles to fast update behavior with Android developers  and system administrators , also finding the important impact of organizational factors, such as management and policies.

Our study investigated these aspects in both more breadth and depth by asking software professionals specifically about individual and organizational factors that contribute to usable security.