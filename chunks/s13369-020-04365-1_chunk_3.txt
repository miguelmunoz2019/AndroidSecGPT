Mannan et al.  presented an empirical study to compare the type, density and distribution of code smells in mobile vs desktop applications. They analyzed a dataset of 500 open source Android applications and 750 desktop applications. They applied InFusion, a commercial tool for detection and analysis of code smells from both type of applications. They concluded that mobile applications have different structure and workflow as compared to desktop applications but the variety and density of code smells.

6 https://f-droid.org/en/.

7 http://www.intooitus.com/inFusion.html.

Arabian Journal for Science and Engineering (2020) 45:3289–3315
is similar in both platforms. However, they found that the distribution of code smells is different in both platforms.

Carette et al.  reported an empirical study to access the impact of energy Android code smells on the performance of Android applications. They proposed an automated approach called HOT-PEPPER supported by a framework to detect and correct code smells and evaluated their impact on energy consumption on Android applications. The authors claimed that they succeeded to improve the performance of examined applications after correction of code smells.

Habchi et al.  conducted a study to detect code smells from iOS-specific applications. The authors focused both on object-oriented and iOS-specific code smells using adapted tool PAPRIKA. They extended PAPRIKA tool to support detection of code smells from Objective-C and Swift. The experiments are performed on 279 open source iOS applications to detect 4 object-oriented and 3 Android-specific code smells with a good accuracy. They documented the first catalog of 6 iOS-specific code smells from different blogs and other sources of literature.

Kessentiniet et al.  reported an automatic approach for the detection of code smells from Android applications using a multi-objective genetic programming algorithm (MOGP). They automatically generate the best set of rules that are used for the detection of code smells. A rule is a combination of quality metrics with their threshold values to detect a specific type of code smell. The approach is evaluated on 184 Android projects with source code hosted on GitHub. Authors achieved 82% accuracy while detecting 10 Android-specific code smells.

Ghafari et al.  presented an approach supplemented with static analysis to detect security code smells from 46,000 Android software applications. Security code smells indicate the vulnerabilities in the source code related to security properties. Authors discovered that the majority of applications suffered from at least 3 security code smells and only 9% applications were free from security code smells. Through manual analysis of 160 applications, authors realized that security code smells are good indications of security vulnerabilities.

Dennis et al.  proposed a static source code analysis based approach supplemented with the support of P-Lint prototype tool to detect 4 permission code smells. Permission code smells are indications of permission related bad programming practices. The major objective of authors is to provide awareness to developers related to permission standards in Android applications to avoid security vulnerabilities. We realized that P-Lint has limited user interface and limited support for data flow analysis.

Cruz et al.  reported an automatic approach for the detection and correction of energy code smells from Android applications. They presented a tool named as Leafactor that is applied on 140 open source Android applications for the detection of 5 energy code smells. Authors claim that they were successful to correct 222 code smells from 45 applications. They found that approximately 32% examined applications had at least one energy code smell that requires refactoring.

Grano et al.  presented a dataset and approach for accessing the quality of Android applications and detection of code smells. They applied PAPRIKA tool for the detection of 4 object-oriented and 4 Android-based code smells from 395 different applications. The primary focus of authors was on developing a standard dataset for Android applications based on user’s feedback. The dataset has 600 versions including 280,000 user’s views and 450,000 user’s feedbacks.

Dustin Lim  presented an approach for the detection of code smells from Android applications. The author focused on 5 OO code smells namely Feature Envoy, Large Class, Long Method, Message Chain and Spethai code. He selected 5 existing well-known code smell detection tools to evaluate that how existing tools are capable to detect code smells from Android applications and compared the results of code smell detectors on the same examined Android applications. The author concluded that the existing state-of-the-art tools developed to detect code smells from OO applications have poor performance and they detect different instances of code smells from same examined applications.

Ibrahim et al.  presented an automatic approach for the detection and refactoring of 3 code smells from Android applications to reduce the redundancy of test case generation. They implemented their approach using Eclipse Plug-in for the detection and refactoring of code smells. Authors embark that they were successful to achieve their goal by reducing test case generation up to 28% and improving test coverage up to 5%.

Mateus et al.  presented an empirical study to investigate the quality of Android applications implemented in Kotlin programming language. The major focus of authors was to determine the adoption of Kotlin for development of Android applications and to measure the quality of Android applications using this new programming language introduced by Google. They applied PAPRIKA tool on 925 open source Android applications to detect 4 object-oriented and 6 Android-based code smells. Authors concluded that 11% Android applications are implemented in Kotlin and quality of applications developed using Kotlin increases as compared to applications developed using Java programming language. They also realized that object-oriented smells are more frequent in Kotlin as compared to Android smells.

A test smells detection approach is presented to recover test smells from different Android applications using a prototyping tool named tsDetect . The author evaluated the impact of test smells on the distribution and
Arabian Journal for Science and Engineering (2020) 45:3289–3315 3295
maintenance of Android applications. By performing extensive experiments on 656 open source Android applications, he concluded that most Android applications lack support for automated verification of the testing mechanism. He also realized that substantial test smells exist in unit test files.

Gadient et al.  presented an approach supplemented with a tool support Android Lint to recognize 12 security code smells from different applications. They applied a lightweight static analysis methodology that analyzes source code under development and provides just-in-time feedback about presence of security smells. They further analyzed the impact of detected security smells on vulnerabilities. They realized that about half of security smells are good indicator of security vulnerabilities. The Android Lint tool is publically available on GitHub
An approach based on concepts of data mining and source code parsing is presented to detect 13 Android code smells from different applications . During the detection process, Author separates different types of files such as Java, XML and AndroidManifest files using different parsers. The results of the first step are saved in CVS files. The CVS files are used by prototyping tool named as BadDroidDetector to detect 13 Android code smells.

A generic approach based on different tools, namely Modelio, OntoUML and Protégé, is presented to automatically detect 15 smells from different Android applications . Authors claim that proposed approach is capable to detect smells from code and design levels. They detected semantic and structural smells from popular Android applications.

Rubin et al.  presented a recent study on detection and evaluation of Android code smells from different software applications. Authors applied the concept of association rule mining to generate detection algorithms. They validated approach on manually analyzed data source code of 48 open source Android applications. Authors also conducted empirical study on a large number of Android applications to extract additional information related to Android code smells.

We come up with the following observations after in-depth and critical review of the state of the art presented in this Section.

1. Most techniques are implemented based on the concept of source code metrics and searching algorithms as indicated in Table 1. Both types of techniques have their limitations for the detection of code bad smells as discussed by Kessentini et al. . The metrics-based techniques compute source code metrics itself or they use metrics extracted from other third party tools for the detection of smells. The accuracy of these techniques is dependent on the accuracy of metrics and their threshold values. There is still no consensus on threshold values among researchers. Most search-based techniques perform static analysis on the source code to detect different Android smells. These techniques also apply machine learning methods for the detection of smells. However, machine learning-based approaches depend on the quality and efficiency of data.

2. PAPRIKA and extended versions of PAPRIKA are applied by different techniques. This tool is capable to detect a limited number of Android smells and its generalization on other Android smells is questionable. ADOCTOR is applied on 15 Android smells but the accuracy of its results need investigation. The rest of the tools are not focusing on Android smells presented by Riemann et al..