# 2. Materials and methods
# 2. App selection process
We used a structured review process to guide the collection of apps. Fig. 1 outlines the inclusion and exclusion of apps during each round of evaluations. Within the iTunes App Store and Google Play Store, we searched for apps using the search term “depression”. We adopted this search strategy in line with other reviews of mental health apps in this space (e.g., Shen et al., 2015; Huguet et al., 2016). We conducted this search on October 15, 2017 in Chicago, IL. As Google Play presents a maximum of 250 results from any search, we also limited apps included from the iTunes App Store to the first 250 apps to make sure results would not be biased towards findings from the iTunes App Store. This resulted in 500 apps for initial review. This seemed like a sufficient number of apps as research shows that most users do not look beyond the top 10 results or even download apps past the top five . It is estimated that 10,000 mental health apps exist (Torous and Roberts, 2017) and 18% target depression (IMS Institute for Healthcare Informatics, 2015). Therefore, we reviewed roughly a quarter of the 1800 available depression apps.

# 2. Inclusion/exclusion
Inclusion and exclusion were determined in two steps by a group of three raters who were the first through third authors. We first identified and eliminated any apps that were duplicates (n = 29). The first step was based on the descriptions within the app stores, and the second step involved downloading and reviewing the app. Certain inclusion and exclusion criteria could only be determined in the second stage of review as they required information only available by downloading and reviewing the app itself. Apps met inclusion criteria if they (1) aim to provide support or treatment for depression; (2) are in English; (3) are designed for adults; and (4) collect data. Apps were excluded if they are (1) for healthcare professionals only; (2) not a standalone app; (3) not available; and (4) did not function. At each stage, each app was reviewed by two of the three raters. Raters obtained an 86% initial agreement for the first stage of screening (examining app store descriptions), and 89% initial agreement for the second stage (reviewing the downloaded apps). For both stages, each disagreement was discussed as a group and full agreement was met before proceeding. 384 apps were excluded, leaving a total of 116 apps for the final evaluation of the privacy policy and security. All 116 eligible apps were intended for patient use.

# K. O'Loughlin et al. Internet Interventions 15 (2019) 110–115
# 2. Measurement development & scoring
For the 116 eligible apps, we evaluated the presence and quality of a privacy policy with questions that aim to assess comprehensiveness of an app's documentation in describing data collection and storage practices and policies. Of note, while we evaluated the comprehensiveness of the privacy policies, we did not conduct a technical audit to evaluate if the data handling procedures outlined in the policy are actually implemented.

The list of questions can be seen in Fig. 2. This checklist was developed by adapting questions from Baumel et al.'s (2017) Enlight Evaluation tool, which aimed to be a comprehensive evaluation of mobile and web-based eHealth interventions. We selected items relevant to privacy and basic security with adaptations guided by the American Psychiatric Association's App Evaluation Model. All questions are answered either “Yes” or “No”. “Yes” responses required that the privacy policy explicitly state the content of the question. “No” responses resulted when the information was absent from the privacy policy, thus an end user would not know that aspect of their data's handling. In the Enlight privacy and security checklists, lower scores represent higher quality of data security. This is somewhat counter-intuitive because higher scores tend to be interpreted more favorably (as in commercial app stores, for example). To guide interpretation of the checklist, resulting scores were grouped into three categories: Acceptable, Questionable, Unacceptable (for an explanation of scoring, see Fig. 2). The first 23 apps were rated by two of the three raters to establish reliability. Consistency of ratings between raters was considered excellent with intraclass correlation coefficients ranging from 0 to 1 (Koo and Li, 2016). Given this level of consistency the remaining apps were rated by a single rater. All reviews were completed in a one-month period.

# 3. Results
Of the 116 eligible apps, 4% (5/116) received a transparency score of acceptable, 28% (32/116) questionable, and 68% (79/116) unacceptable. This was mostly due to the fact that slightly less than half of the apps (49%, 57/116) had a privacy policy. Privacy policies, when available, were found in various places (see Table 1). Most frequently they were available in the app stores (79%), whereas they were least frequently available in the apps themselves (53%). Privacy policies provided in the app were rarely (11%, 13/116) provided to the user before other information was collected.

# 3. Google Play vs iTunes
The availability of privacy policies differed significantly by platform X2 (1) = 6, p = . Table 2 details the availability of privacy policy for apps broken down by app platform (e.g., Google Play/Android and/or Apple iTunes/iOS). Single platform apps are those available on either Google Play/Android or Apple iTunes/iOS, multiplatform apps are those available on both. iTunes/iOS apps were more likely to report privacy policies. This was true even for those apps with a corresponding Google Play/Android version. However, there was no significant difference by platform as to whether privacy policies were provided prior to collecting user data X2 (1) = 2, p =.

a 2 apps included did not have a website.

# 3. Identifiable vs non-identifiable
Finally, we compared the availability and comprehensiveness of privacy policies based on whether or not the app collected identifiable information (i.e., information that can be used to trace or identify a person, such as full name or e-mail) or non-identifiable information (e.g., journal entry, mood or symptom rating, etc.). Not surprisingly, mobile apps which collected identifiable information were significantly more likely X2 (1) = 21, p <  to have a privacy policy (79%) compared to those that collected only non-identifiable information (34%).

Closer examination of the privacy policies for apps collecting identifiable vs. non-identifiable information revealed two points of difference in comprehensiveness, as shown in Table 3. For apps collecting identifiable information, nearly all privacy policies discussed their storage and sharing practices (87%) and included password protection (87%). This was less frequently covered in apps not collecting identifiable information.

Two mobile applications included features to support the user in directly sharing information with a provider through the app. Both had accessible privacy policies, though neither mention HIPAA requirements for safeguarding medical information nor procedures they implement to be in compliance.

# 4. Discussion
Mobile apps offer tremendous potential to facilitate and enhance mental health care and are increasing in prevalence and use. As technology continues to develop, it is likely that more technologies will emerge as adjuncts or alternatives to traditional treatments for conditions such as depression. However, while these digital tools offer exciting new opportunities for mental health care, they come with significant drawbacks, such as insufficient data security and privacy policies, as highlighted by this paper. Such issues need to be addressed in order to increase consumer and clinician confidence in using mental health apps. Currently, low confidence is a barrier to widespread adoption.

Alarmingly, only 4% of the apps reviewed in this study had privacy policies which we deemed to provide sufficient information regarding their data handling procedures. The majority of apps reviewed (68%) were not sufficiently transparent with this information and received
a Final criteria does not apply to apps which only collect non-identifiable information.

# K. O'Loughlin et al.