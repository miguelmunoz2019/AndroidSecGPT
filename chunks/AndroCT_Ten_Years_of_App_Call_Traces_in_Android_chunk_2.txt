# II. THE AndroCT DATASET
The AndroCT dataset includes derived data for at least one thousand apps, malicious or benign, from each of ten past years. The statistics on the apps and sources from where the apps were originally obtained are outlined in Table I. AndroCT does not include these apps (e.g., their APKs) themselves for two reasons. The first is the large space cost of these apps combined and the storage limit with the free, public online data repositories. The second is that in our dataset the APK name of each app is given, according to which all of the apps can be readily downloaded from respective sources. As shown, the benign apps of years 2017 through 2019 were downloaded from the Google Play Store and the malware of years 2013 through 2016 was obtained from VirusShare; other apps were all from AndroZoo. The noticeable variations among the sizes of yearly datasets (with the minimum of 1,106 and maximum of 3,127) were a result of applying our app selection criterion as detailed in Section III.

The derived data in AndroCT consists of two collections of function call traces. Each collection is composed of 35,974 trace files each corresponding to the trace of function calls in a 10-min continuous exploration of one of the 35,974 apps summarized in Table I. The only difference between these two collections is that one was produced on an Android emulator while the other on a real Android device (smartphone).

For each app, the execution trace in either collection, as stored in a text file, contains a number of textual line each representing a function call in the format of “f ->g" where f is the caller and g is the callee. Both f and g are full-qualified method signatures, prefixed by the full class path of respective methods while including each parameter and return data type if any. An real example line of call trace is “&lt;info.universalmetadata.android.apps.novel reader.VoidLayout: void onCreate(android.os.Bundle)&gt; -> &lt;android.view.ContextThemeWrapper: android.content.res.Resources getResources()&gt;.”
Note that the function call traces that we curated in AndroCT were all whole-app traces, meaning that we profiled invocations of all methods in the app—for methods whose
definition cannot be found from the app’s APK, they were profiled only as callees. In terms of the scope of tracing, these methods cover all of the three code layers of an Android app—user code, Android SDK, and third-party libraries, and they may be defined in an app component of any of the four standard types: Activity, Service, BroadcastReceiver, and ContentProvider. In terms of the invocation mechanism of the calls, these methods include both those called explicitly (i.e., with explicit references to the call targets) and those that are the targets of reflective calls, and they may be called through normal or exceptional control flows.

Especially, when a callee is an inter-component communication (ICC) API, the trace contains the value of each ICC Intent field, immediately after the line about the call itself. For non-ICC calls, currently AndroCT does not trace the return values or the values of arguments at a callsite. The reason that we chose to profile more details only for ICC calls was that without these Intent details it would be hard to link the communicating components. Establishing these links would be essential for whole-app dynamic analysis.

Since we have apps in both malware and benign-app classes and across ten years, while in two separate collections, AndroCT includes 2*10*2=40 subdatasets. In our data package, each of these 40 subdatasets is stored as one zip file (.tar.gz), with the file name explicitly indicating of which year and in which security category (malware/benign) the underlying apps are. Moreover, for the collection generated on the real device, the name is further prefixed by the word “real".

# III. DATA COLLECTION AND CONSTRUCTION
We describe how we collected the apps (as summarized in Table I) and how the AndroCT dataset was constructed (i.e., how the function call trace was curated for each app).

# A. App Collection
As it alone provides both benign and malicious apps of different years from various origins, we took AndroZoo as the main source of apps. To further diversify the data sources for better sample representativeness, we considered Virusshare and Google Play as two alternative data sources as well.

For each year, we started with downloading a pool of apps and discarded those for which we cannot meaningfully profile their function calls (due to corrupted APK or failed instrumentation) or cannot attain 60% or higher line coverage of the app’s user code after running the app against test inputs randomly generated by Monkey  for ten minutes. We used these selection criteria because our focus is on the run-time behavioral profiling of apps in terms of function calls, and 60% coverage enforces reasonable confidence about the profile’s representativeness of app behaviors. The Monkey tool was used because of its industry-strength robustness and usability as well as relative small shortage in code coverage compared to various research prototypes for Android app testing. For all the 35,974 apps selected eventually, the mean line coverage per app is 74% (with standard deviation 11%). We did not intend to curate balanced numbers of apps across years given the uneven distribution of the total app populations over the years. We also removed redundant apps within and across the ten years. Further, a benign sample was removed if at least one VirusTotal  tool identified it as malware, and a malware sample was removed if less than ten of VirusTotal tools agreed on its status of being malicious.

# B. Function Call Tracing
The whole-app function calls for each app were all traced using DroidFax . To generate the trace, the tool performed static instrumentation purely at app level to probe for the calls of any method, including ICC APIs, reflective calls, and calls invoked through exceptional control flows (e.g., in a catch or finally block). For ICC API calls, additional probes for profiling the underlying Intent object were inserted.

For the emulator-based trace collection, each instrumented app was then explored by Monkey for ten minutes on a Google Nexus One emulator of 2G RAM and 1G SD storage with the Android 6 installed. The execution trace was collected at the host machine through the Logcat tool . To avoid possible interferences among the executions of different apps, the emulator was restarted as a fresh clean environment before tracing the next app. Further details on the instrumentation and run-time profiling can be found in.

For the real-device-based trace collection, we followed the same process as for creating the emulator-based trace collection, reusing the same instrumented apps. The only difference was that here we ran each app on a Samsung Galaxy S4 smartphone with the same Android platform version, 2G RAM, and 4G SD storage.

# IV. PRIOR USE OF AndroCT
For conducting a dynamic characterization study , we proposed an app behavioral profile, defined by 122 metrics in three dimensions as described in —these metrics were immediately computed from the function call traces in AndroCT although only 125 benign apps of a single year were used in the study. In defining these metrics, we differentiated function calls in different scopes (e.g., the three code layers and four types of app components as mentioned earlier). We also categorized callbacks, a subset of function calls, into various categories. Moreover, we separately treated calls to functions that are pre-defined sources and sinks, while using various source/sink categories to define relevant metrics. The study was later extended to include apps of years 2010 through 2017 , but still only benign apps were considered.

In addition, leveraging another subset of AndroCT, we have built the same dynamic profiles but only for 136 benign apps and 135 malware, both of a single year. From these profiles, we discovered 70 out of the 122 metrics that best differentiated the dynamic profiles between malware and benign apps, and utilized these 70 metrics to develop a new dynamic Android malware detection and categorization tool . Furthermore, we have utilized the AndroCT dataset for developing and evaluating sustainable malware detectors , , —the longitudinal nature enabled us to assess the sustainability of
# the detector in classifying apps appeared several years after the year of the apps used for training.

Most recently, we utilized part of AndroCT to perform a comparative study of the behavioral differences between malware and benign apps, in terms of the same behavioral profile. The study also only used apps of years 2010 through 2017 . To illustrate the use of AndroCT in constructing this behavioral profile, the current data package of AndroCT includes such profiles of apps as used in that prior paper.