Furthermore, the experimental results may be impacted by the validity of the results of the selected vulnerability detection tools. Given that these are static analysis tools, it is known that they may yield false positives. We attempt to mitigate this impact by performing a manual verification to some of the randomly selected vulnerabilities yielded by the three analyzers. As discussed in Section IV-A, the naive verification process does not spot any clearly false positive results (i.e., the vulnerabilities are at least in conformance with the definition of vulnerabilities as proposed in the tools documentation). However, since the verification was implemented by two Ph.D. students, their experiences could have a direct impact on the verification result. Thus, lack of proof of the authenticity of the vulnerabilities is the main threats to the validity of this study. Moreover, during the manual verification, vulnerabilities of non-HTTPS links are not considered. The main reasons are as follows: 1) they are quite straightforward to be identified, and 2) these links can be changed over time, and thereby, are difficult to be verified (e.g., for an HTTP link, if an HTTPS page and redirect were added just before the verification, should we consider it as a false positive?). The pervasiveness of such vulnerabilities also makes it hard to be manually checked. But we still have to be aware of the possibility of the impact on the results.

Finally, due to constraints such as time budgets and computation resources, the results yielded by the three selected static analyzers are for a different number of apps. Since the results obtained by the static analyzers are not always from the same samples, different vulnerabilities could be collected from different datasets. Therefore, our empirical observations could have been impacted by such inconsistent datasets. However, as we have not attempted to compare the results between different.

This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.

# 16
# IEEE TRANSACTIONS ON RELIABILITY
static analyzers, we believe that such an impact should be negligible. Nevertheless, to empirically demonstrate this, we go one step deeper to revisit the aforementioned studies with a common corpus. Specifically, we conduct our revisit study on 356 app lineages, which correspond to 3984 apks, having all these apps successfully analyzed by the three tools. Our revisit study reveals that the empirical findings observed from a common app lineage set are more or less similar to that of imbalanced datasets. For example, regarding the evolving patterns of vulnerable apps, as illustrated in Fig. 19, the results observed from the imbalanced dataset (top subfigure) and the common corpus (bottom subfigure) more or less follow similar trends, indicating that the empirical results observed will unlikely be impacted by the dataset chosen in this article.

# V. RELATED WORK
Our work is related to several contributions in the literature. In previous sections, we have discussed the case of data leaks vulnerability in Android investigated by the authors of TaintDroid , FlowDroid , and IccTA . Other analyzers have been proposed based on static analysis , , , dynamic analysis –, or a combination of both  to find security issues in apps. In view of the amount of literature that relates to our work, we focus on the following three main topics.

# 1) Android Security Studies:
Subsequent to the launch of Android, several comprehensive studies have been proposed to sensitize on security issues plaguing the Android ecosystem. Enck et al.  have provided the first major contribution to understanding Android application security in general with all potential issues. However, compared to the dataset used in this study, the number of their samples was limited. Felt et al.  have then focused on permission redelegation attacks, while Grace et al.  focused on capability leaks. They unveiled vulnerabilities related to permissions. While this article studied different kind of vulnerabilities from the evolution aspect. Zhou et al.  have later focused on manually dissecting malicious apps to characterize them and discuss their evolution. The MalGenome dataset produced in this study has since been used as a reference dataset by the community. We mainly focus on the vulnerabilities of Android. More recently, Li et al.  have performed a systematic study for understanding Android app piggybacking: they notably pointed out libraries as a primary canal for hooking malicious code. Although piggybacking is different from updating, as it is a tempering by other developers, there are some similar mechanisms and we borrowed some ideas from their study.

# 2) Vulnerability Studies:
Vulnerabilities, also known as security-sensitive bugs, have been extensively studied in the literature  for different systems – and languages , –. Camilo et al.  have recently investigated the Chromium project to check whether bugs foreshadow vulnerabilities. Researchers have also proposed approaches to automatically patch them ,.

In the Android literature, several studies have already been performed, which are as follows. Bagheri et al.  have recently analyzed the vulnerabilities of the permission system in Android OS; Huang et al.  have studied so-called stroke vulnerabilities in the Android OS, which can be exploited for DoS attacks and for inducing OS soft reboot; similarly Wang et al.  have analyzed Android framework and found six until-then unknown vulnerabilities in three common services and two shipped apps, while Cao et al.  focused on analyzing input validation mechanisms. Qian et al.  have developed a new static analysis framework for vulnerability detection. Thomas et al.  have analyzed 102k+ apks to study a common vulnerabilities and exposures (CVE) reported vulnerability on the JavaScript-to-Java interface of the WebView API. Jimenez et al.  have attempted to profile 32 CVE vulnerabilities by characterizing the OS components, the issues, the complexity of the associated patches, etc. Linares-Vásquez et al.  have then presented a larger-scale empirical study on Android OS-related vulnerabilities. OS vulnerabilities have also been investigated by Thomas et al.  to assess the lifetime of vulnerabilities on devices even after OS updates are provided. Closely related to our work is the study by Watanabe et al. , where authors investigated the location of vulnerabilities in mobile apps. Our work extends and scales their study to a significantly larger dataset. Finally, Mitra and Ranganath recently proposed the Ghera  repository with a benchmark containing artifacts on 25 vulnerabilities. Our work is complementary to theirs as we systematically collect thousands of pieces of code related to a few vulnerabilities, from which researchers can extract patterns, and help validate detection approaches.

# Table V
lists the works that are similar to this study. It is noteworthy that the number of apks considered in these reported studies is much less (by an order of magnitude) than the number of apks considered in this article. Moreover, most of the studies focused on one specific vulnerability type. Although, the latest two works studied Android vulnerabilities more generally and the last one even considered about app updates. None of them studied vulnerabilities from the aspect of app lineages. Therefore, some evolution patterns of vulnerabilities can only be found in this study such as vulnerability reappearing.

This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.

# GAO et al.: UNDERSTANDING THE EVOLUTION OF ANDROID APP VULNERABILITIES
# TABLE V
formed in total by 465 037 apks. We have then run computationally expensive vulnerability scanning experiments on these app lineages providing a view vulnerability evolution, which was so far the largest scale of this kind of studies. Moreover, investigating Android vulnerabilities from app lineage point of view was the major novelty of this study, which allowed us to yield several newly spotted findings, which are as follows:
1. most vulnerabilities could survive at least three updates;
2. part of third-party libraries were the major contributors of the most vulnerabilities;
3. vulnerability reintroduction occurs for all kinds of vulnerabilities, while Encryption-related vulnerabilities were the most reintroduced within all types of this study;
4. some vulnerabilities may foreshadow malware.

In addition to new findings, this large-scale study also confirmed most of the conclusions from previous studies with relatively small datasets. However, the result of this study also suggested that the recent claim made by Watanabe et al.  that more code and libraries imply more vulnerabilities may not be always true. Finally, the following three valuable artifacts produced by this study: app lineages; the complete dataset of vulnerability scanning reports; and recorded vulnerable pieces of code, were shared.