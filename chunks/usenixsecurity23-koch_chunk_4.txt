# 6 Taxonomy of Consent Dialogs
In Section 5, we analyzed the popularity of different CMPs and had to come to the conclusion that no set of CMPs reaches sufficient popularity to base our analysis on. Consequently, we cannot use key elements of different CMPs to identify, extract, and analyze displayed privacy consent dialogs. We, thus, conducted an initial manual study on a quarter of our apps to analyze observable privacy consent dialogs. Based on this analysis, we defined a taxonomy consisting of three different types of privacy consent dialogs we observed being deployed:
- Link: A simple link referencing the privacy policy. While this might inform the user about an existing privacy policy a link can clearly not fulfill our stated design requirements. A link differs from a notice or a dialog by only being a link, without any form of related buttons or context information.

- Notice: A notice is a text, e.g., in the form of a banner. The text informs the user about the app’s privacy practices in some form but does not offer any form of consent or rejection. Notices commonly only state that by continuing to use the app, the user consents to the privacy policy and data collection, whereas a dialog provides more information. However, the line between a proper dialog using a ’continue’ button and a message, informing you that using the app entails agreeing is thin. The difference between a notice and a dialog resides in the purpose of the contained buttons, specified by their label. A notice only offers buttons that (also) serve another purpose than agreeing to the privacy policy, most commonly they are the log in buttons.

- Proper Dialog: A dialog is text, e.g., in the form of a banner, that not only informs the user but also actively requires agreement in form of interaction, i.e., buttons. This is the only type of privacy consent dialog that can potentially fulfill our stated design requirements. However, a more detailed analysis is required, e.g., can a user actually reject data collection or if they are nudged towards giving consent.

# 6 iOS based Consent Dialogs
Apple introduced privacy improvements for iOS starting with version 14 . Apps do not have default access to the IDFA, a phone global identifier, anymore if a user disables the corresponding setting. Furthermore, an app may now ask for permission to track a user for advertisement purposes. A positive response for this request enables the App to get the IDFA. According to the documentation such permission also entails generic tracking such as ’displaying targeted advertisement’ or ’sharing device location data or email lists with a data broker’. Operating system based consent dialogs are out of scope and we deny each app this permission individually after installation.

# 6 Differentiating Between Consent Dialogs
After having established a taxonomy we proceed to detect, classify, and analyze presented privacy consent dialogs in running mobile apps (i.e., during step 2). This is done in a two step process: (1) we sort a detected privacy consent dialog into our taxonomy; (2) if we detected a proper dialog, we continue to analyze it to check for any problematic design patterns casting doubt on the validity of the privacy consent dialog.

As we detect dialogs and interactable elements based on text we need to be able to extract text elements of each app. We are using Appium for this . The Appium framework provides a generic interface to elements of both Android and iOS apps. This interface affords extracting attributes of app elements such as the contained text. Our dialog analysis process is solely based on the text content of an element to stay operating system agnostic as attributes such as class names or id patterns differ between Android and iOS.

(1) Dialog Classification Based on our initial manual study, we compiled a set of common phrases such as we
care about your privacy or by continuing to use our app, you acknowledge that we may process your data in line with our data protection statement and designed regular expressions capturing essential words or phrases but leaving out app-specific wordings. One example for such a regexp would be /have read( and understood)?[ˆ.]{3,35}(privacy|cookie|data protection|GDPR)(policy|notice|information|statement)/.

This regexp captures common essential phrases of a privacy policy text, i.e., have read and understood, as well as keywords, e.g., privacy policy, GDPR information, or GDPR statement. However, it also leaves space in between those phrases and keywords for app- or vendor-specific text while ensuring that those key elements are within the same sentence. This allows us to detect the presence of any type of privacy consent dialog that contains phrases related to privacy and the GDPR. Our approach catches any dialog that matches our keywords and we do not analyze further why the developer chose to include those keywords, i.e., perform any natural language processing. Thus, we expect that we will encounter a broad spectrum of privacy related consent dialogs.

We distinguish between a proper dialog and a notice by checking for the presence of buttons again using our initial manual study to identify text elements associated with consent dialog buttons such as okay, accept or reject and whose text is not significant longer than the provided matching expression. Furthermore, we ensure that labels such as I do not consent are not matched as consent by controlling for negating keywords. If an app does not display a detectable proper dialog or notice but contains a link to a privacy policy, again identified with a set of regular expressions, we classify the presented consent dialog as a link. All extracted information are stored for further processing. All regular expressions are listed in the appendix as well as contained in our source code.

# 6 In-Depth Traffic Analysis
We are also interested in the transmitted personal information to third parties in the context of privacy consent dialogs, that would clearly require prior consent by the user. To be able to analyze the transmitted traffic in-depth we designed a set of tracking endpoint processors for observed popular endpoints to 20 different known tracking companies. Each processor is designed to analyze the traffic directed at the targeted tracking endpoint and parses the contained data in-depth. We identify a targeted endpoint by scheme, host, and path. This affords us the capability to detect any data collection or processing before Consent. Which is an indirectly stated requirement for any privacy consent dialog: processing can only rely on consent as a legal basis if it occurs after consent has been given.

The endpoints were chosen by their overall requests frequency in our data set as well as for being a known tracking endpoint. We chose to focus on specific endpoints as it allows us to analyze the vast amount of information send to an endpoint including information that would normally be overlooked. We selected datapoints to extract, based on the content of the request by analyzing parameters send via query or body to the same endpoint. To understand values we leveraged the field names if available or recognizing values, e.g., IP or Device Name, by manually analyzing requests. A good example for data transmitted that would be lost by performing a generic search for data of already known information would be the language of the device (commonly just a two letter string), or a flag whether the device is already rooted (a simple boolean value). This type of focused analysis also allows us to decode information that is not transmitted in the clear but encoded. An example would be our support for Protobuf used by Firebase.

Even though not every data point is person specific information (e.g., the localization of a device) as soon as it is transmitted in combination with an identifier it is personal information and requires consent. Furthermore, previous work has shown that a set of non personal identifiers can be used to identify a person or a device and thus could be used as an indirect identifier, which again would then be covered by the GDPR. Thus, focusing specific endpoints allows for a novel perspective on the vast amount of information leaked by mobile applications into the internet.

We consider the Google Advertisement ID (GAID), the iOS Advertisement Identifier (IDFA, IDFV), and any UUID to be an Identifier.