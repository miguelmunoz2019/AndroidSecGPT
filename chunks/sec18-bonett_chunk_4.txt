# 4 Leveraging the Security Goal
Like security operators, mutation schemes may also be designed in a way that accounts for the security goal of the tool being evaluated (Goal G1). Such schemes may be applied to any tool with a similar objective. In keeping with our motivating example (Section 2) and our evaluation (Section 6), we develop an example mutation scheme that can be specifically applied to evaluate data leak detectors. This scheme infers two ways of adding mutants:
1. Taint-based operator placement: This placement methodology tests the tools’ ability to recognize an asynchronous ordering of callbacks, by placing the source in one callback and the sink in another. The execution of the source and sink may be triggered due to the user, and the app developer (i.e., especially a malicious adversary) may craft the mutation scheme specifically so that the sources and sinks lie on callbacks that generally execute in sequence. However, this sequence may not be observable through just static analysis. A simple example is collecting the source data in the onStart() callback, and leaking it in the onResume() callback. As per the activity lifecycle, the onResume() callback always executes right after the onStart() callback.

2. Complex-Path operator placement: Our preliminary analysis demonstrated that static analysis tools may sometimes stop after an arbitrary number of hops when analyzing a call graph, for performance reasons. This finding motivated the complex-path operator placement. In this scheme, we make the path between source and sink as complex as possible (i.e., which is ordinarily one line of code, as seen in Listing 1). That is, the design of this scheme allows the injection of code along the path from source to sink based on a set of predefined rules. In our evaluation, we instantiate this scheme with a rule that recreates the String variable saved by the source, by passing each character of the string into a StringBuilder, then sending the resulting string to the sink. μSE allows the analyst to dynamically implement such rules, as long as the input and output are both strings, and the rule complicates the path between them by sending the input through an arbitrary set of transformations.

In a traditional mutation analysis setting, the mutation placement strategy would seek to minimize the number of non-compilable mutants. However, as our goal is to evaluate the soundness of Android security tools, we design our mutation scheme to over-approximate. Once the mutated apps are created...

USENIX Association 27th USENIX Security Symposium 1269
# Mutated Application
# Dynamic Filter
# Security Tool
Manual Analysis
Number of Mutants
For a feasible analysis, we pass them through a dynamic filter that removes the mutants that cannot be executed, ensuring that the mutants that each security tool is evaluated against are all executable.

# 4 Analysis Feasibility & Methodology
μSE reduces manual effort by filtering out mutants whose security flaws are not verified by dynamic analysis (Goal G3). As described in Figure 2, for any given mutated app, we use a dynamic filter (i.e., the Execution Engine (EE), described in Section 5) to purge non-executable leaks. If a mutant (e.g., a data leak) exists in the mutated app, but is not confirmed as executable by the filter, we discard it. For example, data leaks injected in dead code are filtered out. Thus, when the Android security tools are applied to the mutated apps, only mutants that were executed by EE are considered.

Furthermore, after the security tools were applied to mutant apps, only undetected mutants are considered during analyst analysis. The reduction in the number of mutants subject to analysis at each step of the μSE process is illustrated in Figure 4.

The following methodology is used by an analyst for each undetected mutant after testing a given security tool to isolate and confirm flaws:
1. Identifying the Source and Sink: During mutant generation, μSE’s ME injects a unique mutant identifier, as well as the source and sink using util.Log.d statements. Thus, for each undetected mutant, an analyst simply looks up the unique IDs in the source to derive the source and sink.

2. Performing Leak Call-Chain Analysis: Since the data leaks under analysis went undetected by a given static analysis tool, this implies that there exists one (or multiple) method call sequences (i.e., call-chains) invoking the source and sink that could not be modeled by the tool. Thus, a security analyst inspects the code of a mutated app, and identifies the observable call sequences from various entry points. This is aided by dynamic information from the EE so that an analyst can examine the order of execution of detected data leaks to infer the propagation of leaks through different call chains.

3. Synthesizing Minimal Examples: For each of the identified call sequences invoking a given undetected data leak’s source and sink, an analyst then attempts to synthesize a minimal example by recreating the call sequence using only the required Android APIs or method calls from the mutated app. This info is then inserted into a pre-defined skeleton app project so that it can be again analyzed by the security tools to confirm a flaw.

4. Validating the Minimal Example: Once the minimal example has been synthesized by the analyst, it must be validated against the security tool that failed to detect it earlier. If the tool fails to detect the minimal example, then the process ends with the confirmation of a flaw in the tool. If the tool is able to detect the examples, the analyst can either iteratively refine the examples, or discard the mutant, and move on to the next example.

# 5 Implementation
This section provides the implementation details of μSE: (1) ME for mutating apps, and (2) EE for exercising mutants to filter out non-executing ones. We have made μSE available for use by the wider security research community , along with the data generated or used in our experiments (e.g., operators, flaws) and code samples.

1. Mutation Engine (ME): The ME allows μSE to automatically mutate apps according to a fixed set of security operators and mutation schemes. ME is implemented in Java and builds upon the MDROID + mutation framework for Android . Firstly, ME derives a mutant injection profile (MIP) of all possible injection points for a given mutation scheme, security operator, and target app source code. The MIP is derived through one of two types of analysis: (i) text-based parsing and matching of xml files in the case of app resources; or (ii) using Abstract Syntax Tree (AST) based analysis for identifying potential injection points in code. μSE takes a systematic approach toward applying mutants to a target app, and for each mutant location stipulated by the MIP for a given app, a mutant is seeded. The injection process also uses either text- or AST-based code transformation rules to modify the code or resource files. In the context of our evaluation, μSE further marks injected mutants in the source code with log-based indicators that include a unique identifier for each mutant, as well as the source and sink for the injected leak. This information can be customized for future security operators and exported as a ledger that tracks mutant data. μSE can be extended to additional security operators and mutation schemes by adding methods to derive the MIP.

# 2. Execution Engine (EE)
To facilitate a feasible manual analysis of the mutants that are undetected by a security analysis tool, μSE uses the EE to dynamically analyze target apps, verifying whether or not injected mutants can be executed in practice. This EE builds upon prior work in automated input generation for Android apps by adapting the systematic exploration strategies from the C RASH - S COPE tool  to explore a target app’s GUI. We discuss the limitations of the EE in Section 9. For more details, please see Appendix C.

# 6 Evaluation
The main goal of our evaluation is to measure the effectiveness of μSE at uncovering flaws in security-focused static analysis tools for Android apps, and to demonstrate the extent of such flaws. For this study, we focus on tools that detect private data leaks on a device. Specifically, we focus on a set of seven data leak detectors for Android that use static analysis, primarily due to the availability of their source code, namely FlowDroid , Argus  (previously known as AmanDroid), DroidSafe , IccTA , BlueSeal , HornDroid , and Did-Fail . For all the tools except FlowDroid, we use the latest release version when available; in FlowDroid’s case, we used its v2 release for our μSE analysis, and confirmed our findings with its later releases (i.e., v2 and v2). Additionally, we use a set of 7 open-source Android apps from F-droid  that we mutate. These 7 apps produced 2026 mutants to inspect, which led to the discovery of 13 flaws. A larger dataset of apps is likely to generate more mutants, and lead to more flaws.