- We discuss implications for APPG users, APPG providers, and privacy regulators to improve the APPG ecosystem.

# Online Automated Privacy Policy Generators for Mobile Apps (RQ1)
This section addresses RQ1, describing what APPGs exist for mobile apps and what differences there are between them. We manually collected and identified 10 publicly available online APPGs for mobile apps. We analysed various characteristics and specifically the range of possible data uses in apps.

# Collecting Online APPGs for Mobile Apps
To better understand the current status of APPGs, we identified popular APPGs for mobile apps by using the Google search engine and exploring crowd-knowledge platforms. In detail, we employed the Google search engine to broadly search APPGs for mobile apps. We acted as a hypothetical citizen developer who is trying to generate a privacy policy for their app. We created an initial set of search terms, including “Apps Privacy Policy Generators”, “Apps Privacy Policy Generators Online”, “Privacy Policy Automated Generation”, “Google Play Store Privacy Policy Generator”, “GDPR Policy Generators”. For each search keyword, we evaluated all entries on the first result page. In addition to direct results from Google search, we also identified APPGs by using our Google search terms again in app developer crowd-knowledge platforms including Stack Overflow , GeeksforGeeks , and GitHub . To evaluate search results, we manually identified and read highly related threads, and collected the mentioned APPGs. After collecting an initial set of APPGs and removing duplicates, we filtered out irrelevant APPGs based on the following two criteria: 1) APPGs that only support privacy policy generation for websites; and 2) APPGs that do not actually provide their proposed functions. For example, while some APPGs claim that they are able to generate privacy policies for mobile apps, they do not actually provide such a service.

“Registration” indicates whether a user needs to register an account to use the APPG. All APPGs we collected are based on question answering and template completion (‘boilerplate’), however, they have various different “Modes” to handle information interactions with users as we demonstrated in Figure 1. “User interface”(UI) mode means that users need to select the relative data practices through an integrated UI as à la carte manner, then answer a few other questions about the app’s and developers’ basic information. “Questionnaire” mode only requires users to complete a long questionnaire that covers all potential data practices and a privacy policy will be generated depending on the answers. This is the most common and popular type of APPGs (8/10).

“Document” mode is common in legal consultation websites. Users need to purchase access to a privacy policy document, then answer a series of questions to complete the template. Notably, all analyses of APPGs in this paper include features in both free and paid versions. We conducted all analyses of APPGs in May 2022.

# 2 Characterization
A comprehensive assessment is conducted on identified APPGs along 10 dimensions. The first five (1-5) target practicability, user-friendliness, and convenience from potential APPG users’ perspectives. The next three (6-8) cover legal compliance with privacy regulations, according to the tools’ claims. The last two (9, 10) focus on the understandability of privacy policies. The results are shown in Table 2. We define these 10 dimensions as follows:
1. Extent of Data Recognised (1). Mobile apps normally require data from direct user input or device sensors. Some apps may also provide data to third-party services, for revenue or to enhance the user experience. Privacy regulations such as GDPR [Art. 14(1)(d)] and CCPA [§1798(a)(5)(B), 1798(c), Regs §999(c)(1)(d)))], can require that app developers include information about all collected or shared data within their privacy policy. However, some APPGs only recognise a limited range of data practices for inclusion in privacy policies. As failing to include all data practices could be regarded as a regulatory violation in some jurisdictions, this is an important characteristic and is discussed in more detail in the next section (Section 2). Tentatively, we use ( ) to denote that the APPG recognises a wide range of data use, (G) for a smaller range of data use, and (#) for a few kinds of data use.

2. Customizability (2). Customizability addresses two concerns: can users add privacy practices that were not originally included in the APPG pipeline, and do users have the freedom to add customized clauses in the generated privacy policy document? The former can help developers to provide a more specific and accurate privacy policy; the latter can more easily accommodate developers who want to address additional concerns about users’ privacy. APPGs are denoted as ( ), (G), and (#), as indications that they are positive for both, one, and zero of these questions, respectively.

3. User Instruction (3). The main target audience of APPGs is expected to be developers with little or no legal knowledge about privacy and data protection. Therefore it is crucial to provide sufficient user instructions to help correctly utilize the APPG. User instructions can be generally categorised into three types: providing further explanation of obscure questions (an example is shown in Figure 1), elaborating terms by listing examples, and supporting users with an interactive help center. APPGs are scored as (#) if they only provide one or nil occurrence of the above user instructions, (G) for two to five occurrences, and ( ) for more than five occurrences. Especially, APPG #1 Iubenda also provides an introduction video and comprehensive documentation.

4. Complexity (4). This dimension indicates the general learning cost for APPG users, and higher complexity reflects a higher cost. For UI-mode APPGs, users have to spend more time getting familiar with the UI and learning operation procedures, therefore, we manually set them as ( ). For questionnaire-mode APPGs, we found that the complexity is related to the number of questions that users are asked in the generation process. Based on the “Statistic summary” in Table 3, if the sum of maximum multiple-choice questions and maximum completion is less than 10, the APPG is marked as (#), if it is between 10 to 50, the APPG is marked as (G); and if it is greater than 50, the APPG is marked as ( ). For document-mode APPGs, users only need to select a document from the library and fill up several questions about their basic information, thus, we manually set them as (#).

5. Publishing Support (5). This dimension reflects how convenient it is to deploy the generated privacy policy. Every APPG provides at least one of the following publishing options: 1) a permanently hosted website link containing the privacy policy; and 2) the generated privacy policy context in editable HTML format. In section 3, we presented that a large amount of privacy policy links in the market lead to inaccessible websites, and we believe that a permanently hosted website link provided by APPGs can mitigate this.

#: low level / does not support; G: intermediate level / partially support; : high level / fully support
These three dimensions are binary, simply indicating whether the APPG claims that they provide compliance with the corresponding privacy regulations. ( ) denotes support and (#) denotes non-support. No APPG claims compliance with other privacy regulations such as APP  and PIPL.

Multilingual Support (9). In Section 3, we discuss how current privacy policies suffer from the language localization problems. APPGs that provide multi-language support should benefit both app developers and app users. Additionally, in CCPA [Regs §999(a)(2)(d)], it stipulates that online notices should follow generally recognized industry standards, such as the W3C Web Content Accessibility Guidelines . We use ( ) to denote that APPG can generate privacy policies in more than one language, otherwise (#).

Readability (10). While a long privacy policy can provide more comprehensive and detailed descriptions of data practices in apps, adding unnecessary information to a privacy policy may lead to information overload . Although APPGs can generate more concise privacy policies that are more specifically tailored to the data and data practices relevant to each app, this does not necessarily mean that those privacy policies are more readable. Some regulations require mobile app developers to use clear and understandable language in privacy statements . Also, W3C Web Content Accessibility Guidelines [§3] requires that “make text content readable and understandable”. However, those high-level principles do not give details for this requirement. Thus, we adopt the Flesch Reading-Ease Test  to evaluate the readability of generated privacy policy context. A higher score indicates the content is easier to read and understand, the score scales from 0 to 100. The average readability score of the privacy policies of 12 leading mobile apps , who have over one billion installs, is 46. We use ( ) when the readability score is greater than or equal to 46, (G) for 40 to 46, and (#) for less than 40. Specific readability scores are listed in Appendix Table 10.