FC4: Incorrect Modeling of Asynchronous Methods: The security tool does not recognize a data leak whose source and sink are called within different methods that are asynchronously executed. For instance, FlowDroid does not recognize the flow between data leaks in two callbacks (i.e., onLocationChanged and onStatusChanged) of the LocationListener class, which the adversary may cause to execute sequentially (i.e., as our EE confirmed).

Apart from FC1, which may be patched with limited efforts, the other three categories of flaws may require a significant amount of research effort to resolve. However, documenting them is critical to increase awareness of real challenges faced by Android static analysis tools.

# 6 Flaw Propagation Study
The objective of this experiment is to determine if the flaws discovered in FlowDroid have propagated to the tools that inherit it, and to determine whether other static analysis tools that do not inherit FlowDroid are similarly flawed.

Methodology: We check if the two newer release versions of FlowDroid (i.e., v2, and v2), as well as 6 other tools (i.e., Argus, DroidSafe, IccTA, BlueSeal, HornDroid, and DidFail), are susceptible to any of the flaws discussed previously in FlowDroid v2, by using the tools to analyze the minimal example APKs generated during the in-depth analysis of FlowDroid.

Results: As seen in the Table 3, all the versions
Note that a “-” indicates tool crash with the minimal APK, a “X” indicates presence of the flaw, and a “x” indicates absence, and *FD = FlowDroid.

of FlowDroid are susceptible to the flaws discovered from our analysis of FlowDroid v2. Note that while we fixed the Fragment flaw and our patch was accepted to FlowDroid’s codebase, the latest releases of FlowDroid (i.e., v2 and v2) still seem to have this flaw. We are working with the developers on a solution.

A significant observation from the Table 3 is that the tools that directly inherit FlowDroid (i.e., IccTA, DidFail) are similarly flawed as FlowDroid. This is especially true when the tools do not augment FlowDroid in any manner, and use it as a black box (RQ2). On the contrary, Argus, which is motivated by FlowDroid’s design, but augments it on its own, does not exhibit as many flaws.

Also, BlueSeal, HornDroid, and DroidSafe use a significantly different methodology, and are also not susceptible to these flaws. Interestingly, BlueSeal and DroidSafe are similar to FlowDroid in that they use Soot to construct a control flow graph, and rely on it to identify paths between sources and sinks. However, BlueSeal and DroidSafe both augment the graph in novel ways, and thus don’t exhibit the flaws found in FlowDroid.

Finally, our analysis does not imply that FlowDroid is weaker than the tools which have fewer flaws in Table 3. However, it does indicate that the flaws discovered may be typical of the design choices made in FlowDroid, and inherited by the tools such as IccTA and DidFail. A similar deep exploration into the results of μSE for the other tools may be explored in the future (e.g., of the 83 uncaught leaks in DroidSafe from Section 6).

# 7 Discussion
μSE has demonstrated efficiency and effectiveness at revealing real undocumented flaws in prominent Android security analysis tools. While experts in Android static analysis may be familiar with some of the flaws we discovered (e.g., some flaws in FC1 and FC2), we aim to document these flaws for the entire scientific community. Further, μSE indeed found some design gaps that were surprising to expert developers; e.g., FlowDroid’s design does not consider callbacks in anonymous inner classes (flaws 8-9, Table 3), and in our interaction with the developers of FlowDroid, they acknowledged handling such classes as a non-trivial problem. During our evaluation of μSE we were able to glean the following pertinent insights:
Insight 1: Simple and security goal-specific mutation schemes are effective. While certain mutation schemes may be Android-specific, our results demonstrate limited dependence on these configurations. Out of the 13 flaws discovered by μSE, the Android-influenced mutation scheme revealed one (i.e., BroadCastReceiver in Table 3), while the rest were evenly distributed among the other two mutation schemes; i.e., the schemes that evaluate reachability or leverage the security goal.

Insight 2: Security-focused static analysis tools exhibit undocumented flaws that require further evaluation and analysis. Our results clearly demonstrate that previously unknown security flaws or undocumented design assumptions, which can be detected by μSE, pervade existing Android security static analysis tools. Our findings not only motivate the dire need for systematic discovery, fixing and documentation of unsound choices in these tools, but also clearly illustrate the power of mutation based analysis adapted in security context.

Insight 3: Current tools inherit flaws from legacy tools. A key insight from our work is that while inheriting code of the foundational tools (e.g., FlowDroid) is a common practice, some of the researchers may not necessarily be aware of the unsound choices they are inheriting as well. As our study results demonstrate, when a tool inherits another tool directly (e.g., IccTA inherits FlowDroid), all the flaws propagate. More importantly, even in those cases where the tool does not directly inherit the code.

base, unsound choices may still propagate at the conceptual level and result in real flaws.

# Insight 4:
As tools, libraries, and the Android platform evolve, security problems become harder to track down. Due the nature of software evolution, all the analysis tools, underlying libraries, and the Android platform itself evolve asynchronously. A few changes in the Android API may introduce undocumented flaws in analysis tools. μSE handles this fundamental obstacle of continuous change by ensuring that each version of an analysis tool is systematically tested, as we realize while tracking the Fragment flaw in multiple versions of FlowDroid.

# Insight 5:
Benchmarks need to evolve with time. While manually-curated benchmarks (e.g., DroidBench ) are highly useful as a "first line of defense" in checking if a tool is able to detect well-known flaws, the downside of relying too heavily on benchmarks is that they only provide a known, finite number of tests, leading to a false sense of security. Due to constant changes (insight #3) benchmarks are likely to become less relevant unless they are constantly augmented, which requires tremendous effort and coordination. μSE significantly reduces this burden on benchmark creators via its suite of extensible and expressive security operators and mutation schemes, which can continuously evaluate new versions of tools. The key insight we derive from our experience building μSE is that while benchmarks may check for documented flaws, μSE’s true strength is in discovering new flaws.

# 8 Related Work
μSE builds upon the theoretical underpinnings of mutation analysis from SE, and to our knowledge, is the first work to adapt mutation analysis to evaluate the soundness claimed by security tools. Moreover, μSE adapts mutation analysis to security, and makes fundamental and novel modifications (described previously in Section 4). In this section, we survey related work in three other related areas:
# Formally Verifying Soundness:
While an ideal approach, formal verification is one of the most difficult problems in computer security. For instance, prior work on formally verifying apps often requires the monitor to be rewritten in a new language or use verification-specific programming constructs (e.g., verifying reference monitors , information flows in apps ), which poses practical concerns for tools based on numerous legacy codebases (e.g., FlowDroid , CHEX ). Further, verification techniques generally require correctness to be specified, i.e., the policies or invariants that the program is checked against. Concretely defining what is “correct” is hard even for high-level program behavior (e.g., making a “correct” SSL connection), and may be infeasible for complex static analysis tools (e.g., detecting “all incorrect SSL connections”). μSE does not aim to substitute formal verification of static analysis tools; instead, it aims to uncover existing limitations of such tools.

# Mutation Analysis for Android:
Deng et al.  introduced mutation analysis for Android and derived operators by analyzing the syntax of Android-specific Java constructs. Subsequently, a mutation analysis framework for Android (μDroid) has been introduced to evaluate a test suite’s ability to uncover energy bugs . μSE incorporates concepts from the general mutation analysis proposed by prior work (especially on Android ), but adapts them in the context of security. We design mSE to focus on undetected mutants, providing a semi-automated methodology to resolve such mutants to design/implementation flaws (Section 4). The derivation of security operators (Section 4) represents a notable departure from traditional mutation testing that seeds simple syntactic code changes. Our mutation schemes (Section 4) evaluate coverage of OS-specific abstractions, reachability of the analysis, or the ability to detect semantically-complex mutants, providing the expressibility necessary for security testing, while building upon traditional approaches. Further, μSE builds upon the software infrastructure developed for MDROID +  that allows a scalable analysis of mutants seeded according to security operators. In particular, μSE adapts the process of deriving a potential fault profile for mutant injection and relies on the EE to validate the mutants seeded according to our derived security operators.