# 8. Peer App Voting
User-device interaction analysis for privacy disclosure legitimacy may incur high false negatives, since an interaction does not always mean “intention.” Another approach is to extract the “standard/common privacy disclosures” from functionally similar peer apps, and then compare the suspicious privacy disclosures with the extracted “standard set.” If the disclosure is a privacy leak, it will generally not be included in the “standard set” since its peer apps do not have such leaks. AAPL [Lu et al. 2015] provides a framework to automatically infer privacy disclosures legitimacy based on peer voting mechanism. As the peer apps are selected based on similar functionalities, detection of privacy leaks that are not functionally required may have high false rates, for example, detection device ID and phone number.

According to AAPL, about 67% of detected privacy disclosures are in fact legitimate. With an automated approach to differentiate legitimate privacy disclosures from suspicious ones in demand, we strongly hope more researchers can contribute to this direction in the future.

# 8. Identifying Malicious Behavior
As malicious apps pose increasing threats to the Android ecosystem, a series of malicious app detection mechanisms has been proposed. Based on the detection methodologies, we categorize them into four types: execution-based detection, model checking, WYSIWYX, and machine learning, as shown in Table VII.

# 8. Execution-Based Detection
Abnormal behavior detection using sequences of system calls has been successfully applied on the intrusion detection domain, as the sequence of system calls executed by the program is a good indicator between normal and abnormal behaviors. Higher level semantics such as ICC through Binder IPC/RPC.

ACM Computing Surveys, Vol. 49, No. 2, Article 38, Publication date: August 2016.

# 8. Model Checking
The general idea on model checking is to treat the Android platform as an “event-driven” system and model the interactions of an app with the platform. Checking these interactions will help catch some abnormal behaviors, for example, SMS is sent without user’s consent (i.e., click the “send” button).

# Table VII. Categorization of Algorithms for Identifying Malicious Behavior of Apps
or Dalvik VM traces are additional features that Android app analysis techniques can leverage to improve detection accuracy.

Following this intuition, two QEMU-based solutions, DroidScope [Yan and Yin 2012] and CopperDroid [Kimberly et al. 2015] are proposed to both capture OS-level event sequences (system calls) and higher level semantics. However, malicious apps can use emulator detection techniques to prevent itself from exhibiting malicious behaviors inside an emulator [Kirat et al. 2014].

Another line of research focuses on achieving the same goal by sandboxing apps inside a real Android device instead of whole system emulation/virtualization. NJAS [Bianchi et al. 2015] builds an app sandbox with ptrace-based syscall interposition. It also hooks Binder IPC calls to mediate interaction with the Android framework. Boxify [Backes et al. 2015] leverages the isolated process feature introduced in Android 4 to sandbox a target app and also completely mediates its interaction with the framework. In addition, Boxify can launch multiple apps in the same sandbox, and hence, could potentially capture collusion attacks that requires cooperation of multiple independent apps. Both works are capable of fine-grained information recording without the need of kernel or Android framework modification. However, sandbox-based solutions always suffer from attacks that attempt to escape them, as shown in the Chrome sandbox case [Fisher 2015]. Because the sandbox itself is usually highly privileged, compromising the sandbox yields more benefits to the attackers than compromising a normal app.

# Toward Engineering a Secure Android Ecosystem: A Survey of Existing Techniques
# 8. WYSIWYX
What You See Is What You eXecute is an intuitive policy aiming to ensure that the actual app behaviors should be consistent to users’ perceptions: a functionality not stated or implied in the app description should not be allowed. Checking WYSIWYX is usually done by text analytics with the help of recent development of Natural Language Processing (NLP).

WHYPER [Pandita et al. 2013] and AutoCog [Qu et al. 2014] discussed in Section 4 extract permissions advertised in the app’s description, and compare them with permissions actually requested. CHABADA [Gorla et al. 2014] and ACODE [Watanabe et al. 2015] first reduce the app descriptions into a set of keywords/topics and then measure whether the actual APIs used in the app confirm with these topics. AsDroid [Huang et al. 2014] first extracts and analyzes UI text to infer the criteria behaviors of the apps, and then matches them with the actual app behaviors to uncover contradicted or stealthy activities. However, WYSIWYX approaches are vulnerable to fake description and dynamic UI text manipulation.

# 8. Machine Learning-Based Detection
To achieve effectiveness and scalability of Android malware detection, machine learning-based approaches are well explored and promising. The basic idea is to first statically or dynamically analyze the app to gather a predefined set of features, and then learn a detection model based on given datasets consisting of malicious apps and benign apps. For example, Hao et al.  builds probabilistic generative models using requested permissions and app categories to rank their risks. DroidAPIMiner [Aafer et al. 2013] considers package-level information as well as API call sequences and parameters to distinguish malicious apps. The state-of-the-art system, Drebin [Arp et al. 2014], not only uses the explained features, but also considers other features such as intents, requested hardware components, and network addresses. Its detection rate is up to 94% with a false positive rate of only 1%. Droid-SIFT [Zhang et al. 2014c] extracts a weighted contextual API dependency graph to represent program semantics (i.e., feature set) and further uses graph similarity metrics to uncover potential malware variants. MUDFLOW [Avdiienko et al. 2015] detects malware based on the intuition that malicious apps treat sensitive data differently from benign apps, and hence, can be captured by identifying abnormal dataflow.

However, it is noteworthy that (1) the accuracy of machine learning-based detection is highly dependent on the quality of datasets used for training; and (2) the detection may be easily bypassed if the attacker can figure out how the features are combined for malware indication. Two reports on machine learning-based Android malware detection [Allix et al. 2014; Roy et al. 2015] both show that the detection results are significantly biased when fed with different malware datasets for training. Also, it is suggested that security research should not produce approaches or techniques that are not in line with reality, for example, the detection results of Drebin, which is derived from a “predefined” sample of 5,560 malware may be biased from the ones derived from other app datasets that are crawled from real app markets. So, we hope to see in the future that machine learning-based malware detection approaches can choose app datasets that are consistent with both reality and other competitive approaches as training and evaluation sets, for example, the top 1,000 apps that are most commonly installed by users.

ACM Computing Surveys, Vol. 49, No. 2, Article 38, Publication date: August 2016.

# 8. Test Automation Tools
The effectiveness of dynamic analysis in detecting privacy disclosure or malicious behaviors relies significantly on test automation tools to drive the app. Therefore, a large number of techniques has been proposed to better automate Android app testing.

AndroTest [Shauvik et al. 2015] provides a comprehensive summary and comparison of existing Android testing tools. Based on exploration strategy, current testing methods are categorized into three classes: random, model-based, and systematic. Dynodroid [Aravind et al. 2013] is based on random exploration, but its exploration technique is claimed to be more efficient than Monkey, the default testing tool that comes with the Android SDK. MobiGuitar [Amalfitano et al. 2015] dynamically builds a model of the app under testing by crawling it from a starting state. AppsPlayground [Rastogi et al. 2013], A3E [Tanzirul and Iulian 2013], SwiftHand [Wontae et al. 2013], and PUMA [Shuai et al. 2014] are all similar to MobiGuitar with different static analysis and exploration strategies.

Acteve [Saswat et al. 2012] is a concolic-testing tool that symbolically tracks events from the point where they are generated in the Android framework up to the point where they are handled in the app. In contrast, Evodroid [Mahmood et al. 2014] relies on evolutionary algorithms to generate relevant inputs. Harvester [Rasthofer et al. 2016] provides new insights on automated test driving. Different from other approaches that start path finding from program entry points and explore down to the point-of-interest, Harvester first performs backward slicing from the point-of-interest and extracts the minimal code required to trigger the target from a program entry point, hence, significantly improving the efficiency of app testing.