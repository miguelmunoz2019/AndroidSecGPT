Expected Coverage (EC) = n
A higher EC reflects the APPG has less intrinsic design flaws about disclosing permissions in generated privacy policies.

We use the intersection of privacy policies identified by both FKS and DSC (2,042 privacy policies) because it is more certain that they are generated by one of the APPGs. Based on our observations in Section 2, four APPGs (#2, #5, #6, #10) do not support permission declarations, in other words, Precognised = 0 for every app identified to use those APPGs. In addition, we find that Pdisplayed = 0 for four of those apps, which means that none of the developers realised that the APPG they used did not cover the permissions they claimed.

The results are shown in Table 9. First, for #1 and #3, they both can recognise all nine device permissions involved in this study, so their RCs are equal to ECs. There is a significant portion of missing permission disclosure for all APPGs, since all ECs are much smaller than 100%. The missing disclosure issue is not dependent on users’ input, but on the design of APPGs that did not sufficiently accommodate the requirements. Second, compared to #1’s and #3’s consistency on RCs and ECs, for #4, #7, #8, and #9, their ECs are greatly smaller than RCs. The gap shows the importance of APPG selection, because inappropriate APPGs will hinder developers from including self-reported (claimed) permissions in their privacy policies. Third, #1 has the lowest RC, but it has high level user instruction; whereas #4, #7, and #9 has the relatively high RCs, but low level of user instruction. This counter-intuitive result indicates that current user instructions are not helpful enough to guide developers to correctly include permissions in the generated policies. In addition, #1 is the only UI-mode APPG, with the lowest RC (15%), and other comparable APPGs, whose RC is over 50% are all questionnaire-mode. This observation indicates that UI mode APPGs may be more challenging to be properly used by users.

# Finding 3:
A significant portion of device permissions remain under-claimed, perhaps caused by APPGs’ design issues, and questionnaire mode can better guide users to include claimed device permissions compared to UI mode.

# 4 Contradiction Analysis
Previous works have discussed contradictions within a policy . Specifically, if affirmative and negative sentences mention the same or conflicting entities and data types in a policy, then there can be a contradiction. In this section, we compare the APPG-based and non-APPG-based privacy policies, to examine the situation of contradiction issues in both and the effect introduced by APPGs. For non-APPG-based privacy policies, we used the test set from PoliCheck  which contains 200 policies randomly sampled from 13K mobile apps. For APPG-based privacy policies, we use 30 policies from the “Generated Privacy Policy Collection” and 170 policies that are randomly sampled from the intersection list (indicated as APPG-generated by both FKS and DSC). We employ the state-of-the-art privacy policy analyser, PoliGraph , to conduct the following analysis.

We observed 26 contradictions in APPG-based privacy policies and 15 in non-APPG-based policies, indicating a potential tendency for APPGs to introduce more privacy policy contradiction issues. Closer examination revealed that a significant portion of these contradictions in APPG-based policies arise from conflicting statements present in different sections of the document. For example, one section of the policy explicitly states “[A condition], we sell your personal information to third parties”, while an assertion in the CCPA section contradicts this by claiming “[The App] has not disclosed or sold any personal information to third parties for a business or commercial purpose in the preceding 12 months.”. Therefore, it is imperative for APPG users to exercise caution and meticulously evaluate the coherence and consistency between different sections of generated privacy policies.

# Finding 3:
More privacy policy contradiction issues exist in APPG-based privacy policies.

# 5 Discussion and Implication
Challenges and opportunities coexist in the current APPG development. Based on our observations and study results, we summarize some findings for various roles or stakeholders in the APPG ecosystem.

App developers/APPG users. While app developers may benefit from using APPGs to create privacy policies more efficiently, they should be aware of APPGs’ latent limitations. As illustrated in Section 2, APPGs have different qualities. Some do not directly target specific regulations, such as GDPR and CCPA, and some do not recognise data practices, i.e., the declaration of personal information, device permissions, and third-party services used in their mobile apps. Since app developers must make sure the privacy policies they provide are comprehensive, readable, and compliant, it is very likely a trap if they do not select and use appropriate APPGs.

# 6 Related Work
Privacy policy analysis. Privacy policies have been extensively analysed and discussed by the research community . Wilson et al.  created a corpus of 115 privacy policies and 23K fine-grained data practise annotations, and revealed users’ preferences on privacy policy structure and complexity. Amos et al.  reported that privacy compliance and readability were worse in the last 20 years, according to 130k website privacy policies. Andow et al.  presented PolicyLint, which is a privacy policy analysis tool that can identify privacy contradictions by simultaneously considering negation and varying semantic levels of data objects and entities. Bui et al.  proposed an automated system, dubbed PurPliance, that detects inconsistencies between the data-usage purposes stated in a privacy policy and the actual behaviours of an Android app.

Code-centric privacy policy auto-generation tools. Yu et al.  developed a system named AutoPPG, to automatically construct readable descriptions from the source code of mobile apps, to help create privacy policies on Android. Rocky Slavin  developed PoliDriod, an Android Studio plugin that can be used to detect possible misalignments between Android API methods and privacy policies. Zimmeck et al.  proposed a privacy policy generator, named PrivacyFlash, which leverages mappings between code signatures and privacy practises expressed in policies for iOS apps. While code-centric generators might better align with apps’ actual privacy behaviours compared to online APPGs, they come with significant challenges that hinder their adoption by app developers. First, they cannot ensure compliance with high-level privacy regulations, particularly non-functional requirements. Second, they present a higher entry barrier for developers due to their inherent complexity, whereas online APPGs can be easily accessed, offering a range of user instructions and publishing support as demonstrated in this study. Others  also discussed the automated generation of privacy policies using machine learning methods.

# 7 Conclusion
Online Automated Privacy Policy Generators (APPGs) are broadly used by developers of mobile apps to create privacy policies to respond to regulatory requirements. This paper reports the first large-scale empirical study to comprehensively scrutinize APPGs’ various features, characteristics, and extent of recognition of data use. Our market penetration analysis indicates that privacy policies of 20% apps could be generated by existing APPGs on the Google Play app store, and that #2 is the most popular APPG, with a 72% adoption rate. Our findings underline a substantial level of noncompliance with privacy laws and a frequent under-claiming of data rights and highly concerning privacy practices, especially with the most popular APPG #2. Permissions coverage analysis reveals that existing APPGs have significant issues with including all essential device permissions in the generated privacy policy, and UI mode APPGs could make it worse. Also, more contradiction issues exist in APPG-based privacy policies. In summary, for app developers, selecting and employing APPGs without careful consideration is very likely a trap, creating a substantial risk of breaching privacy regulations.

# Appendix
# Readability Analysis
The readability score of privacy policies are calculated by the Flesch Reading-ease Test :
206 − 1 total words − 84 total syllables
total sentences total words
Specific readability scores are listed in the Table 10.

# GDPR and CCPA requirements compliance
The specific requirements and compliance checking for GDPR and CCPA are tallied in Appendix Table 11 and Table 12..