# E. Experimental Setup
# 1) Execution Environment:
Experiments at the scale considered in our study are challenging, requiring a significant amount of memory, storage disk as well as computing power. The retrieval of apks from the AndroZoo repository alone took seven days and occupied 56 TB of local storage space. Among the vulnerability detection tools, FlowDroid and IC3, as previously reported in the literature , are heavy in terms of resource consumption. Fortunately, we were able to leverage a high performance computing (HPC) platform , using up to 80 nodes, to run as many analyses as possible. We use the fully parallel capability of the HPC platform and we automated the analysis scenarios with Python scripts: FlowDroid analyses occupied 500 cores and consumed 240 CPU hours to scan 223 474 apks; IC3 occupied 200 cores and consumed 360 CPU hours to scan 72 983 apps. AndroBugs light scanning only took 13 CPU hours with 500 cores to go through 458 814 apks.

Overall, we obtained results for 454 799 apks of 27 974 lineages by AndroBugs, 37 736 apks by FlowDroid, and 30 042 apks by IC3 with 3 357 and 2 048 lineages, respectively. The final raw results hold in about 40 GB of disk space. There are two reasons that caused the different numbers in the result of different tools. One is because of the limited time budget for running analysis. As we know from the previous paragraph that AndroBugs is the lightest tool in resource requirement, we collected the most results from its analysis. On the contrary, IC3 is the heaviest tool that got the least results. Meanwhile, some apks could cause crashing of certain detection tools, and normally, different tools crash on different apks. This is another reason that leads to a different number of analysis results in different tools.

# False positives of the selected static analysis tools:
It is known that static analyzers will likely yield false positive results. Toward evaluating the severity of this impact, we resort to a manual process to verify some of the results. Because manual verification is time consuming and may require training in understanding vulnerability types, we restrict ourselves within a working day to conduct the manual verification of a sampled set of vulnerabilities.

Specifically, we invited two Ph.D. students who have been working on Android and static analysis related topics to work on the reports of the three selected tools, respectively.

Default sources and sinks configuration file provided with the FlowDroid source code was used in this study. It can be obtained from the GitHub repository under directory “soot-infoflow-android.” Since the obtained results for different vulnerabilities (i.e., tools) are different, the percentages calculated in the rest of this article are based on the analyzed apks of a certain vulnerability.

This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.

# GAO et al.: UNDERSTANDING THE EVOLUTION OF ANDROID APP VULNERABILITIES
student spent one day on sampled reports13 of AndroBugs and another one spent two days on the reports of IC3 and FlowDorid, respectively. They are able to check 711 vulnerabilities14 for AndroBugs, 275 vulnerabilities (98 of intent spoofing and 177 of unauthorized intent reception) for IC3 and only 78 leaks for FlowDroid. The manual verification process confirms that, at least from the syntactic point of view (i.e., these vulnerabilities are in conformance with the definition of vulnerabilities as proposed in the tools documentation), the results reported by the adopted static analyzers are all true positive results. The students, however, admit that they are only able to focus on checking simple syntactic rules for validating the results. It is time consuming and sometimes very hard to follow the semantic data flows within the disassembled Android bytecode. Indeed, Android apps are commonly obfuscated, making it difficult to understand the code manually. Even without obfuscation, it is also nontrivial to understand the intention behind the code if no prior knowledge is applied.

Moreover, in addition to checking real-world Android apps via disassembled bytecode, which is known to be difficult, we conducted another experiment with a set of open-source apps, in the hope that these apps could help us better validate the reported static analysis results. To this end, we randomly selected 200 apps from F-Droid and conducted the same experiments as for the close-source apps. Interestingly, the results of this experiment are more or less the same to that of close-source apps. We have only observed one false positive for FlowDroid. Among the 200 open-source apps, FlowDroid reported that 45 of them contain sensitive data flows. We manually investigated 15 of them (i.e., developers’ code14 were manually checked) accounting for 29 leaks. Out of 29 reported leaks from these apps, we spot one false positive, which was found in app idv.markkuo.ambitsync. The false positive is caused by an incorrectly generated dummyMainMethod. For FlowDroid to construct call graphs for Android apps, a dummyMainClass containing several dummyMainMethods is required to be instrumented. However, in this case, the dummyMainMethod is incorrectly generated, which further leads to a nonexist path, and hence, a false-positive result. Similar validations were done for Androbugs and IC3 as well, while no false positives were spotted.

Furthermore, it is worth to mention that the three static analyzers we selected in this work have been recurrently leveraged by a significant number of state-of-the-art approaches to achieve various purposes. For example, FlowDroid’s results have been leveraged by Avdiienko et al.  to mine abnormal usage of sensitive data, Cai et al.  leverage IC3 to understand Android application programming and security, while Taylor et al.  have leveraged AndroBugs to investigate the evolution of app vulnerabilities. Moreover, there are studies focusing on analyzing and comparing analysis tools too. Qiu et al.  compared the three most prominent tools, which are FlowDroid, AmanDroid, and DroidSafe and discussed their accuracy, performances, strengths, and weaknesses, etc. Meanwhile, Ibrar et al.  studied vulnerability detectors of mobile security framework (MobSF), quick Android review kit project (QARK), and AndroBugs framework with banking apps. In the aforementioned two works, they all discussed the false positive issues of the tools. According to their results, FlowDroid and Androbugs both performed the best among their kind of tools in terms of false positives. Therefore, from the false positive point of view, we can conclude that the tools we have chosen are the most reliable among other counterpart tools.

# Study Protocol:
Each of the vulnerability detection tools outputs its results in an ad hoc format. We build dedicated parsers to automatically extract relevant information for our study. Fig. 9 provides quantitative details on the distributions of vulnerable apks in the lineages dataset. SSL vulnerabilities are widespread among Android apps and across several apk locations. We also note that a large majority of apps may include a large number of sensitive data flows. As these leaks reveal private information, although for most of them, how the sensitive data will be used is unknown, we should consider them as vulnerabilities.

For the evolution study, vulnerable pieces of code are extracted from the location l of an apk indicated by the vulnerability detection tools. These vulnerable pieces of code are collected and released as a valuable artifact for the community. Real-world examples from this artifact were presented in Section II-B2.

Finally, we monitor and record how vulnerabilities change at these locations that is: given the analysis results for an apk v1 and its successor v2 of a lineage, we track the differences in terms of vulnerability locations; when a given vulnerability type is identified in a location but is no longer reported at the
This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.

# 10
# IEEE TRANSACTIONS ON RELIABILITY
same location, we compute the change diff between the two apk versions and refer to it as potential vulnerability fix changes. 15
# III. RESULTS
We now investigate the evolution of Android app vulnerabilities. Our objective in this work is to understand the evolution of Android app vulnerabilities, and thereby, to recommend actionable countermeasures for mitigating the security challenges of Android apps.