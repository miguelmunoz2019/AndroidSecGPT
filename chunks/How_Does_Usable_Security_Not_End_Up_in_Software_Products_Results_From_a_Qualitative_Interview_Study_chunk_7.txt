We hoped to obtain concrete requirements for usable security, but as a rule, the processes analyzed tend to indicate that usable security is a requirement, which also arises naturally, but where the basis is not the individuals themselves, but rather the project focus and the corporate culture. To the companies that we have classified as aware it was rather clear to the team members that the project focus was on usable security. However, we have seen at certain companies (cf. Section IV-D) that were aware but failed to implement usable security measures. Neither participants who talked about a specific case nor participants who gave us a more high-level view of their experiences mentioned any compliance standards or guidelines related to usable security. In contrast, we heard about security guidelines or standards more frequently. P19 described a case where she was in a conflict with a decision-maker about removing security questions from the product for multiple reasons. In the end, she lost the fight because she did not have any evidence to convince her superior:
“I didn’t have evidence to bring to the table [. . .]. That would have been a lot easier. [. . .] Trying to explain usability without a ton of evidence isn’t gonna get you very far. I wasn’t able to find anything [. . .] worthwhile. You know, sometimes you win, sometimes you lose.” (P19)
# H. Structures and Attitudes that Contribute to Usable Security
This section highlights and relates the structures and attitudes that we identified in the above classification as more positively related to the ability to deal with usable security challenges. We consider a holistic understanding of usable security as necessary so that suitable measures can be established. We have seen that some decisions have been made contrary to results of previous usable security research due to fundamental misconceptions (e. g., some development teams still believing the trade-off myth).

# 1) Communication Pivot:
In all contexts showing user-centered characteristics that we classified as being aware of usable security, we found a person who formed the communication bridge between both worlds, usability and security:
“Yeah, so that was one security part of it [. . .] Especially in the beginning [. . .], what can the developers actually do on that team, and what are their capabilities in the time frame and the money that we had. So, yeah, the developers were included in the discussion with all the security issues from the beginning.” (P14)
Those people with background knowledge in security were not left out but actively involved in the design process. We also observed a strong collaboration between UX experts and security experts in the case of P13.

designers were actively involved during threat assessment with the security experts. However, the designer or UX expert does not always have to be the driver for usable security. In three of five cases in Section IV-B, a security expert was the pivot for communication about usable security in the software teams. We also observed that the domain knowledge of security and usability was more pronounced in either one of the areas. P13 described that the design team was involved during a threat assessment.

# 2) Open Attitude and Commitment Towards Usability:
We have seen that the development teams of most companies whose processes we classified as having user-centered characteristics were given the time and resources to apply user-centered methods. In most of the contexts, as described in Sections IV-B and IV-C, participants showed an open attitude towards usability and its value for the customer and the business: “The main and the most important request from the management was: they need an easy-to-use software or app or interface to compete with other competitors” (P21).

# 3) Access to Real Users and Feedback:
Participants reported two products, one partly (P6), one completely open-source (P2). Both described how they leveraged their user communities to collect feedback. P2 said that they had access to communities all over the world and dedicated contact persons who are in contact with specific user groups via forums and emails. Those communities provided not only comprehensive feedback but were also the source of substantial new requirements. In other contexts which had developed usable security, users were also actively involved in the development. For example, in C5, users were invited to a laboratory to test the software prototype.

# 4) Knowledge About User-centered Methods and (Usable) Security:
In six contexts, we found awareness of the importance of usable security, but the processes were not very user-centered (Section IV-D). Although the lack of resources was often mentioned as a reason for lacking measures (Section IV-G1), participants reported individual user-centered measures, such as personas or prototyping, being used because they were considered rather low-cost. In another case, beta-testing with users and collecting feedback in high-security environments was not possible due to confidentiality reasons: “No, unfortunately [a beta group is] not possible. For the same reason, we don’t get feedback from users.” (C13).

# V. IMPLICATIONS
In this section, we discuss the implications of our findings for academia and the software industry. First, we summarize our results and discuss the major factors that enable or prevent usable security in development organizations as well as identify actions that organizations that espouse usable security as a goal could take to enable and support developers.

# A. Factors Impacting Usable Security
Lack of Awareness. The development processes our participants described revealed fundamental misconceptions of usable security. Misconceptions are not necessarily shortcomings of them as individuals but can be a shared lack of understanding in software development contexts (Section IV-G2). Many of our participants had an apparent misunderstanding of the connection between usability and security (Section IV-E) or suggested having to sacrifice one to achieve the other (see section IV-G2). Some participants stated usability not to be a specific skill set, but some common knowledge developers would implicitly have. In these development contexts, user-centered methods were neither available nor applied (Section IV-C).

Missing Knowledge of User-Centered Methods. Some interviewees were aware of the potential benefits of making security features usable. However, they lacked the means to implement usable security (Section IV-D). Across all our interviews, only a few user-centered methods were mentioned. Hence, there seems to be a lack of usability security knowledge in many software teams (Section IV-H4). The methods the participants were aware of were often not applied due to a lack of resources (Section IV-G1). Even in the face of limited resources and time constraints, developers could engage with usability for security features by applying established heuristics such as Nielsen’s “10 Usability Heuristics for User Interface Design”.

Communication Barriers. In some contexts (Section IV-G3), usability expertise was available in the form of specialists, but individual development teams did not consult them. When usability was seen as easy, consulting experts was considered a waste of time. Usable security is an interdisciplinary field where knowledge from both domains must be brought together to craft an effective security mechanism that does not overburden end-users (Section IV-H1).

# B. Decision Making
In the case of development teams that miss resources to implement usable security or that have the required skills available but do not apply them, adapting structures and processes can help. Functional requirements are frequently defined during requirements engineering. Depending on the level of requirements details, developers need to make their own decisions. Fine-grained requirements evoke the interaction between end-users as well as the system and reduce the likelihood of inappropriate assumptions made by developers. Some participants reported that more rigorously specified design drafts were created in collaboration with one or more technical experts (cf. Section IV-B). Decisions affecting the usability of the product were made by different stakeholders. We rarely identified active decisions for or against usable security: Decisions affecting usable security are often not debated or a source of conflict; they do not seem important enough to invest much effort. These findings illustrate that many of our participants (see Sections IV-C, IV-E) lack usable security awareness and the consequences of not taking care of it.

# C. Recommendations for Industry
Development organizations need to recognize that usable security requires effort and does not come for free with security alone. On one level, making something usable seems easy enough – but it requires basic resources and skills to deliver it. Assuming that developers will take care of a quality attribute that is not clearly specified, and for which nobody has been given responsibility, is wishful thinking – especially when time and resources are always tight. It requires changes to the development process that need to be managed and given resources. In the following section, we present two approaches that could support companies in taking a step further towards usable security.

# 1) Climbing the Competence Curve
Different types of interventions are needed to help software teams climb the competence curve:
1. Build up awareness for usable security.

2. Impart knowledge to those involved.

3. Integrate and consolidate measures into the company’s daily routine.