# 4 APP STIMULATION TOOL EVALUATION
This section evaluates different features provided by app stimulation tools (Table 1). We explain the different options that are not self-explanatory and list pros and cons of each method. The column UI Events indicates if a tool is able to perform basic UI events such as tap and swipe actions. Context aware input indicates the capability to fill out login forms or address fields. System events are capabilities to trigger broadcast messages if a photo was taken or the device screen went on/off. The Instrumentation column tells how the UI interaction is executed. This can either be a modified operating system (OS), an instrumented test app or no instrumentation at all using build in functionality. Modified operating systems are powerful but time intensive to maintain. Modifications have to be at least yearly renewed for new Android versions. Instrumenting the application has the advantage, that activities can directly be triggered. A disadvantage is that this requires repacking the app, which is detectable by the app. Some tools do not require instrumentation and thus rely on Androids inbuilt ADB. The disadvantage of this method is that the feature set is limited. Different exploration strategies exist to interact with UI elements: Random (rnd), Model-based (model) and Systematic (sys). Random approaches randomly trigger UI interactions and usually fire them at high rates. It is common to define seed, to make interaction consistent and reproducible. The advantage of this approach is that it often achieves high UI exploration coverage, mainly due to the high event firing rate. A disadvantage is, that it gets stuck at login screens without further context awareness. High event firing rates often reveal app crashes, which is good for finding bugs, but undesirable for a security and privacy analysis. Model-based exploration often generates a finite-state-machine to model the different app activities as states and the event input combinations to move from one state to another. Advantage of this approach is that different activities can be explored more directly and the tool can easily come back to certain activities in the model to fully explore all available activities. A disadvantage is that it is rather slow, since dumping the UI elements and assigning states requires much computation . Thus, random approaches often achieve the same or higher UI coverage than
# EICC, November 10–11, 2021, Virtual Event, Romania
# Heid and Heider
a model based approaches. Another challenge is to model states without a state explosion[21 , 41]. The last option is a systematic approach. This approach defines certain rules to interact with the UI. For example start clicking buttons from left to right or first fill in text fields before pressing buttons. This approach also allows login handling. The biggest disadvantage of this approach is that the systematic interaction rules have to be carefully designed reach all activities and not get stuck. To overcome this flaw, random exploration is often additionally used. In the context of vulnerability and privacy analysis, a systematic or model-based exploration strategy seems favorable to overcome the login and context aware inputs which are not provided by fully random approaches. A static app analysis can be used to get insights of the app to be explored. For example how many activities are defined and from which activities one can switch to other activities [ 6]. This item is rated neutral due to the additional effort and few advantages in UI exploration coverage [38 ]. The column Device Type indicates if the tool runs only on a real hardware (dev) or just uses an emulator (emu) or runs on both. A tool supporting devices and emulators is preferable, since both have their advantages. Emulators scale very well in parallel on powerful servers. However, some apps refuse to run in emulators. Real devices are more costly and harder to maintain but are capable to run all apps. Thus, a mix of emulators and some devices seems perfect. To test apps, there are different test type methods: white-, gray- and black-box tests. Since the intention is to analyze stranger apps without source-code, only gray and black-box tests are feasible. The last feature is the ability to record and replay a test. This is a very important feature, as a detailed privacy finding. According to a survey of [ 45 ] in 2018, the most relevant publications are Dynodroid[ 30 ], A3E[ 6 ], Sapienz[ 32 ] and AndroidRipper[ 4]. Dynodroid lacks a license and seems to be not maintained since 2017. A3E is not maintained since 2016 and lacks generation of system events. Sapienz contains all desired features but is also not maintained since 2017. Android ripper lacks in generation of system events, a record and replay functionality and is also unmaintained since 2017. More recent tools with updates in 2019 to 2021 are: app-check, DroidMate, Google RoboTest, Monkey, REAPER and Stoat. DroidMate lacks in the generation of system events and additionally, DroidMate is unable to handle contextual input. Google RoboTest is an online service for dynamic app testing. Thus, it is good for finding bugs, but one can’t perform custom tests. The Monkey tool lacks in contextual input generation and would get stuck at every login screen. REAPER lacks in system event generation and record and replay functionality. Stoat only supports white-box testing which is unusable for testing closed-source apps.

# 4 App Stimulation Framework Evaluation
App stimulation frameworks are presented in the second part of Table 1. The property explanations match the ones in the previous section. Currently, only Appium, Quantum and Qmetry support the desired feature of generating system event, even though some events are only supported in the emulator. Quantum is a proprietary tool, only supporting white box tests and no record and replay. Qmetry integrates Appium, Selenuim/Webdriver and Quantum. Thus, it is rather a common interface for test automation. The focus of the framework lies on a test-driven development rather than generic app interaction, which shifts Qmetry out of the focus.

# Dynamic Android App Vulnerability and Privacy Analysis
# EICC, November 10–11, 2021, Virtual Event, Romania
# NETWORK MONITOR
For monitoring the network, features such as http(s) packet content inspection, SSL/TLS certificate exchange and packet modification are required. An API to control and export logs would be essential to properly interface the Network Monitor from the Control Logic.

There exist plenty of network inspection tools like the well known Wireshark. However, these tools tackle a too low inspection level. CharlesW and HTTP ToolkitW are easy-to-use proxies with a nice UI, but lack an external API, which makes it hard to control in an automated environment. FiddlerW is a closed-source tool with an almost two decade long history and provides a plenitude of features. However, it lacks an external control API and automation can only be achieved through JScript.NET extensions/scripts, a mix of .NET and JavaScript. ZAproxyW and Burp SuiteW is a proxy mainly designed for website security testing. ZAproxy offers a great API interaction interface for a variety of languages. However, both tools focus on web page pentests and omit required features such as packet and certificate modification. mitmproxyW is a well maintained open-source tool that offers a python API interface for external control and supports all required features. As a result, mitmproxy can be recommended as network monitor tool.

# CONCLUSION & FUTURE WORK
In this paper, we proposed an abstract design for dynamic Android app vulnerability and privacy analysis and discussed the necessary components of such an infrastructure. An extensive overview of available tools for each component is given and relevant tool properties are displayed in tables for easy comparison, updating outdated related overview papers. Different tools in each category are evaluated based on these aspects and promising ones are promoted. For app stimulation we recommended Appium and app-check, for behavior monitoring a suggestion to Objection and Frida is given in combination with mitmproxy as network monitor. To not share the fate of past overview papers, we propose continuously updated Github tables for everyone to edit. In summary, the available tools today are mostly not usable as plug-and-play. Much implementation effort is still required to achieve a dynamic app analysis environment. As future work, we intend to fill this gap and provide a plug-and-play solution in the context of dynamic Android app analysis. With this publication, we hope to give developers having the goal to generate a dynamic analysis environment a good introduction to the topic as well as a list of available tools at hand..