# Organizational Processes and Security Culture
In addition to individual factors that contribute to security, research has identified organizational processes and culture that impact software security , , , , , , . Haney et al. studied organizations developing cryptographic products  and found a strong security mindset as well as high expertise in cryptography. Thomas et al. conducted interviews with 32 application security experts and concluded that organizational processes and related factors must be improved to improve software security . In an interview study, Assal and Chiasson identified company culture as a reason that security best practices are not followed in software development life cycles (SDLC) . In another paper, Assal and Chiasson evaluated their assumptions quantitatively and concluded that security processes being followed depends more on organizational processes than individual develop-
ers . In an interview study, Votipka et al. found that good communication between hackers and software testers is important for finding vulnerabilities, leading to better security outcomes . Stevens et al. presented a case study evaluating the introduction and effects of threat modeling in an enterprise environment . They found that this is beneficial for the overall security, only leveraging existing resources. In 2019, Lopez et al. conducted an ethnographic study with software developers and concluded that awareness of security matters is raised through several paths, including processes, standards, practices, and company training, and that a focus on security is driven by contextual factors . Weir et al. found a high need for security, only 14–22% of Android developers have access to security experts, and identified the need for increasing the use of assurance techniques . They proposed and evaluated a set of lightweight assurance techniques that help developers create more secure software and raise awareness . The effectiveness was evaluated further in a long-term study.

In 2020, Shostack and Zurko underlined the need for research on secure software development techniques . However, there has been little research with a specific focus on usable security: In 2016, Caputo et al. conducted three exploratory qualitative case studies in large US companies that investigated organizations’ approaches to make their security products more usable . The authors identified barriers to this goal, namely that usability was perceived as less important than security and common sense, i. e., not requiring specialist knowledge or skills. In a preliminary study mainly with end-users, Iacono, Nguyen, and Schmitt analyzed requirements for usable security using a mixed-methods approach and identified the need for lightweight measures, e. g., models, patterns, guidelines, tools, and checklists . We recruited a set of developers from across the industry to see which contextual factors impact the SDP and usable security outcomes.

# III. METHODOLOGY
In this section, we explain the methodology of our interview study, including data collection and analysis (see Figure 1). We chose semi-structured interviews because of the exploratory nature of our research questions. It also affords the flexibility of letting participants relate their experiences with usable security – including practices we did not expect – while going into more depth with follow-up questions. The 25 interviews lasted on average 1:30:06 hours, were audio-recorded, and then transcribed by the authors. All interviews were conducted remotely between August 2020 and January 2021.

# A. Interview Guide
Here, we describe the process of iteratively developing our pre-questionnaire as well as the interview guide itself Instrument Development. We were interested in our participants’ professional experiences with usability, security, and hopefully, usable security. We developed our interview guide based on prior research on usable security  to investigate the roles that usability, security, and usable security play in the development processes of the companies our participants work at. All authors reviewed and iterated the interview guide. Two authors (who had worked as software professionals) tested the guide on each other, then piloted it with a colleague who also had professional software development experience as well as with the first participant. We adapted the guide after each round of feedback. After the interview with the first external pilot participant, very few minor edits were needed, so we included that participant in our sample.

Pre-Questionnaire. Based on the duration of the pilot interviews, we moved several interview questions into a pre-questionnaire which participants were asked to fill in after consenting to the study and before scheduling the interview The pre-questionnaire asks for participant demographics and a self-assessment of knowledge about and experience with usability and security; we referred to the participants’ pre-questionnaire answers during the interviews.

Interview Guide Structure. Our interview guide consists of three parts, each covering a category; first usability, second security, third the interplay, usable security. As we were interested in specific software development processes for usability, security, and usable security, we started the interviews by asking participants to think of a specific software project that contained a security feature with a user interaction component (e. g., login forms, warning messages) and tried to stay in.

895
Authorized licensed use limited to: IEEE Xplore. Downloaded on August 08,2024 at 04:02:25 UTC from IEEE Xplore. Restrictions apply.

# A. Interview Procedure
Those interested in participating in our study were sent to a landing page informing them about the study’s purpose and screened for eligibility for the interview. Then, they were shown our consent form where we informed them about how we would handle their data, their right to terminate the interview at any time without repercussions, and where they could agree to audio-recording and opt in to the interview being video-recorded. They were then asked to fill in a pre-questionnaire, after which they could schedule their interview.

# Interview Setup
We used a locally-hosted open-source, browser-based meeting tool for all interviews. All interviews were audio- and, if participants consented, video-recorded via the meeting tool’s functionality, and we captured audio locally as a backup.

# Interview Process
All interviews were conducted by the first author, when possible, with the support of one of the other authors, which allowed for supplemental questions, and, after the participant left the meeting, discussion and debriefing sessions. The interviews were conducted in English (n = 14) and German (n = 11).

# C. Recruitment
We wanted to recruit software professionals who could offer insights into how usability, security, and usable security are addressed, including software developers and software designers. Therefore, we used purposive sampling: we recruited participants who matched our criteria in terms of role and level of experience in software development. We recruited through all authors’ professional networks, via Reddit, Twitter, relevant Slack workspaces, and Upwork. We advertised the interview as a study for those “willing to share their professional experience with usability and security” with us. Participants qualified if they had professional experience with user interfaces or user interactions and professional experience with software security. They also needed to be willing to talk about a specific software development process (vs. only giving vague answers) We offered $1054 in compensation to be competitive with other job posts on Upwork and attract experienced developers. Moreover, for those interested in the topic, we invited them to participate in a workshop about usable security free of charge. We stopped recruiting after our interviews reached saturation.

# D. Demographics
We interviewed 25 participants; see Table I for an overview of participant demographics and Table III, and Appendix A for full participant details. The majority were from Germany and the US, and we also interviewed participants from India, Lebanon, Venezuela, and the United Arabic Emirates. We interviewed 20 men and 4 women. Participants’ ages range from 24 to 60 years, with an average of 35 years. This tracks with a high level of professional experience in the software industry with an average of 11 years and a maximum experience of 30 years. Our participants also reported a high level of formal education; 19 participants (76%) hold at least a Bachelor’s degree and 10 participants (40%) a Master’s or Doctorate degree. While most interviewees were software engineers, architects, or developers, we also interviewed participants who held founding or C-level roles, as well as usability, design, and front-end professionals. Almost half of the participants were recruited via the authors’ personal networks (n = 12). The majority of the rest was recruited via the freelancer platform Upwork (n = 10), while a small number were recruited via online communities and platforms (n = 1 for Twitter, Reddit, and Slack each).

# E. Transcript Analysis
Data Processing. Members of the research team transcribed the interview recordings. In addition to audio, notable reactions visible on video (such as “air quotes” or “raised eyebrows”) were also transcribed. During transcription, we replaced sensitive information like company names, personal information, or relationships with pseudonyms; some participants asked us to omit specific statements from our transcripts, a request that we honored. We matched the pre-questionnaire data to the appropriate transcript, then destroyed the recordings as promised in the consent form.

# TABLE I PARTICIPANTS’ DEMOGRAPHICS.