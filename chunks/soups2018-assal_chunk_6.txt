Security is not considered in post-development testing. (SI) According to their developers, two teams (T10, T15) do not consider security during this stage. T10 does not perform any testing, security or otherwise. The company to which T15 belongs has its own Quality Analysis (QA) team, though they do not perform security testing. P-T15 said, “I’ve never seen a bug related to security raised by QA.” The case of T15 is particularly concerning; many teams rely on this stage to address software security, while T15 does not. According to our data, security is not part of the development lifecycle in T15. It would be interesting to further explore why some teams completely ignore software security, and what factors could encourage them to adopt a security initiative.

Post-development testing plans include a security dimension. (SI) As mentioned earlier, P-T2 relies mainly on this stage for security testing, In addition, P-T6, and P-T13 say that their teams consider security during this stage. However, there seems to be a disconnect between developers and testers in T6; developers are unaware of the testing process and consider security testing out of scope. Despite her knowledge that security is included in this stage, P-T6 mentioned, “I don’t remember any tester coming back and telling [me] there are [any] kinds of vulnerability issues.” T13 started integrating security in their post-development testing after a newly hired tester who decided to approach the application from a different perspective discovered a serious security issue. P-T13 explained, “No one had really been thinking about looking at the product from security standpoint and so the new tester we had hired, he really went at it from ‘how can I really break this thing?’ [..] and found quite a few problems with the product that way.” The starting point of security testing in T13 was a matter of chance. When an actual security issue was discovered in their code, security was brought to the surface and post-development testing started addressing security.

Through our analysis, we found that along the security prioritization spectrum, there are cases where security in this stage is driven by different factors, as explained below. Some participants discussed that their team relies on a single person to handle security, thus security consideration is driven by specific factors. For example, in T4, Post-development security testing is feature-driven. (SI).

P-T4 is the only developer in his company with security expertise, thus he is responsible for security. He explained that his company has limited resources and few employees, thus they focus their security testing efforts only on security-
sensitive features (e.g., authentication processes), as flagged by the developers. Thus, the question is how reliable are assessments in this case given that they are done by developers with limited security expertise? On the other hand, in T7, Post-development security testing is adhoc. (SI) . P-T7 explained that they rely on a single operations-level engineer who maintains the IT infrastructure and handles security testing. Thus, testing is unplanned and could happen whenever the engineer has time or “whenever he decides.” P-T7 erroneously  presumes their applications are risk-free since they are a “small company”, and thus they are not an interesting target for cyberattacks. Company size was used by some of our participants to justify their practices in multiple instances. Although in our data we did not find evidence to support that company size affects actual security practices, it shows our participants’ perception.

We also found that an external mandate to the company can be a driving factor for security consideration. For example, P-T8 reported that his company needs to comply with certain security standards, thus his team performs security testing when they are expecting an external audit “to make sure the auditors can’t find any issue during the penetration test.” In this case, Post-development security testing is externally-driven. (SI) Such external pressure by an overseeing entity was described as “the main” driving factor to schedule security testing; P-T8 explained that if it were not for these audits, his team would not have bothered with security tests. Mandating security thus proved to be effective in encouraging security practices in a team that was not proactively considering it.

As evidenced by our data, the security inattentive group’s security practices, if existent, are generally informal, unstructured, and not necessarily performed by those qualified. The main focus is delivering features to customers; security is not necessarily a priority unless triggered, e.g., by experiencing a security breach or expecting an external audit.

# 4 The adopters vs. the inattentive
In general, security practices appear to be encouraged in teams to which the security adopters belong. In contrast, as explained by participants from the security inattentive group, their teams’ main priority is functionality; security is an afterthought. Contrary to a trend towards labelling developers as “the weakest link” , our analysis highlights that poor security practices is a rather complex problem that extends beyond the developer. Just as we have identified instances where developers lack security knowledge or lack motivation to address security, we have also identified instances where security was ignored or dismissed by developers’ supervisors, despite the developer’s expertise and interest. It is especially concerning when security is dismissed by those high in the company hierarchy. As an extreme case, P-T15 reported zero security practices in their SDLC; she explained “To be honest, I don’t think anybody cares about [security]. I’ve never heard or seen people talk about security at work [...] I did ask about this to my managers, but they just said ‘well, that’s how the company is. Security is not something we focus on right now.’ ”
It was interesting to find that all our participants who identified themselves as developers of web applications and services, i.e., in their current daily duties, (namely, P-T4, P-T6, P-T7, P-T8, P-T10, P-T13, P-T15) fall in the security inattentive group. Specific reasons for this are unclear. It may be because web-development is generally less mature and has a quick pace , and teams are eager to roll-out functionality to beat their competitors. In such cases, functional requirements may be prioritized and security may be viewed as something that can be addressed as an update, essentially gambling that attackers will miss any vulnerabilities in the intervening time. Teams who have not yet become victims may view this as a reasonable strategy, especially since patching generally does not require end-user involvement (e.g., web server fixes do not require users to update their software), making it a less complicated process. However, since participants building other types of software also fall in the security inattentive group, it is hard to draw a generic conclusion that web-development is particularly insecure.

# 5. INITIATIVES AND BEST PRACTICES
After exploring real life security practices, how do these compare to security best practices? To answer, we offer background on popular sources of best practices. We then amalgamate them into a concise list of the most common recommendations. In Section 6, we discuss the relationship between practices found in our study and best practices.

# 5 Secure SDLC initiatives
This section gives a brief background on prominent processes and recommendations for secure software development.

Security Development Lifecycle (SDL). Microsoft SDL  is the first initiative to encourage the integration of security in the SDLC from the early stages. It consists of 16 security practices and can be employed regardless of the platform.

Building Security In Maturity Model (BSIMM). Currently maintained by Cigital , the BSIMM  recommends 12 main security practices. It provides high-level insights to help companies plan their secure SDLC initiative and assess their security practices compared to other organizations.

Open Web Application Security Project (OWASP) initiatives. OWASP’s Software Assurance Maturity Model (SAMM)  recognizes 4 main classes of SDLC activities and provides 3 security best practices for each. Additionally, the Developer Guide  provides best practices for architects.

Although common themes exist, driving factors for these themes may differ. See Section 4 for more details.

and developers, whereas the Testing Guide  focuses on best practices for testing and evaluating security activities. Others. Additional resources for security best practices include: NASA’s Software Assurance Guidebook , NIST’s Special Publication 800-64 , US-CERT’s Top 10 Secure Coding Practices , as well as various articles emphasizing the importance of secure development.

# 5 Security Best Practices
Available resources for security best practices vary in their organization and their presentation style, e.g., they vary in technical details. Practitioners may find difficulty deciding on best practices to follow and establishing processes within their organizations . To help frame security practices we identified, we collected recommendations from the sources discussed in Section 5 to compose a concise set of best practices. This resulted in an initial set of 57 unorganized recommendations varying in format and technical details. We then grouped related recommendations, organized them in high-level themes, and iterated this process to finally produce the following 12 best practices. Other amalgamations may be possible, but we found this list helpful to interpret our study results. The list could be of independent interest to complementary research in this area.